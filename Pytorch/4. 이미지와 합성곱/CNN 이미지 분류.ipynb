{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import (Dataset, DataLoader, TensorDataset)\n",
    "import tqdm\n",
    "\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "# 훈련용 데이터 가져오기\n",
    "# 초기 상태에선 PIL（Python Imaging Library) 이미지 형식으로\n",
    "# Dataset를 만들어 버린다.\n",
    "# 따라서 transforms.ToTensor를 사용해 Tensor로 변환한다\n",
    "fashion_mnist_train = FashionMNIST(\"./\",\n",
    "\n",
    "                                   train=True, download=True,\n",
    "\n",
    "                                   transform=transforms.ToTensor())\n",
    "\n",
    "\n",
    "# 검증용 데이터 가져오기\n",
    "\n",
    "fashion_mnist_test = FashionMNIST(\"./\",\n",
    "\n",
    "                                  train=False, download=True,\n",
    "\n",
    "                                  transform=transforms.ToTensor())\n",
    "\n",
    "# 배치 크기가 128인 DataLoader를 각각 작성\n",
    "batch_size=128\n",
    "train_loader = DataLoader(fashion_mnist_train,\n",
    "                          batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(fashion_mnist_test,\n",
    "                          batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# (N, C, H, W)혀익의 Tensor를(N, C*H*W)로 늘리는 계층\n",
    "# 합성곱 출력을 MLP에 전달할 때 필요\n",
    "class FlattenLayer(nn.Module):\n",
    "    def forward(self, x):\n",
    "        sizes = x.size()\n",
    "        return x.view(sizes[0], -1)\n",
    "\n",
    "# 5×5의 커널을 사용해서 처음에 32개, 다음에 64개의 채널 작성\n",
    "# BatchNorm2d는 이미지용 Batch Normalization\n",
    "# Dropout2d는 이미지용 Dropout\n",
    "# 마지막으로 FlattenLayer 적용\n",
    "conv_net = nn.Sequential(\n",
    "    nn.Conv2d(1, 32, 5),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.Dropout2d(0.25),\n",
    "    nn.Conv2d(32, 64, 5),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.Dropout2d(0.25),\n",
    "    FlattenLayer()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# 합성곱에 의해 최종적으로 이미지 크기가 어떤지를\n",
    "# 더미 데이터를 넣어서 확인한다\n",
    "\n",
    "test_input = torch.ones(1, 1, 28, 28)\n",
    "conv_output_size = conv_net(test_input).size()[-1]\n",
    "\n",
    "# 2층 MLP\n",
    "mlp = nn.Sequential(\n",
    "    nn.Linear(conv_output_size, 200),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(200),\n",
    "    nn.Dropout(0.25),\n",
    "    nn.Linear(200, 10)\n",
    ")\n",
    "# 최종 CNN\n",
    "net = nn.Sequential(\n",
    "    conv_net,\n",
    "    mlp\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 평가용 헬퍼 함수\n",
    "def eval_net(net, data_loader, device=\"cpu\"):\n",
    "    # Dropout 및 BatchNorm을 무효화\n",
    "    net.eval()\n",
    "    ys = []\n",
    "    ypreds = []\n",
    "    for x, y in data_loader:\n",
    "        # to 메서드로 계산을 실행할 디바이스로 전송\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        # 확률이 가장 큰 클래스를 예측(리스트 2.1 참조)\n",
    "        # 여기선 forward（추론） 계산이 전부이므로 자동 미분에\n",
    "        # 필요한 처리는 off로 설정해서 불필요한 계산을 제한다\n",
    "        with torch.no_grad():\n",
    "            _, y_pred = net(x).max(1)\n",
    "        ys.append(y)\n",
    "        ypreds.append(y_pred)\n",
    "\n",
    "    # 미니 배치 단위의 예측 결과 등을 하나로 묶는다\n",
    "    ys = torch.cat(ys)\n",
    "    ypreds = torch.cat(ypreds)\n",
    "    # 예측 정확도 계산\n",
    "    acc = (ys == ypreds).float().sum() / len(ys)\n",
    "    return acc.item()\n",
    "\n",
    "# 훈련용 헬퍼 함수\n",
    "def train_net(net, train_loader, test_loader,\n",
    "              optimizer_cls=optim.Adam,\n",
    "              loss_fn=nn.CrossEntropyLoss(),\n",
    "              n_iter=10, device=\"cpu\"):\n",
    "    train_losses = []\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    optimizer = optimizer_cls(net.parameters())\n",
    "    for epoch in range(n_iter):\n",
    "        running_loss = 0.0\n",
    "        # 신경망을 훈련 모드로 설정\n",
    "        net.train()\n",
    "        n = 0\n",
    "        n_acc = 0\n",
    "        # 시간이 많이 걸리므로 tqdm을 사용해서 진행바를 표시\n",
    "        for i, (xx, yy) in tqdm.tqdm(enumerate(train_loader),\n",
    "            total=len(train_loader)):\n",
    "            xx = xx.to(device)\n",
    "            yy = yy.to(device)\n",
    "            h = net(xx)\n",
    "            loss = loss_fn(h, yy)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            n += len(xx)\n",
    "            _, y_pred = h.max(1)\n",
    "            n_acc += (yy == y_pred).float().sum().item()\n",
    "        train_losses.append(running_loss / i)\n",
    "        # 훈련 데이터의 예측 정확도\n",
    "        train_acc.append(n_acc / n)\n",
    "\n",
    "        # 검증 데이터의 예측 정확도\n",
    "        val_acc.append(eval_net(net, test_loader, device))\n",
    "        # epoch의 결과 표시\n",
    "        print(epoch, train_losses[-1], train_acc[-1],\n",
    "            val_acc[-1], flush=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 신경망의 모든 파라미터를 GPU로 전송\n",
    "net.to(\"cuda:1\")\n",
    "\n",
    "# 훈련 실행\n",
    "train_net(net, train_loader, test_loader, n_iter=20,\n",
    "device=\"cuda:1\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bde2bf38a87010a97bbcc7a504d7446e8cab3d4ec434d4d775a4fa1164dd87c0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('ailab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}