{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "006fc09a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T08:00:42.340381Z",
     "start_time": "2022-04-06T08:00:42.302383Z"
    }
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys\n",
    "sys.path.append('../예제')\n",
    "sys.path.append('../예제/ch07')\n",
    "from common.time_layers import *\n",
    "from seq2seq import Seq2seq, Encoder\n",
    "\n",
    "\n",
    "class PeekyDecoder:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(H + D, 4 * H) / np.sqrt(H + D)).astype('f')\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "        affine_W = (rn(H + H, V) / np.sqrt(H + H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        self.embed = TimeEmbedding(embed_W)\n",
    "        self.lstm = TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True)\n",
    "        self.affine = TimeAffine(affine_W, affine_b)\n",
    "\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in (self.embed, self.lstm, self.affine):\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "        self.cache = None\n",
    "\n",
    "    def forward(self, xs, h):\n",
    "        N, T = xs.shape\n",
    "        N, H = h.shape\n",
    "\n",
    "        self.lstm.set_state(h)\n",
    "\n",
    "        out = self.embed.forward(xs)\n",
    "        hs = np.repeat(h, T, axis=0).reshape(N, T, H)   ## 시계열만큼 복제하여 hs에 저장\n",
    "        out = np.concatenate((hs, out), axis=2)\n",
    "\n",
    "        out = self.lstm.forward(out)\n",
    "        out = np.concatenate((hs, out), axis=2) ## 출력 연결\n",
    "\n",
    "        score = self.affine.forward(out)\n",
    "        self.cache = H\n",
    "        return score\n",
    "\n",
    "    def backward(self, dscore):\n",
    "        H = self.cache\n",
    "\n",
    "        dout = self.affine.backward(dscore)\n",
    "        dout, dhs0 = dout[:, :, H:], dout[:, :, :H]\n",
    "        dout = self.lstm.backward(dout)\n",
    "        dembed, dhs1 = dout[:, :, H:], dout[:, :, :H]\n",
    "        self.embed.backward(dembed)\n",
    "\n",
    "        dhs = dhs0 + dhs1\n",
    "        dh = self.lstm.dh + np.sum(dhs, axis=1)\n",
    "        return dh\n",
    "\n",
    "    def generate(self, h, start_id, sample_size):\n",
    "        sampled = []\n",
    "        char_id = start_id\n",
    "        self.lstm.set_state(h)\n",
    "\n",
    "        H = h.shape[1]\n",
    "        peeky_h = h.reshape(1, 1, H)\n",
    "        for _ in range(sample_size):\n",
    "            x = np.array([char_id]).reshape((1, 1))\n",
    "            out = self.embed.forward(x)\n",
    "\n",
    "            out = np.concatenate((peeky_h, out), axis=2)\n",
    "            out = self.lstm.forward(out)\n",
    "            out = np.concatenate((peeky_h, out), axis=2)\n",
    "            score = self.affine.forward(out)\n",
    "\n",
    "            char_id = np.argmax(score.flatten())\n",
    "            sampled.append(char_id)\n",
    "\n",
    "        return sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbf9b19d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T08:00:45.489838Z",
     "start_time": "2022-04-06T08:00:45.477834Z"
    }
   },
   "outputs": [],
   "source": [
    "class PeekySeq2seq(Seq2seq):\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        self.encoder = Encoder(V, D, H)\n",
    "        self.decoder = PeekyDecoder(V, D, H)\n",
    "        self.softmax = TimeSoftmaxWithLoss()\n",
    "\n",
    "        self.params = self.encoder.params + self.decoder.params\n",
    "        self.grads = self.encoder.grads + self.decoder.grads\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yyc",
   "language": "python",
   "name": "yyc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
