{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc9b2590",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-23T00:43:58.348165Z",
     "start_time": "2022-03-23T00:29:25.060704Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.300360816262135\n",
      "=== epoch:1, train acc:0.225, test acc:0.229 ===\n",
      "train loss:2.2979903504120687\n",
      "train loss:2.294316641141668\n",
      "train loss:2.290828250328879\n",
      "train loss:2.283581331452786\n",
      "train loss:2.274176215354186\n",
      "train loss:2.2606614636838014\n",
      "train loss:2.247603699046373\n",
      "train loss:2.2091499807708876\n",
      "train loss:2.195903891544505\n",
      "train loss:2.151901110504653\n",
      "train loss:2.1652738112477157\n",
      "train loss:2.135346523113827\n",
      "train loss:2.058441716454205\n",
      "train loss:1.9993646969425\n",
      "train loss:1.961640067758789\n",
      "train loss:1.9204760670647738\n",
      "train loss:1.8413534249806311\n",
      "train loss:1.78157862088594\n",
      "train loss:1.6329143980078284\n",
      "train loss:1.63533905750594\n",
      "train loss:1.5246236515488512\n",
      "train loss:1.5364273921252625\n",
      "train loss:1.365861913536452\n",
      "train loss:1.363531460254264\n",
      "train loss:1.1326312135782368\n",
      "train loss:1.1446196089593612\n",
      "train loss:1.1017829523172251\n",
      "train loss:1.1708777745969057\n",
      "train loss:0.8994838466264572\n",
      "train loss:0.9399167099662264\n",
      "train loss:0.8804807455204995\n",
      "train loss:0.8582114996451348\n",
      "train loss:0.7976752875641706\n",
      "train loss:0.7976830940882009\n",
      "train loss:0.7697045774094334\n",
      "train loss:0.7711939098307795\n",
      "train loss:0.6919958626490632\n",
      "train loss:0.7756271179436086\n",
      "train loss:0.704158886478396\n",
      "train loss:0.5706136916977698\n",
      "train loss:0.6410115112839587\n",
      "train loss:0.5798860221683736\n",
      "train loss:0.4840524014511637\n",
      "train loss:0.5942318484341965\n",
      "train loss:0.6271864334834825\n",
      "train loss:0.5920524383379367\n",
      "train loss:0.65940446609189\n",
      "train loss:0.8073832240255209\n",
      "train loss:0.6551139808679423\n",
      "train loss:0.4640837937300435\n",
      "train loss:0.6061898134307535\n",
      "train loss:0.5312645538185155\n",
      "train loss:0.5074404539826376\n",
      "train loss:0.5957835891299587\n",
      "train loss:0.5486674418103553\n",
      "train loss:0.6258961537102189\n",
      "train loss:0.5290906959148595\n",
      "train loss:0.4857211959439535\n",
      "train loss:0.47694122818967327\n",
      "train loss:0.34074835149968263\n",
      "train loss:0.34118760039182466\n",
      "train loss:0.4307418694383427\n",
      "train loss:0.5103496778204107\n",
      "train loss:0.554575190864971\n",
      "train loss:0.4601627872412268\n",
      "train loss:0.34281620624445397\n",
      "train loss:0.40013672589707583\n",
      "train loss:0.39844559174664196\n",
      "train loss:0.40901323016369967\n",
      "train loss:0.44117751304656144\n",
      "train loss:0.4358261169425791\n",
      "train loss:0.5463891086223114\n",
      "train loss:0.37540986732314574\n",
      "train loss:0.45574382488540777\n",
      "train loss:0.3597432964351547\n",
      "train loss:0.535535290859809\n",
      "train loss:0.4042789372590528\n",
      "train loss:0.3231145161559258\n",
      "train loss:0.45870173039894313\n",
      "train loss:0.40773130969176735\n",
      "train loss:0.5565185453950072\n",
      "train loss:0.42065633833415106\n",
      "train loss:0.3349826554405936\n",
      "train loss:0.3928317670713363\n",
      "train loss:0.3756295039272897\n",
      "train loss:0.4471221837008437\n",
      "train loss:0.3189422059281694\n",
      "train loss:0.47780115345307245\n",
      "train loss:0.36243644422333454\n",
      "train loss:0.44758794870314944\n",
      "train loss:0.39142114739107514\n",
      "train loss:0.41791666616397516\n",
      "train loss:0.4259562528954614\n",
      "train loss:0.5048332798922415\n",
      "train loss:0.4742489354968783\n",
      "train loss:0.37976193686156207\n",
      "train loss:0.45880538991203196\n",
      "train loss:0.31410625480363735\n",
      "train loss:0.5286832864584653\n",
      "train loss:0.5157363953986309\n",
      "train loss:0.450808118389501\n",
      "train loss:0.3927582709125752\n",
      "train loss:0.2838587210994179\n",
      "train loss:0.41453983193685606\n",
      "train loss:0.3456333875355682\n",
      "train loss:0.4298281036572538\n",
      "train loss:0.27567268848435483\n",
      "train loss:0.5176617942703735\n",
      "train loss:0.30641014818162765\n",
      "train loss:0.30434208022807535\n",
      "train loss:0.3109407887845412\n",
      "train loss:0.42837100935913425\n",
      "train loss:0.32063458407471335\n",
      "train loss:0.2911635529033089\n",
      "train loss:0.36326846017585984\n",
      "train loss:0.37690012552517294\n",
      "train loss:0.47397099501586964\n",
      "train loss:0.3200134238146476\n",
      "train loss:0.42345990894677127\n",
      "train loss:0.506342119425566\n",
      "train loss:0.2724688613892536\n",
      "train loss:0.347742492572942\n",
      "train loss:0.2558209334291112\n",
      "train loss:0.27694562466589356\n",
      "train loss:0.29881033768120974\n",
      "train loss:0.35786351739065814\n",
      "train loss:0.3486385291633313\n",
      "train loss:0.3977179224059999\n",
      "train loss:0.21393464369750326\n",
      "train loss:0.39548621473071705\n",
      "train loss:0.3344059746173857\n",
      "train loss:0.4048766722108569\n",
      "train loss:0.37431980652690994\n",
      "train loss:0.26535663942252696\n",
      "train loss:0.21045162242868154\n",
      "train loss:0.47740365801503076\n",
      "train loss:0.33810421277352526\n",
      "train loss:0.5059596316551663\n",
      "train loss:0.34492083882306074\n",
      "train loss:0.4173264785881548\n",
      "train loss:0.33297433431184265\n",
      "train loss:0.3086668191129948\n",
      "train loss:0.2654463810610686\n",
      "train loss:0.42063926698902426\n",
      "train loss:0.3945945228665554\n",
      "train loss:0.4476698316663726\n",
      "train loss:0.32526651688231306\n",
      "train loss:0.19633544807963696\n",
      "train loss:0.42788757901678487\n",
      "train loss:0.25338555515466454\n",
      "train loss:0.22164092627442578\n",
      "train loss:0.26381010673043565\n",
      "train loss:0.2672698844448557\n",
      "train loss:0.32227206147015586\n",
      "train loss:0.34503839783374235\n",
      "train loss:0.25451390070373114\n",
      "train loss:0.44709436745157555\n",
      "train loss:0.2528546944089668\n",
      "train loss:0.34669587874306207\n",
      "train loss:0.5282721843610545\n",
      "train loss:0.2836383026235843\n",
      "train loss:0.3322234854099774\n",
      "train loss:0.26672000050219213\n",
      "train loss:0.2584319745674328\n",
      "train loss:0.2333498333428469\n",
      "train loss:0.604228875957138\n",
      "train loss:0.249804652238724\n",
      "train loss:0.33750275410416797\n",
      "train loss:0.2639934044030779\n",
      "train loss:0.38611006385405916\n",
      "train loss:0.2547105285391553\n",
      "train loss:0.17912621389901037\n",
      "train loss:0.3748780671452986\n",
      "train loss:0.3734460168155646\n",
      "train loss:0.2721530478636394\n",
      "train loss:0.2668138834048635\n",
      "train loss:0.33279777287726303\n",
      "train loss:0.27750412389392953\n",
      "train loss:0.23608972260126607\n",
      "train loss:0.15531224417657272\n",
      "train loss:0.2387632519965941\n",
      "train loss:0.2546347917178892\n",
      "train loss:0.18858938466776504\n",
      "train loss:0.23911547232282726\n",
      "train loss:0.24463039789041527\n",
      "train loss:0.4165803764223529\n",
      "train loss:0.24262147959645566\n",
      "train loss:0.22952491541231093\n",
      "train loss:0.3007682955827813\n",
      "train loss:0.2812465376468403\n",
      "train loss:0.24571911859665327\n",
      "train loss:0.3589401463479502\n",
      "train loss:0.16207995673898604\n",
      "train loss:0.2208105698265158\n",
      "train loss:0.22745651823398155\n",
      "train loss:0.14143667980363905\n",
      "train loss:0.21046756252198393\n",
      "train loss:0.29239167104985925\n",
      "train loss:0.26892938651124754\n",
      "train loss:0.3227834817348303\n",
      "train loss:0.22639783560907362\n",
      "train loss:0.3466531091317309\n",
      "train loss:0.17734355796886636\n",
      "train loss:0.28823884154282187\n",
      "train loss:0.22207366193393852\n",
      "train loss:0.2137409564313945\n",
      "train loss:0.17226923552334772\n",
      "train loss:0.2293331240054978\n",
      "train loss:0.2155773327695377\n",
      "train loss:0.26443898033205065\n",
      "train loss:0.26101926220616395\n",
      "train loss:0.3365053817890692\n",
      "train loss:0.1528175347879535\n",
      "train loss:0.21598701785739893\n",
      "train loss:0.3206896644261771\n",
      "train loss:0.2078688520385167\n",
      "train loss:0.25169253220467225\n",
      "train loss:0.19186341029836387\n",
      "train loss:0.14112815894240968\n",
      "train loss:0.2586297737640455\n",
      "train loss:0.21951288853951098\n",
      "train loss:0.3150888174613406\n",
      "train loss:0.2458320368635202\n",
      "train loss:0.2583668426772554\n",
      "train loss:0.23518152844138576\n",
      "train loss:0.20292053521335646\n",
      "train loss:0.32736409382289217\n",
      "train loss:0.1820589779392886\n",
      "train loss:0.22295543932143705\n",
      "train loss:0.2186960037489812\n",
      "train loss:0.20406018659646577\n",
      "train loss:0.3405976851867392\n",
      "train loss:0.22852689863544304\n",
      "train loss:0.24660823213902475\n",
      "train loss:0.20749804797425012\n",
      "train loss:0.187689229040401\n",
      "train loss:0.1744421845904904\n",
      "train loss:0.2743214277313617\n",
      "train loss:0.20444065836012545\n",
      "train loss:0.23390220808988263\n",
      "train loss:0.25257976246989344\n",
      "train loss:0.2564399760567548\n",
      "train loss:0.13245187717171997\n",
      "train loss:0.1735747221711834\n",
      "train loss:0.2670876811257973\n",
      "train loss:0.2736699291949106\n",
      "train loss:0.2236491773998648\n",
      "train loss:0.13619190668782438\n",
      "train loss:0.23014392339139728\n",
      "train loss:0.4061983277827551\n",
      "train loss:0.23602837979692015\n",
      "train loss:0.3008124034627371\n",
      "train loss:0.28092539005150147\n",
      "train loss:0.22539236521291467\n",
      "train loss:0.14482411447028237\n",
      "train loss:0.3265941322135067\n",
      "train loss:0.2056259773306215\n",
      "train loss:0.12262001129345874\n",
      "train loss:0.15316345161023132\n",
      "train loss:0.28530818266459745\n",
      "train loss:0.21159428223051369\n",
      "train loss:0.26504904901470633\n",
      "train loss:0.25123155691552523\n",
      "train loss:0.21660142165238594\n",
      "train loss:0.16605501765842548\n",
      "train loss:0.26578179905397764\n",
      "train loss:0.1799118370165407\n",
      "train loss:0.20262868112232849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.28841622146338985\n",
      "train loss:0.24047812133038365\n",
      "train loss:0.2657814378150555\n",
      "train loss:0.26690685080211124\n",
      "train loss:0.23306082441205034\n",
      "train loss:0.1830996953670836\n",
      "train loss:0.134123124459887\n",
      "train loss:0.1575410358045308\n",
      "train loss:0.1852532344420047\n",
      "train loss:0.3490826200041364\n",
      "train loss:0.2799052653184862\n",
      "train loss:0.4204951318508599\n",
      "train loss:0.27141101573967225\n",
      "train loss:0.20757275688363183\n",
      "train loss:0.3077834473890436\n",
      "train loss:0.1000587636603792\n",
      "train loss:0.3100080767126662\n",
      "train loss:0.20148029823263072\n",
      "train loss:0.24779257392067958\n",
      "train loss:0.14561416382430192\n",
      "train loss:0.26270561705394097\n",
      "train loss:0.21500520400304476\n",
      "train loss:0.199304454822636\n",
      "train loss:0.10461013215815738\n",
      "train loss:0.19097955684480872\n",
      "train loss:0.26444857290626\n",
      "train loss:0.24253625664092446\n",
      "train loss:0.2173453032285112\n",
      "train loss:0.2066465225172595\n",
      "train loss:0.3289657986767533\n",
      "train loss:0.17224531408796384\n",
      "train loss:0.17028067304411787\n",
      "train loss:0.2801256943445102\n",
      "train loss:0.18706002708924557\n",
      "train loss:0.1530694643974024\n",
      "train loss:0.1458646129929636\n",
      "train loss:0.22488280189659318\n",
      "train loss:0.15701661598032668\n",
      "train loss:0.18270911827234254\n",
      "train loss:0.2154323817328165\n",
      "train loss:0.18922662247313263\n",
      "train loss:0.12029420295025388\n",
      "train loss:0.1799115766866336\n",
      "train loss:0.13983716289256332\n",
      "train loss:0.14438758224397719\n",
      "train loss:0.13152974562110317\n",
      "train loss:0.19285111011959688\n",
      "train loss:0.2625318767421045\n",
      "train loss:0.22554382553313115\n",
      "train loss:0.21185144341315795\n",
      "train loss:0.17654170136129838\n",
      "train loss:0.30754112158346203\n",
      "train loss:0.24455741932425215\n",
      "train loss:0.1864763080643939\n",
      "train loss:0.17206649497030863\n",
      "train loss:0.2545759798266347\n",
      "train loss:0.12682509260222838\n",
      "train loss:0.07969179183165695\n",
      "train loss:0.21136801769468724\n",
      "train loss:0.1433367134860127\n",
      "train loss:0.17197943201266055\n",
      "train loss:0.13747039252988338\n",
      "train loss:0.2501312131953109\n",
      "train loss:0.1646404944452126\n",
      "train loss:0.21316623951156793\n",
      "train loss:0.17886636551161847\n",
      "train loss:0.1380685865061338\n",
      "train loss:0.18107234038856732\n",
      "train loss:0.15698585398929985\n",
      "train loss:0.27849712960954986\n",
      "train loss:0.10866965448594573\n",
      "train loss:0.22398625327055935\n",
      "train loss:0.13336646841098998\n",
      "train loss:0.14272150955506974\n",
      "train loss:0.21182311004468019\n",
      "train loss:0.17012995861299227\n",
      "train loss:0.19959440645501758\n",
      "train loss:0.3121967902396003\n",
      "train loss:0.3012749654662511\n",
      "train loss:0.1401877012826965\n",
      "train loss:0.23085660612414208\n",
      "train loss:0.18971895842541783\n",
      "train loss:0.11358538649366341\n",
      "train loss:0.204258604131018\n",
      "train loss:0.22980284564796288\n",
      "train loss:0.11158554896841828\n",
      "train loss:0.19572777676863246\n",
      "train loss:0.12536814139805724\n",
      "train loss:0.07754555156937534\n",
      "train loss:0.18014262568044578\n",
      "train loss:0.15808579345708026\n",
      "train loss:0.16427560116121417\n",
      "train loss:0.12186741183006754\n",
      "train loss:0.16982910072085125\n",
      "train loss:0.1534386871596395\n",
      "train loss:0.15035086305259512\n",
      "train loss:0.19467792317514732\n",
      "train loss:0.2006062055400922\n",
      "train loss:0.11277974276714561\n",
      "train loss:0.13010485817737144\n",
      "train loss:0.2280351661512395\n",
      "train loss:0.1701654873814279\n",
      "train loss:0.15793070449383825\n",
      "train loss:0.12139481277614342\n",
      "train loss:0.15142637298400774\n",
      "train loss:0.11779445443951474\n",
      "train loss:0.23067862534653735\n",
      "train loss:0.26981857738154896\n",
      "train loss:0.09041242508937355\n",
      "train loss:0.18173547588866248\n",
      "train loss:0.1829242412019923\n",
      "train loss:0.17786218507282647\n",
      "train loss:0.13500667140958117\n",
      "train loss:0.09919145703404292\n",
      "train loss:0.2339101137154056\n",
      "train loss:0.12104224570295974\n",
      "train loss:0.060824204275244334\n",
      "train loss:0.3929055576082934\n",
      "train loss:0.29704478132535106\n",
      "train loss:0.23353779639619898\n",
      "train loss:0.1560740221433633\n",
      "train loss:0.10144231968863426\n",
      "train loss:0.16430139931002774\n",
      "train loss:0.09571681212575109\n",
      "train loss:0.18534151330693352\n",
      "train loss:0.1492544869057741\n",
      "train loss:0.11264809501342697\n",
      "train loss:0.18785395309184555\n",
      "train loss:0.20217627370180577\n",
      "train loss:0.11506328518312586\n",
      "train loss:0.11431346495613486\n",
      "train loss:0.19952444637014416\n",
      "train loss:0.1688141147507993\n",
      "train loss:0.14275702450766128\n",
      "train loss:0.13006709223568538\n",
      "train loss:0.19567120092399468\n",
      "train loss:0.14673150727730286\n",
      "train loss:0.07902741464065052\n",
      "train loss:0.13009033469479983\n",
      "train loss:0.14122680582690322\n",
      "train loss:0.09375424726147222\n",
      "train loss:0.30714499192784134\n",
      "train loss:0.11226200528155961\n",
      "train loss:0.062368314651385086\n",
      "train loss:0.12962677414548293\n",
      "train loss:0.14712197240792826\n",
      "train loss:0.2112730040812769\n",
      "train loss:0.09166890867083524\n",
      "train loss:0.3494244986743487\n",
      "train loss:0.16855304029583973\n",
      "train loss:0.15147474565694835\n",
      "train loss:0.09375720822266784\n",
      "train loss:0.19576825782731663\n",
      "train loss:0.237261377905733\n",
      "train loss:0.19483699937950147\n",
      "train loss:0.19246944479865188\n",
      "train loss:0.19617729119997324\n",
      "train loss:0.17589057092650326\n",
      "train loss:0.20548280715929304\n",
      "train loss:0.13136641263754806\n",
      "train loss:0.1854458308692211\n",
      "train loss:0.11686553581644084\n",
      "train loss:0.15008074347131417\n",
      "train loss:0.29179107856270664\n",
      "train loss:0.12008797548343797\n",
      "train loss:0.12611903728200363\n",
      "train loss:0.07060387804397725\n",
      "train loss:0.054514410951565735\n",
      "train loss:0.14638643158619735\n",
      "train loss:0.10992937987989697\n",
      "train loss:0.1636648438717385\n",
      "train loss:0.09810753210298243\n",
      "train loss:0.14012741846155563\n",
      "train loss:0.08764894344340135\n",
      "train loss:0.06708228464260632\n",
      "train loss:0.1284372349653182\n",
      "train loss:0.31051161497865337\n",
      "train loss:0.1426976264831316\n",
      "train loss:0.08752325400061446\n",
      "train loss:0.36330554068737675\n",
      "train loss:0.1237846558815381\n",
      "train loss:0.11026089683966508\n",
      "train loss:0.11816237181271763\n",
      "train loss:0.15674219943528092\n",
      "train loss:0.1185722102710731\n",
      "train loss:0.16829350910201188\n",
      "train loss:0.029711533159438353\n",
      "train loss:0.10339550575227319\n",
      "train loss:0.093021180484777\n",
      "train loss:0.16270145882644718\n",
      "train loss:0.07197134938121282\n",
      "train loss:0.11142620572998178\n",
      "train loss:0.10455456050635725\n",
      "train loss:0.18836758140154986\n",
      "train loss:0.21032697669959657\n",
      "train loss:0.157748477323256\n",
      "train loss:0.1952377103476326\n",
      "train loss:0.13594193016228562\n",
      "train loss:0.15979480892437128\n",
      "train loss:0.13212070261610614\n",
      "train loss:0.11751105385930671\n",
      "train loss:0.1305046409228955\n",
      "train loss:0.08438922187087478\n",
      "train loss:0.17584384668542544\n",
      "train loss:0.15133887929858048\n",
      "train loss:0.11022281033121956\n",
      "train loss:0.11444738139520917\n",
      "train loss:0.10601129501970549\n",
      "train loss:0.1469260419622443\n",
      "train loss:0.1704564008083873\n",
      "train loss:0.1042393706113543\n",
      "train loss:0.08814942066571069\n",
      "train loss:0.08652216513411409\n",
      "train loss:0.22359369957193095\n",
      "train loss:0.07411352322945108\n",
      "train loss:0.09654012236331112\n",
      "train loss:0.13491469149296706\n",
      "train loss:0.0697907880393611\n",
      "train loss:0.11366389688011509\n",
      "train loss:0.1085292295805581\n",
      "train loss:0.2554895289207673\n",
      "train loss:0.07764595621835961\n",
      "train loss:0.17071712586400295\n",
      "train loss:0.09060719464142883\n",
      "train loss:0.11684090873586837\n",
      "train loss:0.12106129061145349\n",
      "train loss:0.0886288852645612\n",
      "train loss:0.16161651123413898\n",
      "train loss:0.09064399231376394\n",
      "train loss:0.09943718629383927\n",
      "train loss:0.25806449189927166\n",
      "train loss:0.12385155076533132\n",
      "train loss:0.14009150765338865\n",
      "train loss:0.15046153519374708\n",
      "train loss:0.08396176112529366\n",
      "train loss:0.14529664459960648\n",
      "train loss:0.1117470933039402\n",
      "train loss:0.1348885127848777\n",
      "train loss:0.06513401620733601\n",
      "train loss:0.28834997735835655\n",
      "train loss:0.17500396570213986\n",
      "train loss:0.08715690623796317\n",
      "train loss:0.07367307808828498\n",
      "train loss:0.038611248412710894\n",
      "train loss:0.15605744252754955\n",
      "train loss:0.18863049374042185\n",
      "train loss:0.07795821944959531\n",
      "train loss:0.1648398808273284\n",
      "train loss:0.22724145034338736\n",
      "train loss:0.20696630845197536\n",
      "train loss:0.12128860106975703\n",
      "train loss:0.11399170621722254\n",
      "train loss:0.08538859546001536\n",
      "train loss:0.07036824600419064\n",
      "train loss:0.09735293737783288\n",
      "train loss:0.1175953236700974\n",
      "train loss:0.08601869453596979\n",
      "train loss:0.09525668045682485\n",
      "train loss:0.19683249620590715\n",
      "train loss:0.08265303562365561\n",
      "train loss:0.1163949683225599\n",
      "train loss:0.11212703355880378\n",
      "train loss:0.06274667136282704\n",
      "train loss:0.13191843795933625\n",
      "train loss:0.23916172082481588\n",
      "train loss:0.12038679766161355\n",
      "train loss:0.06580026689202267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0856508834953292\n",
      "train loss:0.1108897699071435\n",
      "train loss:0.09890100329359194\n",
      "train loss:0.1726498632527777\n",
      "train loss:0.061187511298333906\n",
      "train loss:0.16796267134980408\n",
      "train loss:0.08103374841794851\n",
      "train loss:0.029193563584379592\n",
      "train loss:0.056991054184686495\n",
      "train loss:0.09568834783135774\n",
      "train loss:0.11630454499188426\n",
      "train loss:0.14454755649187465\n",
      "train loss:0.09477083198224064\n",
      "train loss:0.04006340698467053\n",
      "train loss:0.10940322329136791\n",
      "train loss:0.07010671121696033\n",
      "train loss:0.08080798828342964\n",
      "train loss:0.20386825497038694\n",
      "train loss:0.13114812227323977\n",
      "train loss:0.11645663497668403\n",
      "train loss:0.12749282984058719\n",
      "train loss:0.10550462349691339\n",
      "train loss:0.13482218305746085\n",
      "train loss:0.17126134871971924\n",
      "train loss:0.0848159737463436\n",
      "train loss:0.1216429854688886\n",
      "train loss:0.07773911028416297\n",
      "train loss:0.07793021822563792\n",
      "train loss:0.11333009860309133\n",
      "train loss:0.07188372442278146\n",
      "train loss:0.07147119424955853\n",
      "train loss:0.0585913114666301\n",
      "train loss:0.10099071936190143\n",
      "train loss:0.12029384983498746\n",
      "train loss:0.08004833556605075\n",
      "train loss:0.12880461826459316\n",
      "train loss:0.17520891299416508\n",
      "train loss:0.1259872773826953\n",
      "train loss:0.10916830075274837\n",
      "train loss:0.12650960476181958\n",
      "train loss:0.09896910460604527\n",
      "train loss:0.05298058545818825\n",
      "train loss:0.06429609698985715\n",
      "train loss:0.1531529438005007\n",
      "train loss:0.17879881412071008\n",
      "train loss:0.17318868490779274\n",
      "train loss:0.10186666925790626\n",
      "train loss:0.1013164268654657\n",
      "train loss:0.05383385964501347\n",
      "train loss:0.06592558465584882\n",
      "train loss:0.08282771864483386\n",
      "train loss:0.12653895272846302\n",
      "train loss:0.17656881982718808\n",
      "train loss:0.11476145632624543\n",
      "train loss:0.11318542551630552\n",
      "train loss:0.11001456828901335\n",
      "train loss:0.09590573896453325\n",
      "train loss:0.15958242890790542\n",
      "train loss:0.08487769533720783\n",
      "train loss:0.21408360000972737\n",
      "train loss:0.2091266821378493\n",
      "train loss:0.12684319577035627\n",
      "train loss:0.13164596852313193\n",
      "train loss:0.13075197351047194\n",
      "train loss:0.14870184659671834\n",
      "=== epoch:2, train acc:0.963, test acc:0.961 ===\n",
      "train loss:0.04129320513468402\n",
      "train loss:0.11694199423018642\n",
      "train loss:0.07641853669056788\n",
      "train loss:0.08721330765853703\n",
      "train loss:0.056706601421072096\n",
      "train loss:0.12655551040297106\n",
      "train loss:0.04604556597903202\n",
      "train loss:0.14762158466872355\n",
      "train loss:0.11392943799871542\n",
      "train loss:0.1369577116152228\n",
      "train loss:0.07720837987009779\n",
      "train loss:0.05090580856399453\n",
      "train loss:0.07274656111185887\n",
      "train loss:0.08983851061638445\n",
      "train loss:0.12329697495019348\n",
      "train loss:0.031996410219547036\n",
      "train loss:0.09767163242451625\n",
      "train loss:0.045307712126266074\n",
      "train loss:0.09161503238617738\n",
      "train loss:0.11240397711184665\n",
      "train loss:0.052045218712435365\n",
      "train loss:0.12589627222990873\n",
      "train loss:0.06942259759356008\n",
      "train loss:0.19478427826673034\n",
      "train loss:0.1261952606414331\n",
      "train loss:0.07950246378731561\n",
      "train loss:0.0842170858005807\n",
      "train loss:0.10095630791675543\n",
      "train loss:0.1471728858052889\n",
      "train loss:0.046786386975891645\n",
      "train loss:0.053107924893326414\n",
      "train loss:0.04220833861429082\n",
      "train loss:0.08107481608128397\n",
      "train loss:0.1676022047295054\n",
      "train loss:0.07408807814304079\n",
      "train loss:0.19199566742853946\n",
      "train loss:0.09345834083794456\n",
      "train loss:0.1114202119810686\n",
      "train loss:0.07221142466891622\n",
      "train loss:0.0641182934536793\n",
      "train loss:0.16804441798164935\n",
      "train loss:0.13922909575147768\n",
      "train loss:0.12274658126597235\n",
      "train loss:0.13325503119375975\n",
      "train loss:0.051351981906805365\n",
      "train loss:0.06024678922668443\n",
      "train loss:0.06527287155136871\n",
      "train loss:0.12838800978030518\n",
      "train loss:0.18797237451591378\n",
      "train loss:0.13180377676494365\n",
      "train loss:0.09239675240025685\n",
      "train loss:0.08112163468955537\n",
      "train loss:0.10267109975708447\n",
      "train loss:0.06647820557561819\n",
      "train loss:0.10765239568250529\n",
      "train loss:0.06777615158601086\n",
      "train loss:0.04610845780540227\n",
      "train loss:0.10374769179552742\n",
      "train loss:0.20059500718909218\n",
      "train loss:0.06290322789677623\n",
      "train loss:0.0923907211714836\n",
      "train loss:0.2599070213135349\n",
      "train loss:0.07713970501031574\n",
      "train loss:0.030270220414028173\n",
      "train loss:0.06346969866714629\n",
      "train loss:0.14652865040956406\n",
      "train loss:0.0628592370890219\n",
      "train loss:0.0709102541986598\n",
      "train loss:0.07946261438777819\n",
      "train loss:0.06799908346670652\n",
      "train loss:0.08274272723431897\n",
      "train loss:0.09590219768300587\n",
      "train loss:0.11386539599422839\n",
      "train loss:0.037424931789257786\n",
      "train loss:0.24707672010364612\n",
      "train loss:0.055215484223959485\n",
      "train loss:0.07033628810381468\n",
      "train loss:0.19031109291233128\n",
      "train loss:0.0581525133945524\n",
      "train loss:0.07846994628844003\n",
      "train loss:0.21437149202734648\n",
      "train loss:0.10272585487231128\n",
      "train loss:0.08445561965300445\n",
      "train loss:0.09866268205394092\n",
      "train loss:0.05002297662648544\n",
      "train loss:0.10418968555057231\n",
      "train loss:0.09493594957657288\n",
      "train loss:0.04502132951915476\n",
      "train loss:0.070383711761849\n",
      "train loss:0.06958115238141885\n",
      "train loss:0.14544992511228388\n",
      "train loss:0.07092229689126502\n",
      "train loss:0.21034070071324876\n",
      "train loss:0.1204567462779829\n",
      "train loss:0.1567278546769855\n",
      "train loss:0.03176867814026051\n",
      "train loss:0.054250855429449144\n",
      "train loss:0.034725203476929\n",
      "train loss:0.03413510648569422\n",
      "train loss:0.04625960491205796\n",
      "train loss:0.2250073665383083\n",
      "train loss:0.037841833945001395\n",
      "train loss:0.13545231984400552\n",
      "train loss:0.05719778016553238\n",
      "train loss:0.1381788331424303\n",
      "train loss:0.07474390760914913\n",
      "train loss:0.1302728526963284\n",
      "train loss:0.10516565214774136\n",
      "train loss:0.08114290677413327\n",
      "train loss:0.1099357201093114\n",
      "train loss:0.06459307046602154\n",
      "train loss:0.1373447479811027\n",
      "train loss:0.052304059202928424\n",
      "train loss:0.15247612149622328\n",
      "train loss:0.0987144998277234\n",
      "train loss:0.10163064333826549\n",
      "train loss:0.06534082769915708\n",
      "train loss:0.06573583849039873\n",
      "train loss:0.12015690211101974\n",
      "train loss:0.07625356585178793\n",
      "train loss:0.05996951081874224\n",
      "train loss:0.11987253516786231\n",
      "train loss:0.05848534847792035\n",
      "train loss:0.08718576589976948\n",
      "train loss:0.05073349083208356\n",
      "train loss:0.07976628106454037\n",
      "train loss:0.10857767564946631\n",
      "train loss:0.07505578510158947\n",
      "train loss:0.12009592363455202\n",
      "train loss:0.20201528462631874\n",
      "train loss:0.10141363611799839\n",
      "train loss:0.07932657437720184\n",
      "train loss:0.12275812241471026\n",
      "train loss:0.11653870390344608\n",
      "train loss:0.14360956460074709\n",
      "train loss:0.06265624647086125\n",
      "train loss:0.026458331973668255\n",
      "train loss:0.042859625905040444\n",
      "train loss:0.12381799733935192\n",
      "train loss:0.08154507873862026\n",
      "train loss:0.03198021509648144\n",
      "train loss:0.09762386472472659\n",
      "train loss:0.03720818363624067\n",
      "train loss:0.05470204102793661\n",
      "train loss:0.050556302755703476\n",
      "train loss:0.13533271335723795\n",
      "train loss:0.10479714132152386\n",
      "train loss:0.06731337845512911\n",
      "train loss:0.09868317911771332\n",
      "train loss:0.11726889109735655\n",
      "train loss:0.08448644832678516\n",
      "train loss:0.13202042710775083\n",
      "train loss:0.0842428457111983\n",
      "train loss:0.05686313458905589\n",
      "train loss:0.027378876284085644\n",
      "train loss:0.09673272300314158\n",
      "train loss:0.08683757426819694\n",
      "train loss:0.10419319993614724\n",
      "train loss:0.08851820199521233\n",
      "train loss:0.13043525298207403\n",
      "train loss:0.10321371859995254\n",
      "train loss:0.16696297441268354\n",
      "train loss:0.12306319306668252\n",
      "train loss:0.05973925918197347\n",
      "train loss:0.06178797965079069\n",
      "train loss:0.12481274711902784\n",
      "train loss:0.12007784882427643\n",
      "train loss:0.059490244799557584\n",
      "train loss:0.05659102780798467\n",
      "train loss:0.04466488778097125\n",
      "train loss:0.20153852968531386\n",
      "train loss:0.03440183416275412\n",
      "train loss:0.07318727168688101\n",
      "train loss:0.07598154801531296\n",
      "train loss:0.04763731995062349\n",
      "train loss:0.033856602283846196\n",
      "train loss:0.04602436188077073\n",
      "train loss:0.1592730787546367\n",
      "train loss:0.10660923325506567\n",
      "train loss:0.09467424011498705\n",
      "train loss:0.07330477060407477\n",
      "train loss:0.11702943577120659\n",
      "train loss:0.06037909966670086\n",
      "train loss:0.10805544437950194\n",
      "train loss:0.16682961206275013\n",
      "train loss:0.09857480184553413\n",
      "train loss:0.05452790329616173\n",
      "train loss:0.11356811166546231\n",
      "train loss:0.07349487565511344\n",
      "train loss:0.1314486200749066\n",
      "train loss:0.03929538816880442\n",
      "train loss:0.0718961505403317\n",
      "train loss:0.05602396582278089\n",
      "train loss:0.16504393216504165\n",
      "train loss:0.10099624282775206\n",
      "train loss:0.04990349514721993\n",
      "train loss:0.07444207975854489\n",
      "train loss:0.04336551534547934\n",
      "train loss:0.03330076645714336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.07692062330498774\n",
      "train loss:0.0322236702329207\n",
      "train loss:0.048657308127036246\n",
      "train loss:0.08743617329016497\n",
      "train loss:0.11259380035215863\n",
      "train loss:0.14309644674900363\n",
      "train loss:0.0646352799393734\n",
      "train loss:0.03745495804325936\n",
      "train loss:0.07725254214578936\n",
      "train loss:0.053848161187217684\n",
      "train loss:0.04880878014218227\n",
      "train loss:0.048790192429300466\n",
      "train loss:0.0524862464023196\n",
      "train loss:0.07541211335418735\n",
      "train loss:0.10074471924220975\n",
      "train loss:0.0770574813543192\n",
      "train loss:0.0740944064607415\n",
      "train loss:0.044702564033113706\n",
      "train loss:0.1041276077467176\n",
      "train loss:0.13309991127564177\n",
      "train loss:0.057436261238037724\n",
      "train loss:0.19747092200769883\n",
      "train loss:0.03748130957664695\n",
      "train loss:0.18253485876231065\n",
      "train loss:0.05112070866571045\n",
      "train loss:0.09258008547767366\n",
      "train loss:0.024618172911662028\n",
      "train loss:0.08883354030014524\n",
      "train loss:0.059835230817115705\n",
      "train loss:0.08032401618372446\n",
      "train loss:0.05500502734182974\n",
      "train loss:0.19561230563732426\n",
      "train loss:0.07012042781211193\n",
      "train loss:0.08308966085786192\n",
      "train loss:0.10682166730788524\n",
      "train loss:0.02488868906721601\n",
      "train loss:0.060676782712890294\n",
      "train loss:0.08206240948316995\n",
      "train loss:0.06375279376329182\n",
      "train loss:0.09154156880602728\n",
      "train loss:0.03143071288620158\n",
      "train loss:0.16109087973279856\n",
      "train loss:0.056078656688643515\n",
      "train loss:0.10456676220102407\n",
      "train loss:0.04526170043706071\n",
      "train loss:0.16986884581048822\n",
      "train loss:0.07390145576984906\n",
      "train loss:0.09536908159817052\n",
      "train loss:0.09154476737978805\n",
      "train loss:0.03405054571000393\n",
      "train loss:0.05515350665659517\n",
      "train loss:0.1063386499146422\n",
      "train loss:0.10043817823250452\n",
      "train loss:0.0755590678258498\n",
      "train loss:0.13466413508899808\n",
      "train loss:0.08031770928278253\n",
      "train loss:0.02464389124975446\n",
      "train loss:0.13987409662456096\n",
      "train loss:0.06149919953078259\n",
      "train loss:0.11359108208932783\n",
      "train loss:0.02549827480590324\n",
      "train loss:0.10501252546442377\n",
      "train loss:0.05157726953775065\n",
      "train loss:0.1167005924202224\n",
      "train loss:0.08993441926675791\n",
      "train loss:0.15904491913019378\n",
      "train loss:0.13674842718151997\n",
      "train loss:0.061317287964130676\n",
      "train loss:0.041596957689748734\n",
      "train loss:0.048545754658843074\n",
      "train loss:0.023609270831328414\n",
      "train loss:0.13041625192708828\n",
      "train loss:0.12205359190507918\n",
      "train loss:0.07257670711747038\n",
      "train loss:0.16758938860124956\n",
      "train loss:0.14916303969295497\n",
      "train loss:0.07708096045810846\n",
      "train loss:0.06448982035224908\n",
      "train loss:0.03394622061457493\n",
      "train loss:0.1172068032790217\n",
      "train loss:0.06683192369642409\n",
      "train loss:0.07263082563671443\n",
      "train loss:0.12399423227177392\n",
      "train loss:0.11063512072230731\n",
      "train loss:0.047934550956600236\n",
      "train loss:0.04322611140590976\n",
      "train loss:0.06382694146202712\n",
      "train loss:0.03633269036079434\n",
      "train loss:0.045030900185607875\n",
      "train loss:0.06917531324533832\n",
      "train loss:0.04057337481448713\n",
      "train loss:0.04383822255989284\n",
      "train loss:0.1418440038365544\n",
      "train loss:0.08415930614804909\n",
      "train loss:0.048304175103778366\n",
      "train loss:0.12731370977994133\n",
      "train loss:0.061865443377484036\n",
      "train loss:0.033050863071188985\n",
      "train loss:0.061875339573072764\n",
      "train loss:0.10103361525400613\n",
      "train loss:0.04685248268557505\n",
      "train loss:0.02560381927675619\n",
      "train loss:0.0769974478548447\n",
      "train loss:0.08213676590957018\n",
      "train loss:0.04775350531104535\n",
      "train loss:0.04844664970691311\n",
      "train loss:0.06093242347967434\n",
      "train loss:0.06661090889445088\n",
      "train loss:0.11792313668122331\n",
      "train loss:0.0502128550213142\n",
      "train loss:0.07936074690760307\n",
      "train loss:0.09455668534840658\n",
      "train loss:0.09368047296118402\n",
      "train loss:0.028755799764811477\n",
      "train loss:0.07819680809509946\n",
      "train loss:0.04009232550171762\n",
      "train loss:0.06468015777854526\n",
      "train loss:0.0741329290383934\n",
      "train loss:0.06398047188839084\n",
      "train loss:0.08460760262351114\n",
      "train loss:0.09323727071221118\n",
      "train loss:0.03230606248945069\n",
      "train loss:0.10288730766731977\n",
      "train loss:0.08402275072764283\n",
      "train loss:0.08250735179192156\n",
      "train loss:0.09299385610097094\n",
      "train loss:0.08612923128522365\n",
      "train loss:0.06428936351960891\n",
      "train loss:0.11466727535987492\n",
      "train loss:0.08983972576519482\n",
      "train loss:0.04053183506430435\n",
      "train loss:0.024194562863343653\n",
      "train loss:0.03843122602214914\n",
      "train loss:0.0629023374330024\n",
      "train loss:0.041056494029786866\n",
      "train loss:0.12154267235285843\n",
      "train loss:0.08632666606918069\n",
      "train loss:0.040302825268596125\n",
      "train loss:0.11031221623207571\n",
      "train loss:0.03308099566670919\n",
      "train loss:0.02055426517126717\n",
      "train loss:0.09408732789143365\n",
      "train loss:0.06420188109264637\n",
      "train loss:0.207875359150678\n",
      "train loss:0.176737972730402\n",
      "train loss:0.07334327934805915\n",
      "train loss:0.12698614645671666\n",
      "train loss:0.11864001100833274\n",
      "train loss:0.043270900646102665\n",
      "train loss:0.06027322607017121\n",
      "train loss:0.08330231011355765\n",
      "train loss:0.17346886352058458\n",
      "train loss:0.0540361348915888\n",
      "train loss:0.05033488374833827\n",
      "train loss:0.169878399377896\n",
      "train loss:0.11884618666050115\n",
      "train loss:0.03540389709146689\n",
      "train loss:0.12955564887062948\n",
      "train loss:0.08966460543714015\n",
      "train loss:0.043890381777129145\n",
      "train loss:0.16422881758178115\n",
      "train loss:0.13087769788770123\n",
      "train loss:0.03975055838480215\n",
      "train loss:0.14614503476789745\n",
      "train loss:0.0562673925761549\n",
      "train loss:0.06653149275022904\n",
      "train loss:0.06426263397876382\n",
      "train loss:0.09803998514714038\n",
      "train loss:0.05806676163576591\n",
      "train loss:0.08272751828632316\n",
      "train loss:0.06376065745168111\n",
      "train loss:0.05811627890100117\n",
      "train loss:0.09937879595172178\n",
      "train loss:0.07387899220575288\n",
      "train loss:0.08994354540031496\n",
      "train loss:0.08034287691537337\n",
      "train loss:0.21193163150059124\n",
      "train loss:0.13015622346272246\n",
      "train loss:0.07900806667811412\n",
      "train loss:0.07024809493969306\n",
      "train loss:0.09132367093864457\n",
      "train loss:0.09529149472308646\n",
      "train loss:0.17665399090467548\n",
      "train loss:0.06727880696182192\n",
      "train loss:0.057281023296511656\n",
      "train loss:0.034767990389038765\n",
      "train loss:0.15995100402751342\n",
      "train loss:0.09135087449158558\n",
      "train loss:0.0544685345468839\n",
      "train loss:0.03802294980085805\n",
      "train loss:0.1074219505731881\n",
      "train loss:0.1618539661965147\n",
      "train loss:0.10202059047379006\n",
      "train loss:0.02819345586952032\n",
      "train loss:0.1824052507851918\n",
      "train loss:0.09033361807269764\n",
      "train loss:0.06151509397816483\n",
      "train loss:0.07749910824649549\n",
      "train loss:0.0580196222373296\n",
      "train loss:0.06865610892375291\n",
      "train loss:0.11625590615883542\n",
      "train loss:0.03759796110817478\n",
      "train loss:0.04199434619424707\n",
      "train loss:0.0382185845391606\n",
      "train loss:0.09952514249802691\n",
      "train loss:0.06936117558565032\n",
      "train loss:0.11232101445382738\n",
      "train loss:0.09031181331050263\n",
      "train loss:0.08383985291119683\n",
      "train loss:0.0370088309134675\n",
      "train loss:0.009016484331521144\n",
      "train loss:0.07783472805062598\n",
      "train loss:0.028164054612421295\n",
      "train loss:0.044647443731916606\n",
      "train loss:0.13813554964957456\n",
      "train loss:0.08497058713070053\n",
      "train loss:0.03915381857489384\n",
      "train loss:0.04923685582636405\n",
      "train loss:0.07458285820876745\n",
      "train loss:0.12888232909272337\n",
      "train loss:0.05333379420661152\n",
      "train loss:0.06047145616410263\n",
      "train loss:0.05139718731107662\n",
      "train loss:0.08837540717451697\n",
      "train loss:0.078012431701253\n",
      "train loss:0.04004888429011873\n",
      "train loss:0.08076510972457457\n",
      "train loss:0.0470989957362806\n",
      "train loss:0.04920606309644957\n",
      "train loss:0.070134194169917\n",
      "train loss:0.051909630139903976\n",
      "train loss:0.08574121602167058\n",
      "train loss:0.06397767915830439\n",
      "train loss:0.07729804506375423\n",
      "train loss:0.04814990583652246\n",
      "train loss:0.08274115007509529\n",
      "train loss:0.16376281697401524\n",
      "train loss:0.039488354495221256\n",
      "train loss:0.07050749802697515\n",
      "train loss:0.0461045296085136\n",
      "train loss:0.060948386026293724\n",
      "train loss:0.01663920480573239\n",
      "train loss:0.011010681520948487\n",
      "train loss:0.09349041386921426\n",
      "train loss:0.03413689120749806\n",
      "train loss:0.08155882594394175\n",
      "train loss:0.1039042186102262\n",
      "train loss:0.05768768848252529\n",
      "train loss:0.040075622160478136\n",
      "train loss:0.11611732357545844\n",
      "train loss:0.05335246447085801\n",
      "train loss:0.03910855854341887\n",
      "train loss:0.015081852161074431\n",
      "train loss:0.024806147857241095\n",
      "train loss:0.06813257234371323\n",
      "train loss:0.03815308414425958\n",
      "train loss:0.09782483728619307\n",
      "train loss:0.06551088623934598\n",
      "train loss:0.027902741268181996\n",
      "train loss:0.06284483240563742\n",
      "train loss:0.06702473491194597\n",
      "train loss:0.028808666062816693\n",
      "train loss:0.06885828157028899\n",
      "train loss:0.030977478596583684\n",
      "train loss:0.04161564769935763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.02273524925508685\n",
      "train loss:0.03419199033338103\n",
      "train loss:0.06616215033035394\n",
      "train loss:0.06633955016332639\n",
      "train loss:0.09643286788086297\n",
      "train loss:0.01045656373262138\n",
      "train loss:0.027308694713000074\n",
      "train loss:0.07486182353350747\n",
      "train loss:0.1133001294240194\n",
      "train loss:0.05919908181333191\n",
      "train loss:0.09800578956971631\n",
      "train loss:0.15098070962832114\n",
      "train loss:0.03449533770423143\n",
      "train loss:0.07104030295841869\n",
      "train loss:0.037006911456532315\n",
      "train loss:0.09590431430514566\n",
      "train loss:0.06587266643667006\n",
      "train loss:0.17754250374105993\n",
      "train loss:0.0856315861500912\n",
      "train loss:0.04511888717325802\n",
      "train loss:0.05474402604405346\n",
      "train loss:0.053061201969188815\n",
      "train loss:0.12418503806363444\n",
      "train loss:0.017302184664399468\n",
      "train loss:0.023634896293515915\n",
      "train loss:0.07407285977268291\n",
      "train loss:0.05740044387844884\n",
      "train loss:0.03555071380573414\n",
      "train loss:0.0744580527487526\n",
      "train loss:0.051786403153371525\n",
      "train loss:0.07179829821987303\n",
      "train loss:0.031805593796947466\n",
      "train loss:0.02557120779110603\n",
      "train loss:0.05827236313884633\n",
      "train loss:0.07183237748257279\n",
      "train loss:0.01973524323293139\n",
      "train loss:0.05237635313660658\n",
      "train loss:0.049402251962976075\n",
      "train loss:0.0580606818147386\n",
      "train loss:0.08445515692784564\n",
      "train loss:0.04236281820201335\n",
      "train loss:0.10208925230185718\n",
      "train loss:0.06958316114885214\n",
      "train loss:0.09451687713930487\n",
      "train loss:0.07279827407181029\n",
      "train loss:0.14430859565706491\n",
      "train loss:0.03667846775642757\n",
      "train loss:0.1397167727192669\n",
      "train loss:0.156801507497538\n",
      "train loss:0.056905950322452596\n",
      "train loss:0.06114139569956218\n",
      "train loss:0.036616347209425734\n",
      "train loss:0.0409946368765029\n",
      "train loss:0.1097681987930029\n",
      "train loss:0.03422278253489818\n",
      "train loss:0.0477695537673067\n",
      "train loss:0.012234630099431194\n",
      "train loss:0.11862837637574838\n",
      "train loss:0.07699877742045526\n",
      "train loss:0.0900405462881734\n",
      "train loss:0.08279815821309368\n",
      "train loss:0.057293365332284116\n",
      "train loss:0.03889013530038816\n",
      "train loss:0.07727933467029183\n",
      "train loss:0.029384112705924056\n",
      "train loss:0.053474412510020206\n",
      "train loss:0.04554668663951165\n",
      "train loss:0.06640969231652508\n",
      "train loss:0.08303132631592541\n",
      "train loss:0.012977808406553335\n",
      "train loss:0.05031932205951379\n",
      "train loss:0.11406433290947295\n",
      "train loss:0.03294734957385219\n",
      "train loss:0.1184732187742246\n",
      "train loss:0.04228350086036469\n",
      "train loss:0.13031664060958034\n",
      "train loss:0.0987102318617257\n",
      "train loss:0.008056570889825419\n",
      "train loss:0.028032055757563207\n",
      "train loss:0.12564113609178088\n",
      "train loss:0.030724994739773134\n",
      "train loss:0.10189039306687774\n",
      "train loss:0.0380529006377069\n",
      "train loss:0.050036242264502956\n",
      "train loss:0.04839325144435024\n",
      "train loss:0.05015325830550361\n",
      "train loss:0.07517537921579574\n",
      "train loss:0.03594844076034034\n",
      "train loss:0.02514812508073646\n",
      "train loss:0.1034897352460293\n",
      "train loss:0.07953574139133013\n",
      "train loss:0.047949176942475\n",
      "train loss:0.13612358801152571\n",
      "train loss:0.03554084282664033\n",
      "train loss:0.07941146128177806\n",
      "train loss:0.06486103698083831\n",
      "train loss:0.06226359908168894\n",
      "train loss:0.026065971494797027\n",
      "train loss:0.10908494409980211\n",
      "train loss:0.08259933813603759\n",
      "train loss:0.027084460650121288\n",
      "train loss:0.01608300686137322\n",
      "train loss:0.06744925316756682\n",
      "train loss:0.08983765561140303\n",
      "train loss:0.06717061068345555\n",
      "train loss:0.10861962518377558\n",
      "train loss:0.024955843020609037\n",
      "train loss:0.034611529505476024\n",
      "train loss:0.0483248529760351\n",
      "train loss:0.027318819705444232\n",
      "train loss:0.09650977881888288\n",
      "train loss:0.05144030326356867\n",
      "train loss:0.06186273121372783\n",
      "train loss:0.024400747207682864\n",
      "train loss:0.04604189219941104\n",
      "train loss:0.042982618074069744\n",
      "train loss:0.07271426716156876\n",
      "train loss:0.04357170417537165\n",
      "train loss:0.02955590538343462\n",
      "train loss:0.06527251393772607\n",
      "train loss:0.025447894966997554\n",
      "train loss:0.04943916200608659\n",
      "train loss:0.037459315014705986\n",
      "train loss:0.054603206292508685\n",
      "train loss:0.046465298938616756\n",
      "train loss:0.12578364249779192\n",
      "train loss:0.09222902936606456\n",
      "train loss:0.05533355789199262\n",
      "train loss:0.04181856942860216\n",
      "train loss:0.08251620684354725\n",
      "train loss:0.06479683450826108\n",
      "train loss:0.044371600335467214\n",
      "train loss:0.054162812995620445\n",
      "train loss:0.05978538802835569\n",
      "train loss:0.11354184717198956\n",
      "train loss:0.10373317781622303\n",
      "=== epoch:3, train acc:0.969, test acc:0.973 ===\n",
      "train loss:0.07213833743508108\n",
      "train loss:0.08097028442159739\n",
      "train loss:0.10517678780861077\n",
      "train loss:0.02851734522578973\n",
      "train loss:0.06588403514441332\n",
      "train loss:0.11815657006359313\n",
      "train loss:0.05504069905412016\n",
      "train loss:0.053544511215734295\n",
      "train loss:0.03543224532033044\n",
      "train loss:0.06556973436858525\n",
      "train loss:0.11559630665675666\n",
      "train loss:0.03345521174157799\n",
      "train loss:0.047171899104936396\n",
      "train loss:0.10920689418319636\n",
      "train loss:0.03350304135879182\n",
      "train loss:0.037996227073571746\n",
      "train loss:0.11057064962981542\n",
      "train loss:0.017446181887116906\n",
      "train loss:0.014566859430656467\n",
      "train loss:0.045271014806201985\n",
      "train loss:0.016992076347407934\n",
      "train loss:0.12697508882804384\n",
      "train loss:0.09663165405736096\n",
      "train loss:0.03365109801255067\n",
      "train loss:0.06653830873612974\n",
      "train loss:0.10536171439005355\n",
      "train loss:0.0971353981530685\n",
      "train loss:0.056180072539541076\n",
      "train loss:0.11371044321417507\n",
      "train loss:0.04738084791984587\n",
      "train loss:0.10017586933596029\n",
      "train loss:0.07689306940400412\n",
      "train loss:0.059325186365398824\n",
      "train loss:0.03123722977316154\n",
      "train loss:0.04001197146786688\n",
      "train loss:0.04900088097541807\n",
      "train loss:0.10422927020328453\n",
      "train loss:0.056912653360195326\n",
      "train loss:0.03939842993308417\n",
      "train loss:0.059462187476660704\n",
      "train loss:0.029491788331127346\n",
      "train loss:0.028437343412530253\n",
      "train loss:0.04691466285961279\n",
      "train loss:0.05561730643700227\n",
      "train loss:0.09787660587049532\n",
      "train loss:0.05770172443130555\n",
      "train loss:0.019551460025327948\n",
      "train loss:0.034875162873220227\n",
      "train loss:0.026487928178184846\n",
      "train loss:0.05711170334373338\n",
      "train loss:0.07948421287999852\n",
      "train loss:0.04902926033126147\n",
      "train loss:0.03204107101701768\n",
      "train loss:0.13040887864921416\n",
      "train loss:0.09856089875586958\n",
      "train loss:0.015173771492621368\n",
      "train loss:0.015845986810658422\n",
      "train loss:0.06922690236146577\n",
      "train loss:0.061171232515727286\n",
      "train loss:0.02445341564512633\n",
      "train loss:0.14244104785535003\n",
      "train loss:0.07715365996360406\n",
      "train loss:0.05231292014704758\n",
      "train loss:0.06578014954485\n",
      "train loss:0.022266630840781412\n",
      "train loss:0.03149729183096356\n",
      "train loss:0.05289356147728312\n",
      "train loss:0.036717765837300805\n",
      "train loss:0.04401144991473994\n",
      "train loss:0.02023675774428425\n",
      "train loss:0.08034889334399281\n",
      "train loss:0.019154911595993016\n",
      "train loss:0.0797964122396877\n",
      "train loss:0.030441998986142547\n",
      "train loss:0.043327810954500376\n",
      "train loss:0.140049384817311\n",
      "train loss:0.060814465148891605\n",
      "train loss:0.1373516165376368\n",
      "train loss:0.02139762840232197\n",
      "train loss:0.02530196245170367\n",
      "train loss:0.02899324395625878\n",
      "train loss:0.01682763457535168\n",
      "train loss:0.07500368360193653\n",
      "train loss:0.04762209735566681\n",
      "train loss:0.029186455738570875\n",
      "train loss:0.027703611910059562\n",
      "train loss:0.04280591409350198\n",
      "train loss:0.04894047206686621\n",
      "train loss:0.04093165247680214\n",
      "train loss:0.10241713098153415\n",
      "train loss:0.02139332568971305\n",
      "train loss:0.015141317050401693\n",
      "train loss:0.0751503428256749\n",
      "train loss:0.04929161282183632\n",
      "train loss:0.030211215445167583\n",
      "train loss:0.021583903491563725\n",
      "train loss:0.03392853294308105\n",
      "train loss:0.07811475629527273\n",
      "train loss:0.02667699393565623\n",
      "train loss:0.07430897986479688\n",
      "train loss:0.04376456491916961\n",
      "train loss:0.0230603529006488\n",
      "train loss:0.08592187963387078\n",
      "train loss:0.06244375748311184\n",
      "train loss:0.05067787001602385\n",
      "train loss:0.021852522991466398\n",
      "train loss:0.00885330858351008\n",
      "train loss:0.03891608110836231\n",
      "train loss:0.03933117361978475\n",
      "train loss:0.032859127566493146\n",
      "train loss:0.18083632627308144\n",
      "train loss:0.026486892813637777\n",
      "train loss:0.07283911778557126\n",
      "train loss:0.05659779908960074\n",
      "train loss:0.0614499642712921\n",
      "train loss:0.017520366329264275\n",
      "train loss:0.041774790778780296\n",
      "train loss:0.04868456712890863\n",
      "train loss:0.04944844550957754\n",
      "train loss:0.09780224003344681\n",
      "train loss:0.03819425617016475\n",
      "train loss:0.06931339885820693\n",
      "train loss:0.03127928910530075\n",
      "train loss:0.07839845404176425\n",
      "train loss:0.07245311440352686\n",
      "train loss:0.028673940033414804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.09600581640480525\n",
      "train loss:0.04836162899752011\n",
      "train loss:0.03746753419560392\n",
      "train loss:0.016646142234524583\n",
      "train loss:0.12138949935321668\n",
      "train loss:0.023090285879579585\n",
      "train loss:0.023147625237175777\n",
      "train loss:0.08057204259562852\n",
      "train loss:0.06434756924480174\n",
      "train loss:0.011898840150145085\n",
      "train loss:0.013512408452412679\n",
      "train loss:0.11435051819281218\n",
      "train loss:0.0419822870912195\n",
      "train loss:0.04321153938974168\n",
      "train loss:0.006650385786891643\n",
      "train loss:0.05513406472669526\n",
      "train loss:0.07963277124681506\n",
      "train loss:0.005889901901493608\n",
      "train loss:0.019428960891601673\n",
      "train loss:0.04898416504822967\n",
      "train loss:0.07149137761121116\n",
      "train loss:0.09549620202136432\n",
      "train loss:0.10092303893470586\n",
      "train loss:0.028039734219308773\n",
      "train loss:0.019346989632856467\n",
      "train loss:0.07762768638175457\n",
      "train loss:0.023689398097277506\n",
      "train loss:0.028784108203574424\n",
      "train loss:0.05398559999402859\n",
      "train loss:0.027629726443045823\n",
      "train loss:0.06423302798411581\n",
      "train loss:0.05518700330328686\n",
      "train loss:0.018806831957871105\n",
      "train loss:0.05175341286732373\n",
      "train loss:0.011142816416869697\n",
      "train loss:0.021026234628881636\n",
      "train loss:0.019714264344524893\n",
      "train loss:0.059035415966187464\n",
      "train loss:0.047774079841963\n",
      "train loss:0.09648117057827596\n",
      "train loss:0.04555422006345702\n",
      "train loss:0.08926276358996121\n",
      "train loss:0.060600350586628514\n",
      "train loss:0.0544515016579502\n",
      "train loss:0.10738137859102218\n",
      "train loss:0.018006680033382863\n",
      "train loss:0.05248658383288465\n",
      "train loss:0.030150607838863898\n",
      "train loss:0.0789402902624975\n",
      "train loss:0.07587041662015019\n",
      "train loss:0.025811693250754074\n",
      "train loss:0.030405665358061208\n",
      "train loss:0.14969484915051054\n",
      "train loss:0.06458973397669582\n",
      "train loss:0.07550704633463319\n",
      "train loss:0.03033395118708486\n",
      "train loss:0.133676447607823\n",
      "train loss:0.02539227723523031\n",
      "train loss:0.04349544020226915\n",
      "train loss:0.11347825912819502\n",
      "train loss:0.04883082468535441\n",
      "train loss:0.04386901266260928\n",
      "train loss:0.05534601425875868\n",
      "train loss:0.04377537831581867\n",
      "train loss:0.06864186302283212\n",
      "train loss:0.05616933024828631\n",
      "train loss:0.029448131214605502\n",
      "train loss:0.07294465317483773\n",
      "train loss:0.020957436346430783\n",
      "train loss:0.06420177265936593\n",
      "train loss:0.07874856466095605\n",
      "train loss:0.11477815303201236\n",
      "train loss:0.05114198424186713\n",
      "train loss:0.05442281556043075\n",
      "train loss:0.06459637369190113\n",
      "train loss:0.01750310295858358\n",
      "train loss:0.05382370829293086\n",
      "train loss:0.048988166218871934\n",
      "train loss:0.03880589465073473\n",
      "train loss:0.13455534703821784\n",
      "train loss:0.054616097589073834\n",
      "train loss:0.0410708711829665\n",
      "train loss:0.033408418385936625\n",
      "train loss:0.05613238287281022\n",
      "train loss:0.034107029076561046\n",
      "train loss:0.012519886353776686\n",
      "train loss:0.03535329466830328\n",
      "train loss:0.0447249921296168\n",
      "train loss:0.02327138362600158\n",
      "train loss:0.06727685391643327\n",
      "train loss:0.05147368963131385\n",
      "train loss:0.018448632524782793\n",
      "train loss:0.012971939355669967\n",
      "train loss:0.013372752545067264\n",
      "train loss:0.056682999084782276\n",
      "train loss:0.12976744681626867\n",
      "train loss:0.07666337280388864\n",
      "train loss:0.10464930824276651\n",
      "train loss:0.09427118801084511\n",
      "train loss:0.02653171371176932\n",
      "train loss:0.042006982735475304\n",
      "train loss:0.04735957140738629\n",
      "train loss:0.05098691697555616\n",
      "train loss:0.008139075719358388\n",
      "train loss:0.09172435761065602\n",
      "train loss:0.1229843963050726\n",
      "train loss:0.03258937429550971\n",
      "train loss:0.031141873196166205\n",
      "train loss:0.00533158780417978\n",
      "train loss:0.04082518101723374\n",
      "train loss:0.017726610255708465\n",
      "train loss:0.045032624339302246\n",
      "train loss:0.05553271347486364\n",
      "train loss:0.035596041874319424\n",
      "train loss:0.067509835921131\n",
      "train loss:0.01083868390935043\n",
      "train loss:0.04412056173766577\n",
      "train loss:0.011257352929699226\n",
      "train loss:0.10336353156724706\n",
      "train loss:0.021289948661897994\n",
      "train loss:0.049385970278472476\n",
      "train loss:0.0745100695871221\n",
      "train loss:0.02697562794523209\n",
      "train loss:0.03379242593630808\n",
      "train loss:0.06382385406344679\n",
      "train loss:0.07498721153110884\n",
      "train loss:0.09749366585103733\n",
      "train loss:0.043147982007965824\n",
      "train loss:0.02430269214984365\n",
      "train loss:0.03396970500385494\n",
      "train loss:0.11077637348702689\n",
      "train loss:0.053044622012797464\n",
      "train loss:0.04079437222370188\n",
      "train loss:0.05155568074540999\n",
      "train loss:0.02776413350320345\n",
      "train loss:0.07573538222320239\n",
      "train loss:0.021193588323886164\n",
      "train loss:0.06265787257271295\n",
      "train loss:0.052854684891136955\n",
      "train loss:0.06802914296693252\n",
      "train loss:0.030767859948569624\n",
      "train loss:0.05168979093679058\n",
      "train loss:0.022382505266459077\n",
      "train loss:0.016016964166960558\n",
      "train loss:0.023008272354486502\n",
      "train loss:0.03102456141118999\n",
      "train loss:0.07633565574170413\n",
      "train loss:0.029229012346664907\n",
      "train loss:0.02185420424705272\n",
      "train loss:0.029934529443750107\n",
      "train loss:0.07229839990647931\n",
      "train loss:0.05953029343678165\n",
      "train loss:0.04565472108785628\n",
      "train loss:0.04788079641978711\n",
      "train loss:0.010584828825928129\n",
      "train loss:0.05031832395962536\n",
      "train loss:0.11843809697297016\n",
      "train loss:0.05573991803393664\n",
      "train loss:0.03550634369872455\n",
      "train loss:0.055041480524081254\n",
      "train loss:0.012804763981206183\n",
      "train loss:0.021843685638147706\n",
      "train loss:0.0308189987108365\n",
      "train loss:0.03231097490871721\n",
      "train loss:0.012449702881978357\n",
      "train loss:0.05722947702461548\n",
      "train loss:0.0941311189888736\n",
      "train loss:0.048068698153649746\n",
      "train loss:0.024774335530307424\n",
      "train loss:0.06666154985075004\n",
      "train loss:0.0687873611788909\n",
      "train loss:0.13763684359127942\n",
      "train loss:0.0605452677627503\n",
      "train loss:0.02338421887128383\n",
      "train loss:0.05554112337300704\n",
      "train loss:0.01301365270093209\n",
      "train loss:0.04491903086796853\n",
      "train loss:0.1166966681921707\n",
      "train loss:0.08277077601163796\n",
      "train loss:0.021687244866843803\n",
      "train loss:0.11064289296475399\n",
      "train loss:0.10182125331961721\n",
      "train loss:0.05447641998876576\n",
      "train loss:0.11659955294805573\n",
      "train loss:0.00942039839589965\n",
      "train loss:0.029567094442203828\n",
      "train loss:0.015997326673676912\n",
      "train loss:0.05486142016792657\n",
      "train loss:0.2823077234272196\n",
      "train loss:0.139325376008644\n",
      "train loss:0.061891703147388684\n",
      "train loss:0.06560707829925062\n",
      "train loss:0.03613529401167281\n",
      "train loss:0.02468426920228231\n",
      "train loss:0.030611648030826673\n",
      "train loss:0.10602849558546686\n",
      "train loss:0.05500261900639881\n",
      "train loss:0.059869504892531726\n",
      "train loss:0.04969075583213453\n",
      "train loss:0.06111185103676096\n",
      "train loss:0.26556697146803127\n",
      "train loss:0.05595855793327438\n",
      "train loss:0.04176765510957459\n",
      "train loss:0.11185278380144237\n",
      "train loss:0.08040110693193146\n",
      "train loss:0.06472418258250688\n",
      "train loss:0.060163090345099236\n",
      "train loss:0.05037113337264351\n",
      "train loss:0.01918307938060363\n",
      "train loss:0.04016127929909433\n",
      "train loss:0.05746903880120477\n",
      "train loss:0.015857734458873906\n",
      "train loss:0.08617327478773452\n",
      "train loss:0.022837085724204242\n",
      "train loss:0.013518326771276776\n",
      "train loss:0.062383806005449724\n",
      "train loss:0.07135615901408922\n",
      "train loss:0.022647582596402177\n",
      "train loss:0.05391013534774205\n",
      "train loss:0.04896159841052231\n",
      "train loss:0.08079606043252997\n",
      "train loss:0.043188859757986\n",
      "train loss:0.14703203296858194\n",
      "train loss:0.014716661199618406\n",
      "train loss:0.10505333462346252\n",
      "train loss:0.04829805849275859\n",
      "train loss:0.05653004190413866\n",
      "train loss:0.03168577028941408\n",
      "train loss:0.04490523114345423\n",
      "train loss:0.07046217191045359\n",
      "train loss:0.06622610444520131\n",
      "train loss:0.02963687280145082\n",
      "train loss:0.08689235587127671\n",
      "train loss:0.05748955540962077\n",
      "train loss:0.03228997803899226\n",
      "train loss:0.060017233175088565\n",
      "train loss:0.02891252233114818\n",
      "train loss:0.07057797464857918\n",
      "train loss:0.00965109045894292\n",
      "train loss:0.021661049203109052\n",
      "train loss:0.013839456532527803\n",
      "train loss:0.045950836833736276\n",
      "train loss:0.048743186199173255\n",
      "train loss:0.04711260740872632\n",
      "train loss:0.19166173673034834\n",
      "train loss:0.062145905000597974\n",
      "train loss:0.07755225294398846\n",
      "train loss:0.03004376787122094\n",
      "train loss:0.023687022021636493\n",
      "train loss:0.013982706428159459\n",
      "train loss:0.17931813538725486\n",
      "train loss:0.027334189892277427\n",
      "train loss:0.07693036796898937\n",
      "train loss:0.04281496150210653\n",
      "train loss:0.05529160288719373\n",
      "train loss:0.05818073392594529\n",
      "train loss:0.02508445422818014\n",
      "train loss:0.017296544709128735\n",
      "train loss:0.06564147348571062\n",
      "train loss:0.034908003031862284\n",
      "train loss:0.040231358244066706\n",
      "train loss:0.023120865510228933\n",
      "train loss:0.023963936373353527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.04082151990810034\n",
      "train loss:0.041709547983894285\n",
      "train loss:0.03651015165522644\n",
      "train loss:0.011392328597894519\n",
      "train loss:0.10230642130812255\n",
      "train loss:0.012918631972675293\n",
      "train loss:0.020887197290851853\n",
      "train loss:0.0626621079105133\n",
      "train loss:0.11296823982441839\n",
      "train loss:0.05508427827621103\n",
      "train loss:0.06291454296059923\n",
      "train loss:0.03582179714105995\n",
      "train loss:0.028593699224999266\n",
      "train loss:0.09670474128630556\n",
      "train loss:0.09855890590491134\n",
      "train loss:0.04366365389821691\n",
      "train loss:0.032660120881506695\n",
      "train loss:0.06578620994967366\n",
      "train loss:0.10351437633556566\n",
      "train loss:0.019843098961490727\n",
      "train loss:0.04199999260851004\n",
      "train loss:0.04667517976228226\n",
      "train loss:0.03649424543635377\n",
      "train loss:0.055941058473236376\n",
      "train loss:0.14287883753494238\n",
      "train loss:0.03346123687939138\n",
      "train loss:0.04325202775863216\n",
      "train loss:0.03171264533567568\n",
      "train loss:0.022676311514042785\n",
      "train loss:0.04939128350940008\n",
      "train loss:0.09705019344253861\n",
      "train loss:0.021983214524632824\n",
      "train loss:0.03985672051710871\n",
      "train loss:0.07898856484710698\n",
      "train loss:0.021536046259602527\n",
      "train loss:0.018709589735449023\n",
      "train loss:0.02264961673622054\n",
      "train loss:0.023361699075423282\n",
      "train loss:0.0074051256861709346\n",
      "train loss:0.062506857100874\n",
      "train loss:0.03804578992300185\n",
      "train loss:0.0454560042964957\n",
      "train loss:0.024139030056004068\n",
      "train loss:0.07391897804665416\n",
      "train loss:0.037026279797966744\n",
      "train loss:0.018921392900001558\n",
      "train loss:0.048828797215717507\n",
      "train loss:0.02671590617439095\n",
      "train loss:0.04929037663054011\n",
      "train loss:0.11332497752884468\n",
      "train loss:0.11592677389252921\n",
      "train loss:0.05702604239655269\n",
      "train loss:0.04613991554811852\n",
      "train loss:0.028495179488029553\n",
      "train loss:0.02343674652552998\n",
      "train loss:0.015559129753795687\n",
      "train loss:0.08031852664037373\n",
      "train loss:0.03483230565753526\n",
      "train loss:0.09384231332870936\n",
      "train loss:0.04902604568621673\n",
      "train loss:0.041543040564887106\n",
      "train loss:0.050917422440316606\n",
      "train loss:0.04056003790159333\n",
      "train loss:0.039750452460157515\n",
      "train loss:0.033936615988367815\n",
      "train loss:0.03867841545810282\n",
      "train loss:0.0739017216068554\n",
      "train loss:0.06846216700946227\n",
      "train loss:0.024167694602424215\n",
      "train loss:0.02853862064740022\n",
      "train loss:0.015180882071487524\n",
      "train loss:0.04227991309430317\n",
      "train loss:0.039701324026384446\n",
      "train loss:0.06897135711828092\n",
      "train loss:0.05749984272459553\n",
      "train loss:0.05017125278069466\n",
      "train loss:0.056958521973026616\n",
      "train loss:0.01927242339323517\n",
      "train loss:0.024525342753763314\n",
      "train loss:0.02470348001580568\n",
      "train loss:0.08832468294906409\n",
      "train loss:0.01644002321306206\n",
      "train loss:0.009955170962517598\n",
      "train loss:0.023283077958749055\n",
      "train loss:0.035229329559179456\n",
      "train loss:0.0725759851336596\n",
      "train loss:0.03691638802952873\n",
      "train loss:0.03883539211752779\n",
      "train loss:0.04881502245479001\n",
      "train loss:0.043994588374993364\n",
      "train loss:0.029621709354549094\n",
      "train loss:0.03869037010178879\n",
      "train loss:0.09110708253306254\n",
      "train loss:0.025173486445216803\n",
      "train loss:0.03266071000981647\n",
      "train loss:0.021292248346050847\n",
      "train loss:0.033016088592873284\n",
      "train loss:0.008009077427684528\n",
      "train loss:0.01833542390742552\n",
      "train loss:0.026241017597271897\n",
      "train loss:0.02788637722530479\n",
      "train loss:0.030982464485811115\n",
      "train loss:0.07622562036898765\n",
      "train loss:0.05177286771991896\n",
      "train loss:0.03199228336679249\n",
      "train loss:0.030521052238820682\n",
      "train loss:0.03416065144505626\n",
      "train loss:0.013777005166954197\n",
      "train loss:0.030464961981561945\n",
      "train loss:0.03511156135944558\n",
      "train loss:0.029906583106162277\n",
      "train loss:0.005969236819110581\n",
      "train loss:0.02175569278677178\n",
      "train loss:0.013464229012086803\n",
      "train loss:0.03708156389653002\n",
      "train loss:0.028490760993855044\n",
      "train loss:0.01604388624394429\n",
      "train loss:0.03119523826967709\n",
      "train loss:0.061785694745423086\n",
      "train loss:0.08741456414187121\n",
      "train loss:0.04108737885158042\n",
      "train loss:0.03227172755193604\n",
      "train loss:0.023843166028291868\n",
      "train loss:0.056853203796231586\n",
      "train loss:0.0322593810863115\n",
      "train loss:0.06469447564571999\n",
      "train loss:0.04970251041490204\n",
      "train loss:0.03582414217891908\n",
      "train loss:0.08057328666112587\n",
      "train loss:0.05638503976862188\n",
      "train loss:0.0850228125248295\n",
      "train loss:0.013989191733884602\n",
      "train loss:0.018077317705186405\n",
      "train loss:0.02826785169439692\n",
      "train loss:0.07014202865983545\n",
      "train loss:0.02377321833558864\n",
      "train loss:0.018525281785020553\n",
      "train loss:0.02341352094092129\n",
      "train loss:0.03921112780183587\n",
      "train loss:0.028736491000458355\n",
      "train loss:0.08636701950367812\n",
      "train loss:0.058351130978006864\n",
      "train loss:0.043623860701757396\n",
      "train loss:0.04842538337503635\n",
      "train loss:0.025412615397893887\n",
      "train loss:0.027850172165201928\n",
      "train loss:0.017804240808574578\n",
      "train loss:0.04197293321004622\n",
      "train loss:0.027281063934598327\n",
      "train loss:0.06138691422971198\n",
      "train loss:0.035287579361531304\n",
      "train loss:0.059796229595169906\n",
      "train loss:0.060628409913348585\n",
      "train loss:0.06593867957083294\n",
      "train loss:0.06849722492499602\n",
      "train loss:0.0755428052737579\n",
      "train loss:0.04081445174829451\n",
      "train loss:0.1044762434044164\n",
      "train loss:0.03891262146132579\n",
      "train loss:0.0750664900725888\n",
      "train loss:0.04636988804881547\n",
      "train loss:0.03047577905735404\n",
      "train loss:0.04697877934857719\n",
      "train loss:0.02907800057415328\n",
      "train loss:0.04651217473487507\n",
      "train loss:0.015415504155543902\n",
      "train loss:0.06484495723235477\n",
      "train loss:0.021041248445170017\n",
      "train loss:0.023735960366703796\n",
      "train loss:0.03740811977468792\n",
      "train loss:0.11319772879904959\n",
      "train loss:0.01967167857332048\n",
      "train loss:0.04972231072604086\n",
      "train loss:0.022726299175706396\n",
      "train loss:0.0656590468475759\n",
      "train loss:0.07730198533468725\n",
      "train loss:0.015821398416684777\n",
      "train loss:0.06294899820948414\n",
      "train loss:0.03684125262322988\n",
      "train loss:0.021900517287523322\n",
      "train loss:0.05706626219563939\n",
      "train loss:0.05060381434728239\n",
      "train loss:0.06543298917882175\n",
      "train loss:0.01965229765679222\n",
      "train loss:0.021565431925522533\n",
      "train loss:0.053326617560919394\n",
      "train loss:0.013434454471352952\n",
      "train loss:0.07285266710022452\n",
      "train loss:0.06298264339582242\n",
      "train loss:0.020102696425324373\n",
      "train loss:0.038643070283883814\n",
      "train loss:0.02666414769978446\n",
      "train loss:0.1455183990578632\n",
      "train loss:0.03011550919208119\n",
      "train loss:0.023991151517588637\n",
      "train loss:0.01056967300470101\n",
      "train loss:0.028218800404754742\n",
      "train loss:0.014505613752998517\n",
      "train loss:0.012425494076229353\n",
      "train loss:0.03751086187359101\n",
      "train loss:0.019491752665050783\n",
      "train loss:0.031084432175103857\n",
      "train loss:0.040175239416622516\n",
      "train loss:0.09490452880544653\n",
      "train loss:0.02971534045337349\n",
      "train loss:0.02546498032399046\n",
      "train loss:0.026658114149624726\n",
      "train loss:0.029709743733078352\n",
      "train loss:0.019794642412799376\n",
      "train loss:0.023635763119470465\n",
      "train loss:0.05251956414914938\n",
      "=== epoch:4, train acc:0.98, test acc:0.98 ===\n",
      "train loss:0.07224223090879538\n",
      "train loss:0.012998106041524174\n",
      "train loss:0.015198658885930513\n",
      "train loss:0.012944994971885272\n",
      "train loss:0.10544634986131186\n",
      "train loss:0.10462925369417703\n",
      "train loss:0.03142857480892897\n",
      "train loss:0.034597913567257194\n",
      "train loss:0.03412418180100436\n",
      "train loss:0.029132268964698057\n",
      "train loss:0.03611360897113183\n",
      "train loss:0.009114451166150549\n",
      "train loss:0.09892088503392613\n",
      "train loss:0.03981596446069373\n",
      "train loss:0.03552571674735138\n",
      "train loss:0.09684592735610961\n",
      "train loss:0.07942405411309758\n",
      "train loss:0.028418316903393016\n",
      "train loss:0.016615999623723558\n",
      "train loss:0.0581576075099241\n",
      "train loss:0.016537786623146197\n",
      "train loss:0.1637756919799723\n",
      "train loss:0.057814889989280846\n",
      "train loss:0.18928760541606543\n",
      "train loss:0.029431086122441198\n",
      "train loss:0.03141662067195294\n",
      "train loss:0.04271916604819301\n",
      "train loss:0.010482245173799441\n",
      "train loss:0.025619587680069306\n",
      "train loss:0.04703322347324601\n",
      "train loss:0.09522986684850526\n",
      "train loss:0.03557717955182538\n",
      "train loss:0.013259520283217186\n",
      "train loss:0.04925624978622885\n",
      "train loss:0.07881418973403016\n",
      "train loss:0.11984214906401712\n",
      "train loss:0.08442886710148677\n",
      "train loss:0.02659179808638633\n",
      "train loss:0.04248816833102686\n",
      "train loss:0.02536724865558794\n",
      "train loss:0.048400295728405804\n",
      "train loss:0.05555859674756543\n",
      "train loss:0.031437806873494754\n",
      "train loss:0.08923916237787273\n",
      "train loss:0.03353292568382595\n",
      "train loss:0.10336277659589127\n",
      "train loss:0.04486968061015375\n",
      "train loss:0.030066648929352055\n",
      "train loss:0.03423268348285078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.06119164264662242\n",
      "train loss:0.07368351280949163\n",
      "train loss:0.03882004999721588\n",
      "train loss:0.02458697110969205\n",
      "train loss:0.02550394214047458\n",
      "train loss:0.024689265649232274\n",
      "train loss:0.03330014232203343\n",
      "train loss:0.018799304827395433\n",
      "train loss:0.06692983340573881\n",
      "train loss:0.023342734036746835\n",
      "train loss:0.026899798883342135\n",
      "train loss:0.031240502520363766\n",
      "train loss:0.0618935508179423\n",
      "train loss:0.025038324636458963\n",
      "train loss:0.04083329754186785\n",
      "train loss:0.05096329152271757\n",
      "train loss:0.018660175543751337\n",
      "train loss:0.02762961706064073\n",
      "train loss:0.10401038460610162\n",
      "train loss:0.10365306961605114\n",
      "train loss:0.0753069896672605\n",
      "train loss:0.021541351043567643\n",
      "train loss:0.05245701981544862\n",
      "train loss:0.11397199624602322\n",
      "train loss:0.01762794833833548\n",
      "train loss:0.013470768339787354\n",
      "train loss:0.020029337038729462\n",
      "train loss:0.015951471771976995\n",
      "train loss:0.02734183281906065\n",
      "train loss:0.03688955271893819\n",
      "train loss:0.02304242396117585\n",
      "train loss:0.07605428636330848\n",
      "train loss:0.014972967018425981\n",
      "train loss:0.027394922962129947\n",
      "train loss:0.03416205338085409\n",
      "train loss:0.07430241727298309\n",
      "train loss:0.030440229039507792\n",
      "train loss:0.043327312533079\n",
      "train loss:0.07157591381199546\n",
      "train loss:0.014280974973336913\n",
      "train loss:0.031097664536178727\n",
      "train loss:0.02290776760457728\n",
      "train loss:0.03440956564387299\n",
      "train loss:0.016844656424364782\n",
      "train loss:0.025677080626365936\n",
      "train loss:0.021182601476142673\n",
      "train loss:0.027273273693527594\n",
      "train loss:0.026929889641989408\n",
      "train loss:0.009459575709415956\n",
      "train loss:0.015900770021721092\n",
      "train loss:0.07544397289382014\n",
      "train loss:0.0419184870499871\n",
      "train loss:0.056718142619944685\n",
      "train loss:0.026116917479158133\n",
      "train loss:0.01834661763852568\n",
      "train loss:0.054230741152724485\n",
      "train loss:0.0948539661832764\n",
      "train loss:0.04393925629714645\n",
      "train loss:0.03167332223417037\n",
      "train loss:0.07401655755760166\n",
      "train loss:0.03860065883876536\n",
      "train loss:0.03915136250066086\n",
      "train loss:0.0891254062762394\n",
      "train loss:0.021274196597053822\n",
      "train loss:0.011408062544247843\n",
      "train loss:0.047637608668171565\n",
      "train loss:0.021892341940378177\n",
      "train loss:0.06394039062649914\n",
      "train loss:0.03682838416929118\n",
      "train loss:0.11902351095284767\n",
      "train loss:0.051617894132641444\n",
      "train loss:0.057940748031958166\n",
      "train loss:0.018435450605239302\n",
      "train loss:0.024841101744963918\n",
      "train loss:0.03182700892339703\n",
      "train loss:0.026363203268914927\n",
      "train loss:0.036190745457168834\n",
      "train loss:0.042149072663379174\n",
      "train loss:0.03846357429566385\n",
      "train loss:0.02650670896884046\n",
      "train loss:0.005499943434868839\n",
      "train loss:0.003985397398159762\n",
      "train loss:0.013001438757908964\n",
      "train loss:0.03301844665624104\n",
      "train loss:0.03410290739992222\n",
      "train loss:0.030577240809098308\n",
      "train loss:0.03764918681718236\n",
      "train loss:0.051779666756776116\n",
      "train loss:0.055761069564880576\n",
      "train loss:0.049364471928877655\n",
      "train loss:0.007262949957966144\n",
      "train loss:0.04352507461980915\n",
      "train loss:0.012704309709482324\n",
      "train loss:0.05991107059848327\n",
      "train loss:0.01488462611169852\n",
      "train loss:0.009839348477214533\n",
      "train loss:0.009682005938455824\n",
      "train loss:0.007616896221601082\n",
      "train loss:0.03179798099325071\n",
      "train loss:0.010953553675407209\n",
      "train loss:0.01089539187530959\n",
      "train loss:0.02689449947716662\n",
      "train loss:0.00942034675519075\n",
      "train loss:0.04635811998157041\n",
      "train loss:0.06904794480156169\n",
      "train loss:0.03491949336468138\n",
      "train loss:0.026899245121188617\n",
      "train loss:0.05813048585608367\n",
      "train loss:0.03358835704344758\n",
      "train loss:0.051723357951615555\n",
      "train loss:0.012168631517136905\n",
      "train loss:0.07715155035228193\n",
      "train loss:0.03700400886487564\n",
      "train loss:0.013711033692211218\n",
      "train loss:0.022122815599002633\n",
      "train loss:0.007300989272922923\n",
      "train loss:0.011391123488410195\n",
      "train loss:0.035292727973534756\n",
      "train loss:0.018105672642046586\n",
      "train loss:0.019856426725599403\n",
      "train loss:0.04801282858016191\n",
      "train loss:0.00976398776821154\n",
      "train loss:0.008834757184507517\n",
      "train loss:0.015799773084816\n",
      "train loss:0.009202926277321099\n",
      "train loss:0.05553722773698894\n",
      "train loss:0.01683515647070985\n",
      "train loss:0.018721976914004686\n",
      "train loss:0.008642893555147704\n",
      "train loss:0.010328664882534904\n",
      "train loss:0.05127224096965495\n",
      "train loss:0.004660054333075988\n",
      "train loss:0.06311743211258393\n",
      "train loss:0.04123786640691382\n",
      "train loss:0.018037846386350573\n",
      "train loss:0.04832316993115532\n",
      "train loss:0.01928868447757521\n",
      "train loss:0.05744179385579663\n",
      "train loss:0.08991275625551762\n",
      "train loss:0.019355951462723505\n",
      "train loss:0.03874910644322083\n",
      "train loss:0.09884370994831394\n",
      "train loss:0.04895701867266321\n",
      "train loss:0.03402217863128079\n",
      "train loss:0.019000769721213714\n",
      "train loss:0.03169766043962177\n",
      "train loss:0.007700614287655561\n",
      "train loss:0.017453695168646404\n",
      "train loss:0.015759835217749926\n",
      "train loss:0.022855843361232555\n",
      "train loss:0.09003853583260167\n",
      "train loss:0.03113075915748628\n",
      "train loss:0.014904402922660265\n",
      "train loss:0.06667418351372759\n",
      "train loss:0.04964247367144083\n",
      "train loss:0.01758197994253588\n",
      "train loss:0.02135188217686081\n",
      "train loss:0.06473143668232555\n",
      "train loss:0.009172634586547716\n",
      "train loss:0.024818963073690734\n",
      "train loss:0.022915754288868325\n",
      "train loss:0.01841099854393945\n",
      "train loss:0.02904896326509022\n",
      "train loss:0.030149936985142105\n",
      "train loss:0.025234257718858608\n",
      "train loss:0.02341684797110671\n",
      "train loss:0.013289831442106943\n",
      "train loss:0.03367489148763829\n",
      "train loss:0.015074262651510224\n",
      "train loss:0.033546481721338124\n",
      "train loss:0.030729988074941608\n",
      "train loss:0.04797069745920117\n",
      "train loss:0.031320280649248244\n",
      "train loss:0.01730894976907476\n",
      "train loss:0.009578381273984466\n",
      "train loss:0.027384546967740654\n",
      "train loss:0.0907523314884333\n",
      "train loss:0.010826594637438722\n",
      "train loss:0.03120089971829483\n",
      "train loss:0.055075954407218235\n",
      "train loss:0.09823067522237373\n",
      "train loss:0.018293194695327433\n",
      "train loss:0.032800928050343944\n",
      "train loss:0.0772393537179295\n",
      "train loss:0.09331985822602254\n",
      "train loss:0.054494271275608804\n",
      "train loss:0.012991858131890282\n",
      "train loss:0.025318171543554816\n",
      "train loss:0.016183059816832615\n",
      "train loss:0.06134703992277763\n",
      "train loss:0.039541703651899\n",
      "train loss:0.15191615628279995\n",
      "train loss:0.06602514487037865\n",
      "train loss:0.08491497910895544\n",
      "train loss:0.019474167760707012\n",
      "train loss:0.012876508266059305\n",
      "train loss:0.05000658959101498\n",
      "train loss:0.0073246189289850995\n",
      "train loss:0.023722390142112634\n",
      "train loss:0.04658062583766289\n",
      "train loss:0.061744209486226255\n",
      "train loss:0.018449364013454796\n",
      "train loss:0.017916815018602615\n",
      "train loss:0.005217845731887663\n",
      "train loss:0.028339157350758547\n",
      "train loss:0.02395190846988287\n",
      "train loss:0.051860812742517706\n",
      "train loss:0.023441425712022807\n",
      "train loss:0.015869556799482664\n",
      "train loss:0.04469721156662652\n",
      "train loss:0.0693022421703215\n",
      "train loss:0.028002247634397955\n",
      "train loss:0.0529122581854035\n",
      "train loss:0.009130357562373424\n",
      "train loss:0.022088965513340234\n",
      "train loss:0.0391447084738767\n",
      "train loss:0.008534028060621843\n",
      "train loss:0.01252653494245164\n",
      "train loss:0.02381287760737843\n",
      "train loss:0.044897089044369946\n",
      "train loss:0.02596158384891605\n",
      "train loss:0.030369596117379608\n",
      "train loss:0.014036119848796552\n",
      "train loss:0.06514964698487408\n",
      "train loss:0.04342639070509766\n",
      "train loss:0.020579541970217954\n",
      "train loss:0.029150799303636333\n",
      "train loss:0.17805219971643266\n",
      "train loss:0.03957509819396886\n",
      "train loss:0.08402107183961421\n",
      "train loss:0.08339725255166322\n",
      "train loss:0.0034337813069129303\n",
      "train loss:0.020474389465327168\n",
      "train loss:0.022933648220893308\n",
      "train loss:0.01668507574302755\n",
      "train loss:0.014008237358967408\n",
      "train loss:0.01465961058545306\n",
      "train loss:0.06752516017315596\n",
      "train loss:0.1011866972558949\n",
      "train loss:0.07911931692146595\n",
      "train loss:0.012903046360528808\n",
      "train loss:0.016996381540201957\n",
      "train loss:0.005873577245894697\n",
      "train loss:0.0576779153462681\n",
      "train loss:0.013537634743492415\n",
      "train loss:0.014095418521456505\n",
      "train loss:0.02046163072158172\n",
      "train loss:0.019312383877204294\n",
      "train loss:0.017123649435472822\n",
      "train loss:0.012909305902207924\n",
      "train loss:0.02484616028223809\n",
      "train loss:0.04075496427036053\n",
      "train loss:0.011166515480236212\n",
      "train loss:0.047413350377564153\n",
      "train loss:0.01389629338087636\n",
      "train loss:0.0156859687214154\n",
      "train loss:0.009043249743178659\n",
      "train loss:0.03228788588048445\n",
      "train loss:0.061023465536634534\n",
      "train loss:0.06489773822694776\n",
      "train loss:0.021546811201667473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.034445828372250166\n",
      "train loss:0.06476339778680418\n",
      "train loss:0.01850047263148466\n",
      "train loss:0.07416963423103086\n",
      "train loss:0.09071668045045245\n",
      "train loss:0.012922196992100095\n",
      "train loss:0.006106822247300131\n",
      "train loss:0.02894376074334409\n",
      "train loss:0.009187955496690613\n",
      "train loss:0.0263176310245421\n",
      "train loss:0.04185826460059877\n",
      "train loss:0.0263050855725331\n",
      "train loss:0.009979578487321623\n",
      "train loss:0.03923085505800112\n",
      "train loss:0.04046836762025555\n",
      "train loss:0.021674842077404693\n",
      "train loss:0.024813419075561866\n",
      "train loss:0.034930974611406346\n",
      "train loss:0.016349431654753853\n",
      "train loss:0.0447111455616583\n",
      "train loss:0.04370139777528985\n",
      "train loss:0.009308185806080916\n",
      "train loss:0.008689812064703456\n",
      "train loss:0.015099252292216273\n",
      "train loss:0.02637069396797429\n",
      "train loss:0.03283251587326029\n",
      "train loss:0.013534310338997517\n",
      "train loss:0.03401684784216309\n",
      "train loss:0.03575456083853191\n",
      "train loss:0.034485998294348105\n",
      "train loss:0.02479447921016598\n",
      "train loss:0.014565654353004847\n",
      "train loss:0.04134200930387717\n",
      "train loss:0.08025320638446347\n",
      "train loss:0.05115734771855384\n",
      "train loss:0.02021210718586848\n",
      "train loss:0.018536770828756342\n",
      "train loss:0.03735979529289746\n",
      "train loss:0.01919170694495154\n",
      "train loss:0.010840542544485918\n",
      "train loss:0.0878288398230237\n",
      "train loss:0.020718171887632662\n",
      "train loss:0.011562996414625598\n",
      "train loss:0.05866521065020149\n",
      "train loss:0.058750925690932994\n",
      "train loss:0.07500125802849192\n",
      "train loss:0.021744555345686943\n",
      "train loss:0.015145727906538078\n",
      "train loss:0.03664463668591091\n",
      "train loss:0.013002980920229218\n",
      "train loss:0.019061604696855857\n",
      "train loss:0.019812243186222364\n",
      "train loss:0.03949158129490768\n",
      "train loss:0.07678742007978073\n",
      "train loss:0.04520450846853742\n",
      "train loss:0.014836998512210646\n",
      "train loss:0.05835797981443066\n",
      "train loss:0.13749036114963123\n",
      "train loss:0.028154059267942136\n",
      "train loss:0.025648329399844537\n",
      "train loss:0.029879541599522726\n",
      "train loss:0.011545659220328257\n",
      "train loss:0.012575464292496081\n",
      "train loss:0.020313814725789293\n",
      "train loss:0.04989676151330033\n",
      "train loss:0.04968409726000157\n",
      "train loss:0.01724852350858987\n",
      "train loss:0.06837089411186832\n",
      "train loss:0.05893109424913314\n",
      "train loss:0.043117909609175616\n",
      "train loss:0.05515925522257383\n",
      "train loss:0.12462169826974355\n",
      "train loss:0.021924614674596183\n",
      "train loss:0.030997727658443178\n",
      "train loss:0.03337584624829308\n",
      "train loss:0.019663841418352285\n",
      "train loss:0.04865426739919784\n",
      "train loss:0.019816328462619416\n",
      "train loss:0.030742702770638036\n",
      "train loss:0.08399449757741068\n",
      "train loss:0.06423132571840229\n",
      "train loss:0.12541193644210935\n",
      "train loss:0.03124492933437222\n",
      "train loss:0.0205018862230112\n",
      "train loss:0.04556121875855133\n",
      "train loss:0.03485813821396722\n",
      "train loss:0.05685848654446076\n",
      "train loss:0.05485885907129478\n",
      "train loss:0.027436902766229582\n",
      "train loss:0.016442730351945097\n",
      "train loss:0.015840273648357033\n",
      "train loss:0.04821461631537261\n",
      "train loss:0.02945450400255066\n",
      "train loss:0.022699870943055298\n",
      "train loss:0.020058026960361408\n",
      "train loss:0.01751512234365871\n",
      "train loss:0.05346751444712419\n",
      "train loss:0.030887276294719542\n",
      "train loss:0.0339397775123689\n",
      "train loss:0.06175218776623053\n",
      "train loss:0.04767051017071772\n",
      "train loss:0.02667293572692521\n",
      "train loss:0.06617263679861646\n",
      "train loss:0.010161962260100865\n",
      "train loss:0.018549135174781694\n",
      "train loss:0.03383396840903056\n",
      "train loss:0.029287980458692568\n",
      "train loss:0.031333935708274946\n",
      "train loss:0.03532743455909651\n",
      "train loss:0.021701315972718876\n",
      "train loss:0.05470621471440963\n",
      "train loss:0.01809585137458184\n",
      "train loss:0.01001743447524963\n",
      "train loss:0.013535375768374156\n",
      "train loss:0.07912418886101284\n",
      "train loss:0.06233493181968162\n",
      "train loss:0.019933984669633552\n",
      "train loss:0.06307832992754514\n",
      "train loss:0.005646582870778748\n",
      "train loss:0.017903118053201765\n",
      "train loss:0.023249556524974437\n",
      "train loss:0.021887175260330006\n",
      "train loss:0.04177042441316486\n",
      "train loss:0.019860883074426967\n",
      "train loss:0.022128933488823544\n",
      "train loss:0.022716572425142748\n",
      "train loss:0.011255794534710655\n",
      "train loss:0.023969207334996304\n",
      "train loss:0.035559322021498994\n",
      "train loss:0.04219293140690668\n",
      "train loss:0.008891706376255484\n",
      "train loss:0.01878577660221385\n",
      "train loss:0.02069853351052596\n",
      "train loss:0.004832046129017972\n",
      "train loss:0.012233918362234386\n",
      "train loss:0.010044523003347945\n",
      "train loss:0.027608953761094707\n",
      "train loss:0.01703148191120386\n",
      "train loss:0.011386446512936679\n",
      "train loss:0.03886486997862043\n",
      "train loss:0.08907160106506491\n",
      "train loss:0.13106606588843372\n",
      "train loss:0.0515103225685644\n",
      "train loss:0.007226520996561959\n",
      "train loss:0.14496547134178073\n",
      "train loss:0.010736656759903141\n",
      "train loss:0.026827262115279908\n",
      "train loss:0.018188198108620678\n",
      "train loss:0.025621225286733985\n",
      "train loss:0.03980511768420908\n",
      "train loss:0.06293006616130795\n",
      "train loss:0.06503116266399579\n",
      "train loss:0.009869436410275073\n",
      "train loss:0.04880652605438628\n",
      "train loss:0.017776157428948027\n",
      "train loss:0.02981826485848268\n",
      "train loss:0.028777995586937277\n",
      "train loss:0.014846577309114636\n",
      "train loss:0.008671466843496367\n",
      "train loss:0.011947767426947553\n",
      "train loss:0.09414078661398953\n",
      "train loss:0.004926603228419284\n",
      "train loss:0.012948979857001075\n",
      "train loss:0.05351088745921558\n",
      "train loss:0.017906287449107123\n",
      "train loss:0.04152526766079388\n",
      "train loss:0.038054755760474804\n",
      "train loss:0.05668381464634403\n",
      "train loss:0.027684667707646597\n",
      "train loss:0.011323252665985916\n",
      "train loss:0.07352544355829206\n",
      "train loss:0.08467856226684103\n",
      "train loss:0.02011166702356708\n",
      "train loss:0.01645822430672951\n",
      "train loss:0.022087400771256233\n",
      "train loss:0.11994576808550661\n",
      "train loss:0.057614970055257994\n",
      "train loss:0.07316848721951637\n",
      "train loss:0.027533967895811782\n",
      "train loss:0.016693994317364572\n",
      "train loss:0.029272367674199547\n",
      "train loss:0.01676362767648831\n",
      "train loss:0.020800828811913363\n",
      "train loss:0.10463377032745569\n",
      "train loss:0.06516511732059653\n",
      "train loss:0.04696097791295048\n",
      "train loss:0.028152184202019242\n",
      "train loss:0.03815805459811513\n",
      "train loss:0.03776223869525279\n",
      "train loss:0.00982782679119113\n",
      "train loss:0.02665327001414663\n",
      "train loss:0.08488182671558457\n",
      "train loss:0.028694241984063406\n",
      "train loss:0.014790633930556322\n",
      "train loss:0.01105169661245113\n",
      "train loss:0.07552056016431936\n",
      "train loss:0.07132760285294858\n",
      "train loss:0.008007739986491269\n",
      "train loss:0.10514553120736082\n",
      "train loss:0.010399244982196154\n",
      "train loss:0.07870049790747116\n",
      "train loss:0.011697733505237\n",
      "train loss:0.025164436410528016\n",
      "train loss:0.024145111445017152\n",
      "train loss:0.03155071069677931\n",
      "train loss:0.014069566979879258\n",
      "train loss:0.01304391211774751\n",
      "train loss:0.03653596830997803\n",
      "train loss:0.041580768724518664\n",
      "train loss:0.015396325760106864\n",
      "train loss:0.01866848463594527\n",
      "train loss:0.005478650582304198\n",
      "train loss:0.07102107332178706\n",
      "train loss:0.04409874214189352\n",
      "train loss:0.018995738119997843\n",
      "train loss:0.020332126295920513\n",
      "train loss:0.017650543615995745\n",
      "train loss:0.030123373056066337\n",
      "train loss:0.01970274437623239\n",
      "train loss:0.02786664589173255\n",
      "train loss:0.030611023904255078\n",
      "train loss:0.012547597355015074\n",
      "train loss:0.01592386151772597\n",
      "train loss:0.009121761536244749\n",
      "train loss:0.00947040133582954\n",
      "train loss:0.012902531343195318\n",
      "train loss:0.02896261420877485\n",
      "train loss:0.057688135838906446\n",
      "train loss:0.040688771432872244\n",
      "train loss:0.02582015749844529\n",
      "train loss:0.04410131868869219\n",
      "train loss:0.00314231115272823\n",
      "train loss:0.052991731818924824\n",
      "train loss:0.019527772909689198\n",
      "train loss:0.07042201044522887\n",
      "train loss:0.024536328053459944\n",
      "train loss:0.018930790337714783\n",
      "train loss:0.05678777331146474\n",
      "train loss:0.04249839837225355\n",
      "train loss:0.01328389504089813\n",
      "train loss:0.005512039656752858\n",
      "train loss:0.012490699459259147\n",
      "train loss:0.012418922114102908\n",
      "train loss:0.05761625357402699\n",
      "train loss:0.0877662235441633\n",
      "train loss:0.03818051896604753\n",
      "train loss:0.021013613919828235\n",
      "train loss:0.029689652291471687\n",
      "train loss:0.046859557701948475\n",
      "train loss:0.0372424734610978\n",
      "train loss:0.07645533540432056\n",
      "train loss:0.042673426747447\n",
      "train loss:0.03734959593326535\n",
      "train loss:0.04114553153124729\n",
      "train loss:0.015837271338593\n",
      "train loss:0.015886102534416836\n",
      "train loss:0.01034609447366742\n",
      "train loss:0.02482558695896151\n",
      "train loss:0.011418847846676065\n",
      "train loss:0.04718193340244085\n",
      "train loss:0.06188213391162886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.010225279425350597\n",
      "train loss:0.01390612851307599\n",
      "train loss:0.035307475222651236\n",
      "train loss:0.029754986903753684\n",
      "train loss:0.027077252256111555\n",
      "train loss:0.09729104434480584\n",
      "train loss:0.01014210932173893\n",
      "train loss:0.0594947069061265\n",
      "train loss:0.028341408888222598\n",
      "train loss:0.04218908354582512\n",
      "train loss:0.07373656189251304\n",
      "train loss:0.0300447176969256\n",
      "train loss:0.033793915025936344\n",
      "train loss:0.024372533488968267\n",
      "train loss:0.017654147809389936\n",
      "train loss:0.019812460503027925\n",
      "train loss:0.017439710288245182\n",
      "train loss:0.010053502826867783\n",
      "train loss:0.03946858491684043\n",
      "train loss:0.015426555239936201\n",
      "train loss:0.02847182170424935\n",
      "train loss:0.020170680129504393\n",
      "train loss:0.05794250723653398\n",
      "train loss:0.02278779988698132\n",
      "train loss:0.030344787166747447\n",
      "train loss:0.012771627725724965\n",
      "train loss:0.020486165308868914\n",
      "train loss:0.026401424236437897\n",
      "train loss:0.05638637143364075\n",
      "=== epoch:5, train acc:0.984, test acc:0.982 ===\n",
      "train loss:0.02539309197456717\n",
      "train loss:0.023588985297361045\n",
      "train loss:0.011235772748235569\n",
      "train loss:0.025755034983556992\n",
      "train loss:0.01689742337399119\n",
      "train loss:0.010345333416852454\n",
      "train loss:0.026445675708378122\n",
      "train loss:0.0027712829928869614\n",
      "train loss:0.04225863614531968\n",
      "train loss:0.014653039813249025\n",
      "train loss:0.01714442940879852\n",
      "train loss:0.01947937742710237\n",
      "train loss:0.06088858288696027\n",
      "train loss:0.008737341520657705\n",
      "train loss:0.0354496889613143\n",
      "train loss:0.028661806879600453\n",
      "train loss:0.005412335469831092\n",
      "train loss:0.0727083152739174\n",
      "train loss:0.03550623632093705\n",
      "train loss:0.014441688086540056\n",
      "train loss:0.027782406922599215\n",
      "train loss:0.02152795955327499\n",
      "train loss:0.05528193559396159\n",
      "train loss:0.008192374143580185\n",
      "train loss:0.00589818951540442\n",
      "train loss:0.08959871224827044\n",
      "train loss:0.03042508960714493\n",
      "train loss:0.016547597451997603\n",
      "train loss:0.05663587170584755\n",
      "train loss:0.027386304317355267\n",
      "train loss:0.018730613219794336\n",
      "train loss:0.07525814859924396\n",
      "train loss:0.031042362200065753\n",
      "train loss:0.07175047392010908\n",
      "train loss:0.019516460829357582\n",
      "train loss:0.04397006271924725\n",
      "train loss:0.03423659750801651\n",
      "train loss:0.038273485407250105\n",
      "train loss:0.02237633575862275\n",
      "train loss:0.01885329345864369\n",
      "train loss:0.011747043323413652\n",
      "train loss:0.009446267228690729\n",
      "train loss:0.04253819159531452\n",
      "train loss:0.07359862033912487\n",
      "train loss:0.02113074625000899\n",
      "train loss:0.011771589530730322\n",
      "train loss:0.03062598478877896\n",
      "train loss:0.016456659259255546\n",
      "train loss:0.018965022047380056\n",
      "train loss:0.049270987152469685\n",
      "train loss:0.0282757147707865\n",
      "train loss:0.018390386099229605\n",
      "train loss:0.01034020526706652\n",
      "train loss:0.10160427571619719\n",
      "train loss:0.014907240178002568\n",
      "train loss:0.15093621624677905\n",
      "train loss:0.02286878852935359\n",
      "train loss:0.008582378503685066\n",
      "train loss:0.02485985824469137\n",
      "train loss:0.04545322479332067\n",
      "train loss:0.032766415200248304\n",
      "train loss:0.01214191928694927\n",
      "train loss:0.0863193987126917\n",
      "train loss:0.01999619103065902\n",
      "train loss:0.02506845488258656\n",
      "train loss:0.04780334863934255\n",
      "train loss:0.04075181036893076\n",
      "train loss:0.03325644376819013\n",
      "train loss:0.03705453331355674\n",
      "train loss:0.009501846806423382\n",
      "train loss:0.02962425694863228\n",
      "train loss:0.02495410284565095\n",
      "train loss:0.022603952164176325\n",
      "train loss:0.010956226677149693\n",
      "train loss:0.013036783735824174\n",
      "train loss:0.010622927249410491\n",
      "train loss:0.052087292993386915\n",
      "train loss:0.02427115558456296\n",
      "train loss:0.06337583366832844\n",
      "train loss:0.01630337878108169\n",
      "train loss:0.00968977007343466\n",
      "train loss:0.01466113305674319\n",
      "train loss:0.047286145110903836\n",
      "train loss:0.012228604964177998\n",
      "train loss:0.038732953787331485\n",
      "train loss:0.03528158432521329\n",
      "train loss:0.07191150541644548\n",
      "train loss:0.009770602830145206\n",
      "train loss:0.020038230740483675\n",
      "train loss:0.015345368188757456\n",
      "train loss:0.008448410217547333\n",
      "train loss:0.01250722096531556\n",
      "train loss:0.04689124830292139\n",
      "train loss:0.017157397571882334\n",
      "train loss:0.009231509336038952\n",
      "train loss:0.013726034735313041\n",
      "train loss:0.028562771429971722\n",
      "train loss:0.010095158532428882\n",
      "train loss:0.02572982754987051\n",
      "train loss:0.00949149980230575\n",
      "train loss:0.014817172473130729\n",
      "train loss:0.01149201660103729\n",
      "train loss:0.040939933639286136\n",
      "train loss:0.020546861420725513\n",
      "train loss:0.006793891569098621\n",
      "train loss:0.012259010157044994\n",
      "train loss:0.0026058858153949383\n",
      "train loss:0.02022677781693724\n",
      "train loss:0.016548227970614563\n",
      "train loss:0.011330498813009236\n",
      "train loss:0.008990852017144134\n",
      "train loss:0.018545709985940562\n",
      "train loss:0.00805019691806368\n",
      "train loss:0.013835207588064556\n",
      "train loss:0.010696678569046129\n",
      "train loss:0.02011237883746064\n",
      "train loss:0.0166229026545843\n",
      "train loss:0.029898882716026143\n",
      "train loss:0.026948034342638056\n",
      "train loss:0.028695792694855622\n",
      "train loss:0.006895849087684965\n",
      "train loss:0.01724343331917273\n",
      "train loss:0.015891886226502904\n",
      "train loss:0.04390507817368801\n",
      "train loss:0.01065775761478651\n",
      "train loss:0.0035644413758583278\n",
      "train loss:0.0319026994050888\n",
      "train loss:0.00936989444457299\n",
      "train loss:0.035056123676021046\n",
      "train loss:0.028499333505549652\n",
      "train loss:0.010925507029185887\n",
      "train loss:0.013514628563385523\n",
      "train loss:0.005138740278420275\n",
      "train loss:0.06125141810194031\n",
      "train loss:0.03433009293681884\n",
      "train loss:0.12736917494949776\n",
      "train loss:0.030445007612149036\n",
      "train loss:0.006360582293292587\n",
      "train loss:0.05816458469031773\n",
      "train loss:0.012869437755067976\n",
      "train loss:0.015754730632342496\n",
      "train loss:0.029161493781135923\n",
      "train loss:0.06999387698937315\n",
      "train loss:0.06351473533277864\n",
      "train loss:0.03816154260657278\n",
      "train loss:0.014416286425366402\n",
      "train loss:0.013432254258299543\n",
      "train loss:0.018228398541470844\n",
      "train loss:0.012510941835085873\n",
      "train loss:0.015781882459705195\n",
      "train loss:0.013882988177671068\n",
      "train loss:0.024735073504958894\n",
      "train loss:0.040218393684350165\n",
      "train loss:0.028162498758926974\n",
      "train loss:0.012306531904542017\n",
      "train loss:0.04131487784443446\n",
      "train loss:0.010557279582517103\n",
      "train loss:0.005492245859238449\n",
      "train loss:0.006772147218904255\n",
      "train loss:0.027005018855708825\n",
      "train loss:0.029938693540448535\n",
      "train loss:0.026340264173570337\n",
      "train loss:0.020594464807064266\n",
      "train loss:0.013936062280453689\n",
      "train loss:0.1275505538224818\n",
      "train loss:0.009710071740221978\n",
      "train loss:0.03013853908643877\n",
      "train loss:0.011134252486163716\n",
      "train loss:0.027271101389616706\n",
      "train loss:0.035581856760076705\n",
      "train loss:0.09606055846938867\n",
      "train loss:0.01935883344839222\n",
      "train loss:0.0057082642702281795\n",
      "train loss:0.028963868534070628\n",
      "train loss:0.017252738336374675\n",
      "train loss:0.0039514313735580205\n",
      "train loss:0.03593696823553052\n",
      "train loss:0.01410062352054391\n",
      "train loss:0.042176416198700425\n",
      "train loss:0.009174874612403959\n",
      "train loss:0.021822516115080806\n",
      "train loss:0.015805780462266657\n",
      "train loss:0.008608502503094848\n",
      "train loss:0.055033731530681945\n",
      "train loss:0.04997103988737752\n",
      "train loss:0.031517199207025885\n",
      "train loss:0.03381662131757906\n",
      "train loss:0.06712950533201656\n",
      "train loss:0.026886056293597037\n",
      "train loss:0.006153127491134722\n",
      "train loss:0.014720021150491638\n",
      "train loss:0.019583526838750923\n",
      "train loss:0.019575481538533758\n",
      "train loss:0.002901580602137596\n",
      "train loss:0.043446322788604406\n",
      "train loss:0.01739227240166651\n",
      "train loss:0.022169744180465974\n",
      "train loss:0.02192230508191985\n",
      "train loss:0.06528035020458609\n",
      "train loss:0.006115870129760689\n",
      "train loss:0.024970276043595772\n",
      "train loss:0.04373362486759556\n",
      "train loss:0.016802074795748686\n",
      "train loss:0.006606822095902156\n",
      "train loss:0.03449015066512853\n",
      "train loss:0.005485353799773983\n",
      "train loss:0.02171125592101783\n",
      "train loss:0.032770340279392664\n",
      "train loss:0.0497081278703326\n",
      "train loss:0.008707462221468606\n",
      "train loss:0.07247751388453383\n",
      "train loss:0.01293167092304138\n",
      "train loss:0.014316651537007577\n",
      "train loss:0.012636775676347155\n",
      "train loss:0.03933964581785859\n",
      "train loss:0.030408942243867608\n",
      "train loss:0.00841339999751954\n",
      "train loss:0.02684884508740064\n",
      "train loss:0.03631121361930636\n",
      "train loss:0.009340612265314328\n",
      "train loss:0.009163870237610445\n",
      "train loss:0.056453045979493154\n",
      "train loss:0.0361542213432003\n",
      "train loss:0.06627532812575104\n",
      "train loss:0.006728541436080412\n",
      "train loss:0.03536749887771029\n",
      "train loss:0.016920650094757347\n",
      "train loss:0.0354164337764267\n",
      "train loss:0.0629040510670364\n",
      "train loss:0.03581223858089401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.017288432342910918\n",
      "train loss:0.008208262373827505\n",
      "train loss:0.0840326862698505\n",
      "train loss:0.015363688856979703\n",
      "train loss:0.00933560042157265\n",
      "train loss:0.04170032918368847\n",
      "train loss:0.14349769472888615\n",
      "train loss:0.01744749504372372\n",
      "train loss:0.06904192548097525\n",
      "train loss:0.020048255502430307\n",
      "train loss:0.032890531931459514\n",
      "train loss:0.015671668112603253\n",
      "train loss:0.026096996111932964\n",
      "train loss:0.01060234702164621\n",
      "train loss:0.014769124645220509\n",
      "train loss:0.055368356022734135\n",
      "train loss:0.02498313788926395\n",
      "train loss:0.00780971262122154\n",
      "train loss:0.010691692433265527\n",
      "train loss:0.026453299685847788\n",
      "train loss:0.008501467725598129\n",
      "train loss:0.012410660728474205\n",
      "train loss:0.012072518701761504\n",
      "train loss:0.007406189703016059\n",
      "train loss:0.06409480765121564\n",
      "train loss:0.026413131587278253\n",
      "train loss:0.02561575796154132\n",
      "train loss:0.03463358917796427\n",
      "train loss:0.013478977906133949\n",
      "train loss:0.08890659011737326\n",
      "train loss:0.00958569258147106\n",
      "train loss:0.023716198092925293\n",
      "train loss:0.009035071736696739\n",
      "train loss:0.032778011130581076\n",
      "train loss:0.022211797909310885\n",
      "train loss:0.016252530980626383\n",
      "train loss:0.007523576452352961\n",
      "train loss:0.03922837314423715\n",
      "train loss:0.0018416378877774222\n",
      "train loss:0.02137030541943543\n",
      "train loss:0.010139637590936855\n",
      "train loss:0.009257335037349691\n",
      "train loss:0.006435747196292017\n",
      "train loss:0.03390195938264197\n",
      "train loss:0.024550481556559197\n",
      "train loss:0.015118687081075699\n",
      "train loss:0.011004501343078283\n",
      "train loss:0.0241209932839251\n",
      "train loss:0.0056091587348396895\n",
      "train loss:0.03750254092646771\n",
      "train loss:0.02191323228433187\n",
      "train loss:0.02208341039924801\n",
      "train loss:0.07466881615878845\n",
      "train loss:0.00730140574969757\n",
      "train loss:0.014806759321601637\n",
      "train loss:0.006966772482551872\n",
      "train loss:0.009561914408150692\n",
      "train loss:0.007808592844530743\n",
      "train loss:0.06012033511045257\n",
      "train loss:0.09868844918659687\n",
      "train loss:0.07750251089898759\n",
      "train loss:0.022969409178787436\n",
      "train loss:0.014032036804661563\n",
      "train loss:0.023757755589641567\n",
      "train loss:0.027942689494815626\n",
      "train loss:0.1261482192882842\n",
      "train loss:0.055621830233978826\n",
      "train loss:0.004012399807736073\n",
      "train loss:0.028979811160163203\n",
      "train loss:0.025113706885745202\n",
      "train loss:0.02262034627500564\n",
      "train loss:0.026352448687390822\n",
      "train loss:0.009779717146642547\n",
      "train loss:0.005923234549801743\n",
      "train loss:0.016380777383506056\n",
      "train loss:0.07191889906749317\n",
      "train loss:0.02317611835072573\n",
      "train loss:0.02270618949780924\n",
      "train loss:0.03537335460347274\n",
      "train loss:0.011023404217542903\n",
      "train loss:0.016285267018120313\n",
      "train loss:0.030319876342842212\n",
      "train loss:0.042997466915576085\n",
      "train loss:0.09764610380822468\n",
      "train loss:0.03112269244936305\n",
      "train loss:0.014463066089165368\n",
      "train loss:0.015920862798099317\n",
      "train loss:0.008738799147148854\n",
      "train loss:0.004965919159280564\n",
      "train loss:0.03019113420976819\n",
      "train loss:0.006467432779738182\n",
      "train loss:0.012908946356647693\n",
      "train loss:0.025176706029191885\n",
      "train loss:0.01099172665819134\n",
      "train loss:0.10446864351004559\n",
      "train loss:0.005972288234250163\n",
      "train loss:0.06872097144655867\n",
      "train loss:0.0033370421375419467\n",
      "train loss:0.07571220222818731\n",
      "train loss:0.011231760818895466\n",
      "train loss:0.021362525693786365\n",
      "train loss:0.022225787046034687\n",
      "train loss:0.005775503587871541\n",
      "train loss:0.022882209768353656\n",
      "train loss:0.044342931349240416\n",
      "train loss:0.01868907566854917\n",
      "train loss:0.0037373488136616547\n",
      "train loss:0.012510406918357355\n",
      "train loss:0.03492347187492212\n",
      "train loss:0.02574176627177538\n",
      "train loss:0.014656955434391822\n",
      "train loss:0.003806917201478884\n",
      "train loss:0.018234584287679937\n",
      "train loss:0.02660566716612603\n",
      "train loss:0.010156388932006915\n",
      "train loss:0.010629936057325304\n",
      "train loss:0.016188655181414928\n",
      "train loss:0.007735069375791437\n",
      "train loss:0.012312430318164385\n",
      "train loss:0.03085343466225933\n",
      "train loss:0.0026797414801555813\n",
      "train loss:0.0034175032851745707\n",
      "train loss:0.018731306362353154\n",
      "train loss:0.0132246737688416\n",
      "train loss:0.007717818081801215\n",
      "train loss:0.01991823481307166\n",
      "train loss:0.010722623207303711\n",
      "train loss:0.018670716957663102\n",
      "train loss:0.03407916654560914\n",
      "train loss:0.028497686745170926\n",
      "train loss:0.031207503597389444\n",
      "train loss:0.013767742643596835\n",
      "train loss:0.017859309975924526\n",
      "train loss:0.04318255241134828\n",
      "train loss:0.054021193338988256\n",
      "train loss:0.044234085404439086\n",
      "train loss:0.015905002740821086\n",
      "train loss:0.008334663184908456\n",
      "train loss:0.03885524507056344\n",
      "train loss:0.01243298007161364\n",
      "train loss:0.012883266160931186\n",
      "train loss:0.04226191584354818\n",
      "train loss:0.03069977228576417\n",
      "train loss:0.00692272185764079\n",
      "train loss:0.027365754651861723\n",
      "train loss:0.030294699899010836\n",
      "train loss:0.042200930843061396\n",
      "train loss:0.051344433400577\n",
      "train loss:0.07799645581606095\n",
      "train loss:0.021272635953454015\n",
      "train loss:0.06179567103359486\n",
      "train loss:0.021800337489056586\n",
      "train loss:0.10450634823726387\n",
      "train loss:0.046704108997461066\n",
      "train loss:0.009456679072279596\n",
      "train loss:0.0047180759991864215\n",
      "train loss:0.027442924862034958\n",
      "train loss:0.08531667962985612\n",
      "train loss:0.02172422440026632\n",
      "train loss:0.01867349534104606\n",
      "train loss:0.023626620308944125\n",
      "train loss:0.04634750287723067\n",
      "train loss:0.013060091494927883\n",
      "train loss:0.014742581286561574\n",
      "train loss:0.008247175322362868\n",
      "train loss:0.06201918964165899\n",
      "train loss:0.017769147889275142\n",
      "train loss:0.005073185730207882\n",
      "train loss:0.015331142834037437\n",
      "train loss:0.04666483592378319\n",
      "train loss:0.06417439363404355\n",
      "train loss:0.0033566036636326017\n",
      "train loss:0.004581814385604277\n",
      "train loss:0.035796450804582915\n",
      "train loss:0.06252332426129129\n",
      "train loss:0.003178764839450796\n",
      "train loss:0.02362459185739874\n",
      "train loss:0.015826017025535467\n",
      "train loss:0.037566488846888034\n",
      "train loss:0.03329824632304976\n",
      "train loss:0.00890438294989562\n",
      "train loss:0.020029884060807288\n",
      "train loss:0.03018696445142458\n",
      "train loss:0.017221643665627225\n",
      "train loss:0.01967789389311947\n",
      "train loss:0.010855593473946643\n",
      "train loss:0.04596697861189787\n",
      "train loss:0.02277647638868365\n",
      "train loss:0.03381440291314974\n",
      "train loss:0.009106853772712569\n",
      "train loss:0.0041982633875042\n",
      "train loss:0.015902979133308796\n",
      "train loss:0.0205985753385918\n",
      "train loss:0.009962261672607149\n",
      "train loss:0.02773537612143988\n",
      "train loss:0.021743799400538798\n",
      "train loss:0.016139200459767494\n",
      "train loss:0.012688404034690176\n",
      "train loss:0.08637103109552532\n",
      "train loss:0.02314492681579252\n",
      "train loss:0.006637171228886392\n",
      "train loss:0.015366508308918335\n",
      "train loss:0.012394749921874351\n",
      "train loss:0.015121725299987591\n",
      "train loss:0.037525609397383\n",
      "train loss:0.03172327181782014\n",
      "train loss:0.008721154200941715\n",
      "train loss:0.02866203700292159\n",
      "train loss:0.056568884419871644\n",
      "train loss:0.026136740995613583\n",
      "train loss:0.016397624233124887\n",
      "train loss:0.04832210600421392\n",
      "train loss:0.02646525965701503\n",
      "train loss:0.01322476341772073\n",
      "train loss:0.01873950316868403\n",
      "train loss:0.02491299735593638\n",
      "train loss:0.012426148968374432\n",
      "train loss:0.04205580933928241\n",
      "train loss:0.005545976534986483\n",
      "train loss:0.04266024289726247\n",
      "train loss:0.013053807738917178\n",
      "train loss:0.048232786149432855\n",
      "train loss:0.014223464117423175\n",
      "train loss:0.0069613992079524956\n",
      "train loss:0.029555947035024087\n",
      "train loss:0.015153762209476906\n",
      "train loss:0.05123363943707566\n",
      "train loss:0.06397768080730297\n",
      "train loss:0.03269263733301868\n",
      "train loss:0.011197301871966152\n",
      "train loss:0.03417175596849867\n",
      "train loss:0.014401449521707079\n",
      "train loss:0.039367757803307715\n",
      "train loss:0.021675259644467412\n",
      "train loss:0.03703038681982253\n",
      "train loss:0.0072935620255507\n",
      "train loss:0.01428901334116701\n",
      "train loss:0.028214777921327892\n",
      "train loss:0.024614624940378815\n",
      "train loss:0.06412158900694283\n",
      "train loss:0.029600312934636257\n",
      "train loss:0.01929801987019899\n",
      "train loss:0.0570301781757335\n",
      "train loss:0.089700580927446\n",
      "train loss:0.041410317954993295\n",
      "train loss:0.020509125053210463\n",
      "train loss:0.014836580048396672\n",
      "train loss:0.010953260883043561\n",
      "train loss:0.006532161498775925\n",
      "train loss:0.00946285549141444\n",
      "train loss:0.010042672812113615\n",
      "train loss:0.013566571252718278\n",
      "train loss:0.016386104977070187\n",
      "train loss:0.05264120284533453\n",
      "train loss:0.05174878267610592\n",
      "train loss:0.02962321259026973\n",
      "train loss:0.045061169090031085\n",
      "train loss:0.005513517732024794\n",
      "train loss:0.0585326494570094\n",
      "train loss:0.02614446249853735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.016347626394759434\n",
      "train loss:0.020719246554377894\n",
      "train loss:0.012842459871320188\n",
      "train loss:0.051365462602988715\n",
      "train loss:0.03587274363379046\n",
      "train loss:0.07266160732727425\n",
      "train loss:0.04061761812216018\n",
      "train loss:0.037472731292814136\n",
      "train loss:0.01320767753019185\n",
      "train loss:0.05035353671003775\n",
      "train loss:0.03925586661198617\n",
      "train loss:0.04614064556020786\n",
      "train loss:0.014424074091066188\n",
      "train loss:0.01213738885788317\n",
      "train loss:0.00891429846919131\n",
      "train loss:0.011198579117222331\n",
      "train loss:0.01562137625605032\n",
      "train loss:0.01569842664908595\n",
      "train loss:0.00799677120194136\n",
      "train loss:0.009686829037875296\n",
      "train loss:0.031626443185841804\n",
      "train loss:0.029932859874696516\n",
      "train loss:0.004389438632761093\n",
      "train loss:0.045859802094869166\n",
      "train loss:0.01894818616807724\n",
      "train loss:0.07023523975406741\n",
      "train loss:0.01238804677091508\n",
      "train loss:0.08285657938130676\n",
      "train loss:0.042175525023372566\n",
      "train loss:0.08644195214108635\n",
      "train loss:0.037644706104561484\n",
      "train loss:0.05943896497228327\n",
      "train loss:0.01891361854631801\n",
      "train loss:0.03615959172084159\n",
      "train loss:0.030723301657702113\n",
      "train loss:0.01267827912007332\n",
      "train loss:0.18616903201902812\n",
      "train loss:0.06992691345427249\n",
      "train loss:0.0215255486171979\n",
      "train loss:0.01545158838622907\n",
      "train loss:0.010713377777997054\n",
      "train loss:0.016614916829126497\n",
      "train loss:0.031996003662190645\n",
      "train loss:0.018309351233300294\n",
      "train loss:0.026976154503656823\n",
      "train loss:0.01033901018783544\n",
      "train loss:0.013278190228525144\n",
      "train loss:0.03400705740466295\n",
      "train loss:0.015859464749501215\n",
      "train loss:0.005925603318680461\n",
      "train loss:0.009547725653660372\n",
      "train loss:0.019051007652502904\n",
      "train loss:0.025628368700606446\n",
      "train loss:0.06859650765942722\n",
      "train loss:0.05493895027268607\n",
      "train loss:0.009750490514072492\n",
      "train loss:0.017981592854056597\n",
      "train loss:0.00706159882583252\n",
      "train loss:0.015722699614235613\n",
      "train loss:0.01187726021310104\n",
      "train loss:0.04030752141663422\n",
      "train loss:0.019746372271962832\n",
      "train loss:0.024109508190527575\n",
      "train loss:0.014343534176579582\n",
      "train loss:0.02976095961112728\n",
      "train loss:0.05724758564082752\n",
      "train loss:0.024414507582480965\n",
      "train loss:0.0675360018435764\n",
      "train loss:0.04933439787957966\n",
      "train loss:0.167284324160578\n",
      "train loss:0.010539513558267686\n",
      "train loss:0.02002235985116539\n",
      "train loss:0.030837003197653316\n",
      "train loss:0.007004761216245442\n",
      "train loss:0.029679984289463612\n",
      "train loss:0.01597429584628632\n",
      "train loss:0.006298265760927624\n",
      "train loss:0.025532391353519368\n",
      "train loss:0.0029712305602670607\n",
      "train loss:0.05340410316632606\n",
      "train loss:0.022542516258196095\n",
      "train loss:0.008808258992136657\n",
      "train loss:0.016966395657620904\n",
      "train loss:0.010630432855008672\n",
      "train loss:0.0016546330422337575\n",
      "train loss:0.003606353669181514\n",
      "train loss:0.026004461965127783\n",
      "train loss:0.05456664228843098\n",
      "train loss:0.010548848570930509\n",
      "train loss:0.010775157584552372\n",
      "train loss:0.012041954910913278\n",
      "train loss:0.03562434244606106\n",
      "train loss:0.012375484510929227\n",
      "train loss:0.008414947863854804\n",
      "train loss:0.05009619459722444\n",
      "train loss:0.03405347950635817\n",
      "train loss:0.06796868157738847\n",
      "train loss:0.0371157142081637\n",
      "train loss:0.0689048661756881\n",
      "train loss:0.014598139024351585\n",
      "train loss:0.02049976515991833\n",
      "train loss:0.03364875637990241\n",
      "train loss:0.15535237639950333\n",
      "train loss:0.01334233455166011\n",
      "train loss:0.07472724031916511\n",
      "train loss:0.005707909001352212\n",
      "train loss:0.030500713102304972\n",
      "train loss:0.005858677287293157\n",
      "train loss:0.007706675399554545\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.9851\n",
      "Saved Network Parameters!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(\"../예제/\")\n",
    "sys.path.append(\"../예제/ch07\")# 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from simple_convnet import SimpleConvNet\n",
    "from common.trainer import Trainer\n",
    "\n",
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "# 시간이 오래 걸릴 경우 데이터를 줄인다.\n",
    "#x_train, t_train = x_train[:5000], t_train[:5000]\n",
    "#x_test, t_test = x_test[:1000], t_test[:1000]\n",
    "\n",
    "max_epochs = 5\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "                        \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# 매개변수 보존\n",
    "network.save_params(\"params.pkl\")\n",
    "print(\"Saved Network Parameters!\")\n",
    "\n",
    "# 그래프 그리기\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8324def",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yyc",
   "language": "python",
   "name": "yyc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
