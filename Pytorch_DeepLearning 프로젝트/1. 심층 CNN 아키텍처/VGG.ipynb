{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f94107e78d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddir = 'hymenoptera_data'\n",
    "\n",
    "# Data normalization and augmentation transformations for train dataset\n",
    "# Only normalization transformation for validation dataset\n",
    "\n",
    "data_transformers = {\n",
    "    'train': transforms.Compose([transforms.RandomResizedCrop(224), transforms.RandomHorizontalFlip(),\n",
    "                                    transforms.ToTensor(), \n",
    "                                    transforms.Normalize([0.490, 0.449, 0.411], [0.231, 0.221, 0.230])]),\n",
    "    'val': transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), \n",
    "                                      transforms.ToTensor(), \n",
    "                                      transforms.Normalize([0.490, 0.449, 0.411], [0.231, 0.221, 0.230])])}\n",
    "\n",
    "img_data = {k: datasets.ImageFolder(os.path.join(ddir, k), data_transformers[k]) for k in ['train', 'val']}\n",
    "dloaders = {k: torch.utils.data.DataLoader(img_data[k], batch_size=8, shuffle=True, num_workers=2) \n",
    "            for k in ['train', 'val']}\n",
    "dset_sizes = {x: len(img_data[x]) for x in ['train', 'val']}\n",
    "dvc = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'tench, Tinca tinca', 1: 'goldfish, Carassius auratus', 2: 'great white shark, white shark, man-eater, man-eating shark, Carcharodon carcharias', 3: 'tiger shark, Galeocerdo cuvieri', 4: 'hammerhead, hammerhead shark'}\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "with open('hymenoptera_data/imagenet1000_clsidx_to_labels.txt') as f:\n",
    "    classes_data = f.read()\n",
    "classes_dict = ast.literal_eval(classes_data)\n",
    "print({k: classes_dict[k] for k in list(classes_dict)[:5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageshow(img, text=None):\n",
    "    img = img.numpy().transpose((1, 2, 0))\n",
    "    avg = np.array([0.490, 0.449, 0.411])\n",
    "    stddev = np.array([0.231, 0.221, 0.230])\n",
    "    img = stddev * img + avg\n",
    "    img = np.clip(img, 0, 1)\n",
    "    plt.imshow(img)\n",
    "    if text is not None:\n",
    "        plt.title(text)\n",
    "\n",
    "def visualize_predictions(pretrained_model, max_num_imgs=4):\n",
    "    torch.manual_seed(1)\n",
    "    was_model_training = pretrained_model.training\n",
    "    pretrained_model.eval()\n",
    "    imgs_counter = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (imgs, tgts) in enumerate(dloaders['val']):\n",
    "            imgs = imgs.to(dvc)\n",
    "            ops = pretrained_model(imgs)\n",
    "            _, preds = torch.max(ops, 1)\n",
    "            \n",
    "            for j in range(imgs.size()[0]):\n",
    "                imgs_counter += 1\n",
    "                ax = plt.subplot(max_num_imgs//2, 2, imgs_counter)\n",
    "                ax.axis('off')\n",
    "                ax.set_title(f'pred: {classes_dict[int(preds[j])]}')\n",
    "                imageshow(imgs.cpu().data[j])\n",
    "\n",
    "                if imgs_counter == max_num_imgs:\n",
    "                    pretrained_model.train(mode=was_model_training)\n",
    "                    return\n",
    "        pretrained_model.train(mode=was_model_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg13(pretrained=True) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
