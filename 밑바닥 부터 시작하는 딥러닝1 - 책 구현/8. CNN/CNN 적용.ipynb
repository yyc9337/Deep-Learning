{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9b2590",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-03-22T08:51:37.846Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.3003816311739143\n",
      "=== epoch:1, train acc:0.227, test acc:0.208 ===\n",
      "train loss:2.299077583996624\n",
      "train loss:2.2935383213572846\n",
      "train loss:2.2906437377243902\n",
      "train loss:2.286051763888552\n",
      "train loss:2.2753990938560804\n",
      "train loss:2.2716709359231553\n",
      "train loss:2.248615909668375\n",
      "train loss:2.2334105078932227\n",
      "train loss:2.213056298824245\n",
      "train loss:2.1670693859829204\n",
      "train loss:2.1614440967870947\n",
      "train loss:2.123807093355354\n",
      "train loss:2.0720542530476944\n",
      "train loss:2.0194114103458416\n",
      "train loss:1.954806472749916\n",
      "train loss:1.9168770627883887\n",
      "train loss:1.8013325967453429\n",
      "train loss:1.7365183122528136\n",
      "train loss:1.7110038450524139\n",
      "train loss:1.6168009854605827\n",
      "train loss:1.4693284378581941\n",
      "train loss:1.4821000899568202\n",
      "train loss:1.3959220757411668\n",
      "train loss:1.203227051896086\n",
      "train loss:1.109980882430469\n",
      "train loss:1.1267443279046057\n",
      "train loss:1.0588574202820837\n",
      "train loss:1.0671870498201037\n",
      "train loss:1.0426293942216887\n",
      "train loss:0.9123970665127343\n",
      "train loss:0.8634119313459558\n",
      "train loss:0.7417673182033779\n",
      "train loss:0.8890140895804908\n",
      "train loss:0.7761803663519785\n",
      "train loss:0.7618123830922106\n",
      "train loss:0.7691574490858213\n",
      "train loss:0.7647581603478106\n",
      "train loss:0.7150150931737587\n",
      "train loss:0.4865504287525391\n",
      "train loss:0.6396288377678833\n",
      "train loss:0.6441524848947959\n",
      "train loss:0.577269640080376\n",
      "train loss:0.9500946525251728\n",
      "train loss:0.39252703593338134\n",
      "train loss:0.4883442782331766\n",
      "train loss:0.4316441826238848\n",
      "train loss:0.778117221651197\n",
      "train loss:0.5508022309067684\n",
      "train loss:0.5878649832823271\n",
      "train loss:0.6812635739389725\n",
      "train loss:0.4216157212470703\n",
      "train loss:0.5720988470508575\n",
      "train loss:0.5127089003210598\n",
      "train loss:0.4850881520706538\n",
      "train loss:0.4890646614620659\n",
      "train loss:0.30540564295265354\n",
      "train loss:0.65877410594105\n",
      "train loss:0.6810102260787194\n",
      "train loss:0.5199372798230523\n",
      "train loss:0.5459010705720031\n",
      "train loss:0.43748759697946304\n",
      "train loss:0.45982460026955807\n",
      "train loss:0.4156577979643583\n",
      "train loss:0.5316095850154093\n",
      "train loss:0.4507957315130767\n",
      "train loss:0.5455083975351885\n",
      "train loss:0.4207096104561003\n",
      "train loss:0.3859037050440373\n",
      "train loss:0.4125964609470062\n",
      "train loss:0.4409077172739758\n",
      "train loss:0.23151711475572725\n",
      "train loss:0.3015305323499556\n",
      "train loss:0.38012970162205045\n",
      "train loss:0.4056355482881092\n",
      "train loss:0.39666933905740065\n",
      "train loss:0.4306543285490881\n",
      "train loss:0.4414831059033603\n",
      "train loss:0.29739439399997986\n",
      "train loss:0.29576996153606044\n",
      "train loss:0.32907122232727815\n",
      "train loss:0.38714230015015494\n",
      "train loss:0.6359104087871102\n",
      "train loss:0.30745628800797564\n",
      "train loss:0.23041663633447723\n",
      "train loss:0.31187248984839466\n",
      "train loss:0.3866119936070112\n",
      "train loss:0.5020731808937614\n",
      "train loss:0.4660028624884475\n",
      "train loss:0.3273973058617131\n",
      "train loss:0.3445335408214866\n",
      "train loss:0.28357392814548005\n",
      "train loss:0.22859486057592482\n",
      "train loss:0.31727500539195097\n",
      "train loss:0.63758018457539\n",
      "train loss:0.3547562342865432\n",
      "train loss:0.414035919154853\n",
      "train loss:0.4708927296847103\n",
      "train loss:0.18201870924513341\n",
      "train loss:0.26006125913779343\n",
      "train loss:0.4023602223824902\n",
      "train loss:0.3732633621660814\n",
      "train loss:0.226577923997731\n",
      "train loss:0.38992987570932214\n",
      "train loss:0.37096967221552923\n",
      "train loss:0.3254353434016429\n",
      "train loss:0.3388953720415076\n",
      "train loss:0.3474196525197217\n",
      "train loss:0.3405893654494348\n",
      "train loss:0.2398226366411847\n",
      "train loss:0.3256546254060966\n",
      "train loss:0.270110138341199\n",
      "train loss:0.3130778884907709\n",
      "train loss:0.3381234411031739\n",
      "train loss:0.3994352151083993\n",
      "train loss:0.23134661335954437\n",
      "train loss:0.39767925164557005\n",
      "train loss:0.29778520693802374\n",
      "train loss:0.31560533106685196\n",
      "train loss:0.31757278214563756\n",
      "train loss:0.3287980032598452\n",
      "train loss:0.3546397172659354\n",
      "train loss:0.270743699220318\n",
      "train loss:0.2776635150625322\n",
      "train loss:0.21622190258118532\n",
      "train loss:0.30084100771860084\n",
      "train loss:0.3624305679844199\n",
      "train loss:0.21006929178280687\n",
      "train loss:0.6046085851942875\n",
      "train loss:0.27845574477940854\n",
      "train loss:0.3561595012315511\n",
      "train loss:0.2750548444489683\n",
      "train loss:0.32639090749038424\n",
      "train loss:0.4199135398838819\n",
      "train loss:0.2711256797406282\n",
      "train loss:0.3791822703709515\n",
      "train loss:0.35733162113346184\n",
      "train loss:0.2830736302114366\n",
      "train loss:0.5036422168805579\n",
      "train loss:0.32343631406753237\n",
      "train loss:0.2261842525213186\n",
      "train loss:0.2465586963297715\n",
      "train loss:0.35967455499010315\n",
      "train loss:0.3517631509972526\n",
      "train loss:0.4491803156413222\n",
      "train loss:0.3435885173691095\n",
      "train loss:0.4563456379914409\n",
      "train loss:0.260203444737224\n",
      "train loss:0.42248099417200663\n",
      "train loss:0.27592889476789023\n",
      "train loss:0.343177190338118\n",
      "train loss:0.3310448253622291\n",
      "train loss:0.3311484381528272\n",
      "train loss:0.4021898609907764\n",
      "train loss:0.3719846853824464\n",
      "train loss:0.26869877430706574\n",
      "train loss:0.31666530389211706\n",
      "train loss:0.30147098999583866\n",
      "train loss:0.26357541619442487\n",
      "train loss:0.43078367182582766\n",
      "train loss:0.3138218411607868\n",
      "train loss:0.40978360239043243\n",
      "train loss:0.3264753468049281\n",
      "train loss:0.3358506860992964\n",
      "train loss:0.29327654300090644\n",
      "train loss:0.24825616317285065\n",
      "train loss:0.24399570217583819\n",
      "train loss:0.22015233221500444\n",
      "train loss:0.3894003175955711\n",
      "train loss:0.3731368030046221\n",
      "train loss:0.34910284553795506\n",
      "train loss:0.28112007785825255\n",
      "train loss:0.3691617521997154\n",
      "train loss:0.28678901410281776\n",
      "train loss:0.30441790039494143\n",
      "train loss:0.2388453223975378\n",
      "train loss:0.17278676258800868\n",
      "train loss:0.3234483965421531\n",
      "train loss:0.14622384589663975\n",
      "train loss:0.36450946127577993\n",
      "train loss:0.30628583496269596\n",
      "train loss:0.25936386201008776\n",
      "train loss:0.1360185215995341\n",
      "train loss:0.3536826959133339\n",
      "train loss:0.37375122704313424\n",
      "train loss:0.2701043518394779\n",
      "train loss:0.353438679351068\n",
      "train loss:0.24069697562805145\n",
      "train loss:0.2641486999388248\n",
      "train loss:0.1499172199586681\n",
      "train loss:0.1718972688093739\n",
      "train loss:0.201351199094289\n",
      "train loss:0.28476135008376424\n",
      "train loss:0.20520523697672197\n",
      "train loss:0.2788661057850709\n",
      "train loss:0.20211412698909942\n",
      "train loss:0.3187315658035116\n",
      "train loss:0.3190378274815218\n",
      "train loss:0.2958826727019164\n",
      "train loss:0.2066736260754619\n",
      "train loss:0.1815539321515461\n",
      "train loss:0.35248721985242654\n",
      "train loss:0.3464683465045118\n",
      "train loss:0.19516932785973753\n",
      "train loss:0.3987211579425716\n",
      "train loss:0.2987377736001904\n",
      "train loss:0.23643743031791595\n",
      "train loss:0.23537846031452714\n",
      "train loss:0.20509222719577694\n",
      "train loss:0.32906241172878814\n",
      "train loss:0.2315330306652431\n",
      "train loss:0.20270396051990405\n",
      "train loss:0.1562390733579226\n",
      "train loss:0.23080242625287323\n",
      "train loss:0.224281370813863\n",
      "train loss:0.09151205522763274\n",
      "train loss:0.23692436748636442\n",
      "train loss:0.42700167660204746\n",
      "train loss:0.15498261283514292\n",
      "train loss:0.2817921275242262\n",
      "train loss:0.26390376608564986\n",
      "train loss:0.1887289792852021\n",
      "train loss:0.22866381438428887\n",
      "train loss:0.31924716931216013\n",
      "train loss:0.3173104557054495\n",
      "train loss:0.20866083107741226\n",
      "train loss:0.16135059945299246\n",
      "train loss:0.15933213832099816\n",
      "train loss:0.2040662252021399\n",
      "train loss:0.2747829496347953\n",
      "train loss:0.19107925297359565\n",
      "train loss:0.3314436409125891\n",
      "train loss:0.34433355440869695\n",
      "train loss:0.25036559775410144\n",
      "train loss:0.24606093104630655\n",
      "train loss:0.21073661450906012\n",
      "train loss:0.20162005483488132\n",
      "train loss:0.2548499922788119\n",
      "train loss:0.15910733497616666\n",
      "train loss:0.20204003411133734\n",
      "train loss:0.3001092575661696\n",
      "train loss:0.17802684144264\n",
      "train loss:0.30405569440121927\n",
      "train loss:0.205917687307707\n",
      "train loss:0.2166490950890157\n",
      "train loss:0.3927157845026098\n",
      "train loss:0.26270753181376105\n",
      "train loss:0.34114703034816435\n",
      "train loss:0.20968364803315037\n",
      "train loss:0.16439156594937768\n",
      "train loss:0.2604212966853342\n",
      "train loss:0.22650350702248484\n",
      "train loss:0.19156445385327772\n",
      "train loss:0.27064190590203174\n",
      "train loss:0.16087468531800656\n",
      "train loss:0.18645097692922386\n",
      "train loss:0.2801601212399575\n",
      "train loss:0.20482771493395868\n",
      "train loss:0.23432423562579224\n",
      "train loss:0.41927067296548887\n",
      "train loss:0.14122930655805832\n",
      "train loss:0.18958282693626163\n",
      "train loss:0.13663078065399373\n",
      "train loss:0.21034247425467562\n",
      "train loss:0.2909790768383695\n",
      "train loss:0.13608117192194005\n",
      "train loss:0.28147763693549\n",
      "train loss:0.13620670153867467\n",
      "train loss:0.23286239298770348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.1811503586972891\n",
      "train loss:0.22162159839692858\n",
      "train loss:0.3591568790173391\n",
      "train loss:0.1352985176234201\n",
      "train loss:0.2643336109679574\n",
      "train loss:0.24795428282815013\n",
      "train loss:0.23510884544017638\n",
      "train loss:0.20876802197332484\n",
      "train loss:0.20244939067743026\n",
      "train loss:0.18757883332858769\n",
      "train loss:0.21856665027385916\n",
      "train loss:0.32219835240171674\n",
      "train loss:0.295722644794749\n",
      "train loss:0.30426957455869785\n",
      "train loss:0.2114120229605342\n",
      "train loss:0.17614708960115533\n",
      "train loss:0.31870712988899075\n",
      "train loss:0.14565070734128815\n",
      "train loss:0.25263759630039645\n",
      "train loss:0.21448619226279764\n",
      "train loss:0.24476793638234412\n",
      "train loss:0.20956582104416474\n",
      "train loss:0.16228524246165926\n",
      "train loss:0.140894718875212\n",
      "train loss:0.20207164959374302\n",
      "train loss:0.13127390118387594\n",
      "train loss:0.20581914218996722\n",
      "train loss:0.10475909144749297\n",
      "train loss:0.2266254423010797\n",
      "train loss:0.21341009488066734\n",
      "train loss:0.14381569579025583\n",
      "train loss:0.1832008237182341\n",
      "train loss:0.14699611637126125\n",
      "train loss:0.11239317121090436\n",
      "train loss:0.15074441223761004\n",
      "train loss:0.15881700236831361\n",
      "train loss:0.13028995998048562\n",
      "train loss:0.10553567661176436\n",
      "train loss:0.24890348352044928\n",
      "train loss:0.1719822818443208\n",
      "train loss:0.36515183503012116\n",
      "train loss:0.12347205355865701\n",
      "train loss:0.20142574691838833\n",
      "train loss:0.13878842532106062\n",
      "train loss:0.23099024367792384\n",
      "train loss:0.21971137626251314\n",
      "train loss:0.21462529740946185\n",
      "train loss:0.12535737188007717\n",
      "train loss:0.13021813968134394\n",
      "train loss:0.10554673997461647\n",
      "train loss:0.21271988689525276\n",
      "train loss:0.2978252097471545\n",
      "train loss:0.22887583824353638\n",
      "train loss:0.06268802222840546\n",
      "train loss:0.20526082997337394\n",
      "train loss:0.24400668815239152\n",
      "train loss:0.1993377243555805\n",
      "train loss:0.13651926265801914\n",
      "train loss:0.18397619208866509\n",
      "train loss:0.259000427929056\n",
      "train loss:0.2123855047859214\n",
      "train loss:0.12967168889706335\n",
      "train loss:0.24132216281140895\n",
      "train loss:0.16246132550970604\n",
      "train loss:0.13736343516164487\n",
      "train loss:0.10083932253276974\n",
      "train loss:0.21811332700664884\n",
      "train loss:0.19593023225403106\n",
      "train loss:0.11959532406901166\n",
      "train loss:0.16473741416442955\n",
      "train loss:0.19651452192942448\n",
      "train loss:0.1886022440239649\n",
      "train loss:0.09299458195340077\n",
      "train loss:0.13043021919359193\n",
      "train loss:0.11187226850564348\n",
      "train loss:0.179437115512737\n",
      "train loss:0.13479127464199328\n",
      "train loss:0.18469474198190997\n",
      "train loss:0.33244976265902343\n",
      "train loss:0.18491179121632098\n",
      "train loss:0.22098806308639524\n",
      "train loss:0.10065010146267576\n",
      "train loss:0.2770086864940776\n",
      "train loss:0.18017618813156325\n",
      "train loss:0.1346333061627479\n",
      "train loss:0.11324629483470633\n",
      "train loss:0.08265456798978148\n",
      "train loss:0.17571490209984567\n",
      "train loss:0.10497114400254118\n",
      "train loss:0.13196094371754494\n",
      "train loss:0.14964770769409766\n",
      "train loss:0.1707385348077683\n",
      "train loss:0.1967738580376016\n",
      "train loss:0.2341936338901868\n",
      "train loss:0.12029990990027079\n",
      "train loss:0.10897851125682352\n",
      "train loss:0.21541395501177263\n",
      "train loss:0.19353008892504886\n",
      "train loss:0.24683287927926273\n",
      "train loss:0.11063023778229862\n",
      "train loss:0.09517449712900435\n",
      "train loss:0.1275004525280147\n",
      "train loss:0.12377811948686418\n",
      "train loss:0.17829189302899148\n",
      "train loss:0.1459616084204696\n",
      "train loss:0.1560031738757891\n",
      "train loss:0.08814699274880335\n",
      "train loss:0.22926346977588274\n",
      "train loss:0.17011973126330943\n",
      "train loss:0.31063191069473656\n",
      "train loss:0.15662752294967885\n",
      "train loss:0.23074040587641945\n",
      "train loss:0.13117950076072352\n",
      "train loss:0.08204758470270201\n",
      "train loss:0.17411499785792459\n",
      "train loss:0.09908308805506931\n",
      "train loss:0.1142787736910154\n",
      "train loss:0.0987580743616343\n",
      "train loss:0.11342300337808923\n",
      "train loss:0.09631082330596741\n",
      "train loss:0.3338068389354465\n",
      "train loss:0.2035581614764322\n",
      "train loss:0.12739965956539873\n",
      "train loss:0.168534354472573\n",
      "train loss:0.1977583780117512\n",
      "train loss:0.31539046920063774\n",
      "train loss:0.4125238359475167\n",
      "train loss:0.15502003308021645\n",
      "train loss:0.25536049664456933\n",
      "train loss:0.21130592667714962\n",
      "train loss:0.1732970745726168\n",
      "train loss:0.18829481097954182\n",
      "train loss:0.07981767829351659\n",
      "train loss:0.12014652295739699\n",
      "train loss:0.22686040527104726\n",
      "train loss:0.17938401749975771\n",
      "train loss:0.15225571672261554\n",
      "train loss:0.1910929797775159\n",
      "train loss:0.12577173187311097\n",
      "train loss:0.10270167087250505\n",
      "train loss:0.12813809524958555\n",
      "train loss:0.11894527289001605\n",
      "train loss:0.3219679220969091\n",
      "train loss:0.12930603975688693\n",
      "train loss:0.16511233863967534\n",
      "train loss:0.23461428440642912\n",
      "train loss:0.19495982946959445\n",
      "train loss:0.139840992360413\n",
      "train loss:0.14738508338755377\n",
      "train loss:0.0962842013094474\n",
      "train loss:0.21280194322172744\n",
      "train loss:0.13210740297925208\n",
      "train loss:0.1523259419876272\n",
      "train loss:0.11807747664771769\n",
      "train loss:0.09564821980168095\n",
      "train loss:0.09186256559886505\n",
      "train loss:0.10939512705702711\n",
      "train loss:0.14825552497734978\n",
      "train loss:0.13577156646960073\n",
      "train loss:0.07335240780887459\n",
      "train loss:0.14412721141361118\n",
      "train loss:0.14466202596818367\n",
      "train loss:0.17940563509401297\n",
      "train loss:0.05699636552995895\n",
      "train loss:0.09078566056970044\n",
      "train loss:0.2002319234070987\n",
      "train loss:0.24239418666399068\n",
      "train loss:0.10005634703820016\n",
      "train loss:0.09376771814304131\n",
      "train loss:0.15062613158312133\n",
      "train loss:0.12415070886760525\n",
      "train loss:0.14598554751362777\n",
      "train loss:0.12423894518211777\n",
      "train loss:0.08313328055259797\n",
      "train loss:0.054550115546382776\n",
      "train loss:0.27112169688811716\n",
      "train loss:0.1341376515317159\n",
      "train loss:0.05672938549534827\n",
      "train loss:0.10737748135792677\n",
      "train loss:0.07052427789467011\n",
      "train loss:0.18972582967681184\n",
      "train loss:0.09219485041799987\n",
      "train loss:0.149023668925028\n",
      "train loss:0.2549118315129796\n",
      "train loss:0.16132082933568687\n",
      "train loss:0.18242581756620907\n",
      "train loss:0.0971957073409882\n",
      "train loss:0.08861372108621872\n",
      "train loss:0.10294234289038538\n",
      "train loss:0.2510235249374417\n",
      "train loss:0.21794196087815135\n",
      "train loss:0.1344423763608695\n",
      "train loss:0.0679989293961166\n",
      "train loss:0.18187257161817424\n",
      "train loss:0.10468869407907222\n",
      "train loss:0.06985435378878314\n",
      "train loss:0.07704960982253199\n",
      "train loss:0.156500807064141\n",
      "train loss:0.05988493871499742\n",
      "train loss:0.1116790535093204\n",
      "train loss:0.10745605898015753\n",
      "train loss:0.14920410719795207\n",
      "train loss:0.17005279013353694\n",
      "train loss:0.07070488217407064\n",
      "train loss:0.06996148143791495\n",
      "train loss:0.17983715946137224\n",
      "train loss:0.08698697185335208\n",
      "train loss:0.10183145486266325\n",
      "train loss:0.2600809926989118\n",
      "train loss:0.14694616973960362\n",
      "train loss:0.1601907241886142\n",
      "train loss:0.16493856493910364\n",
      "train loss:0.11127412633404815\n",
      "train loss:0.15099668311315648\n",
      "train loss:0.20814773192444208\n",
      "train loss:0.13975006002120907\n",
      "train loss:0.11182754821865107\n",
      "train loss:0.1222413455671088\n",
      "train loss:0.1783093166640397\n",
      "train loss:0.09693441484313127\n",
      "train loss:0.13085826431384087\n",
      "train loss:0.3020670184110297\n",
      "train loss:0.11475849329020767\n",
      "train loss:0.08252077930936971\n",
      "train loss:0.12790661580588036\n",
      "train loss:0.13722738888708647\n",
      "train loss:0.12044440269540833\n",
      "train loss:0.08884970144303002\n",
      "train loss:0.15148369393006844\n",
      "train loss:0.08515685842340817\n",
      "train loss:0.16477494178903196\n",
      "train loss:0.11614280996376297\n",
      "train loss:0.09527126218655058\n",
      "train loss:0.1425718861524464\n",
      "train loss:0.126438372536951\n",
      "train loss:0.07972496402428078\n",
      "train loss:0.1099938311052524\n",
      "train loss:0.13012341558688642\n",
      "train loss:0.20626106032945657\n",
      "train loss:0.09572674327375989\n",
      "train loss:0.11166065304425117\n",
      "train loss:0.17040583922602046\n",
      "train loss:0.09901030547683948\n",
      "train loss:0.03689516387891068\n",
      "train loss:0.173352505421755\n",
      "train loss:0.15720270306745\n",
      "train loss:0.19364846595390695\n",
      "train loss:0.18146566122355232\n",
      "train loss:0.08087136504928746\n",
      "train loss:0.14999624677159054\n",
      "train loss:0.12980290891900362\n",
      "train loss:0.1103162730047146\n",
      "train loss:0.13239606797393969\n",
      "train loss:0.1326949338990202\n",
      "train loss:0.23992082277019214\n",
      "train loss:0.06890120480332594\n",
      "train loss:0.0829502306799082\n",
      "train loss:0.07353734658648763\n",
      "train loss:0.1717610738046603\n",
      "train loss:0.1524637738900135\n",
      "train loss:0.04653715502892029\n",
      "train loss:0.19039816248274227\n",
      "train loss:0.16048313797716632\n",
      "train loss:0.2566516294025501\n",
      "train loss:0.0981286761610699\n",
      "train loss:0.09512665393938996\n",
      "train loss:0.07578530883132593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.12501018944126505\n",
      "train loss:0.08202280254199648\n",
      "train loss:0.11720976362321708\n",
      "train loss:0.07645862382290186\n",
      "train loss:0.08217393853048571\n",
      "train loss:0.04518918157140108\n",
      "train loss:0.1363610339317857\n",
      "train loss:0.20822785024907728\n",
      "train loss:0.31642839598797523\n",
      "train loss:0.07205305976756021\n",
      "train loss:0.09865137040033453\n",
      "train loss:0.1769948096781401\n",
      "train loss:0.0981828993226258\n",
      "train loss:0.18892172403931995\n",
      "train loss:0.13698444654766617\n",
      "train loss:0.16610629945741576\n",
      "train loss:0.08856885017763987\n",
      "train loss:0.05645056788619583\n",
      "train loss:0.19958546065707874\n",
      "train loss:0.14769968681889348\n",
      "train loss:0.0882841322232885\n",
      "train loss:0.07382012499952642\n",
      "train loss:0.15591986102641553\n",
      "train loss:0.12709191213123014\n",
      "train loss:0.12975377996124196\n",
      "train loss:0.06144774849706411\n",
      "train loss:0.05268812614622059\n",
      "train loss:0.094155246657864\n",
      "train loss:0.1255647449831602\n",
      "train loss:0.15078448997803703\n",
      "train loss:0.18769483618183508\n",
      "train loss:0.04471257294777306\n",
      "train loss:0.14849584690919507\n",
      "train loss:0.12729046002531144\n",
      "train loss:0.06871355551407662\n",
      "train loss:0.046300737063163365\n",
      "train loss:0.10517621257988545\n",
      "train loss:0.11499414946896667\n",
      "train loss:0.19177009884173363\n",
      "train loss:0.08405286859182329\n",
      "train loss:0.07602949112557945\n",
      "train loss:0.09857850355346935\n",
      "train loss:0.16818473319184674\n",
      "train loss:0.040857188439294756\n",
      "train loss:0.035027459122223915\n",
      "train loss:0.11233652291496449\n",
      "train loss:0.13486913620804675\n",
      "train loss:0.06995492539551314\n",
      "train loss:0.12886932555530797\n",
      "train loss:0.07076066706777198\n",
      "train loss:0.08292671300434701\n",
      "train loss:0.07724100260621819\n",
      "train loss:0.04546394276137655\n",
      "train loss:0.06575354993028401\n",
      "train loss:0.12432216973364658\n",
      "train loss:0.08310116670841096\n",
      "train loss:0.20872579287733883\n",
      "train loss:0.043414181233297516\n",
      "train loss:0.07544990489131188\n",
      "train loss:0.10100115260853365\n",
      "train loss:0.16921487248262848\n",
      "train loss:0.06132122815281209\n",
      "train loss:0.06503222943143794\n",
      "train loss:0.0633409132423411\n",
      "train loss:0.12142572669093439\n",
      "=== epoch:2, train acc:0.968, test acc:0.964 ===\n",
      "train loss:0.09596425841736496\n",
      "train loss:0.2060664695407372\n",
      "train loss:0.04321235760682776\n",
      "train loss:0.030597965443921953\n",
      "train loss:0.10828036309759251\n",
      "train loss:0.10842736863028274\n",
      "train loss:0.0872389455391619\n",
      "train loss:0.0826305413346079\n",
      "train loss:0.0723432847912486\n",
      "train loss:0.13341165570955937\n",
      "train loss:0.12183775981609134\n",
      "train loss:0.09145260060220366\n",
      "train loss:0.09843141031246998\n",
      "train loss:0.09924345512428401\n",
      "train loss:0.12332521664180524\n",
      "train loss:0.08384386738207099\n",
      "train loss:0.09783826303851453\n",
      "train loss:0.18418564683751282\n",
      "train loss:0.05145676421809694\n",
      "train loss:0.09717405393771697\n",
      "train loss:0.09925734275447987\n",
      "train loss:0.09491686171239035\n",
      "train loss:0.07409129622255894\n",
      "train loss:0.06242359070931112\n",
      "train loss:0.04690119357924607\n",
      "train loss:0.06643271053312284\n",
      "train loss:0.1328892420976873\n",
      "train loss:0.11921383911041787\n",
      "train loss:0.11487658127066877\n",
      "train loss:0.097316639196329\n",
      "train loss:0.08846117278318631\n",
      "train loss:0.09027260829531038\n",
      "train loss:0.10572956936892965\n",
      "train loss:0.045662929616717224\n",
      "train loss:0.060377000629152675\n",
      "train loss:0.1203419064144239\n",
      "train loss:0.07970112856420646\n",
      "train loss:0.13641953200347276\n",
      "train loss:0.07389891161834142\n",
      "train loss:0.06514741167169641\n",
      "train loss:0.11926307242794332\n",
      "train loss:0.12759080479147966\n",
      "train loss:0.07246285825862998\n",
      "train loss:0.13598601624273723\n",
      "train loss:0.09222178931455734\n",
      "train loss:0.1524314421464372\n",
      "train loss:0.11657026330438017\n",
      "train loss:0.09546839416919876\n",
      "train loss:0.14723866125608692\n",
      "train loss:0.1390832230234047\n",
      "train loss:0.06748787114913343\n",
      "train loss:0.10751430211095116\n",
      "train loss:0.0976066735326671\n",
      "train loss:0.04759647424097171\n",
      "train loss:0.05696029418543252\n",
      "train loss:0.04948881914445125\n",
      "train loss:0.14255283944685274\n",
      "train loss:0.12682942571181366\n",
      "train loss:0.08690749761399916\n",
      "train loss:0.06541123265682422\n",
      "train loss:0.12353885346385185\n",
      "train loss:0.11210075838019622\n",
      "train loss:0.10000020405993591\n",
      "train loss:0.0776193154469914\n",
      "train loss:0.10779584362974086\n",
      "train loss:0.06551592229046474\n",
      "train loss:0.0880094068226747\n",
      "train loss:0.084224671414956\n",
      "train loss:0.14069396820045965\n",
      "train loss:0.1535532569098273\n",
      "train loss:0.04525812848538182\n",
      "train loss:0.06270000332014057\n",
      "train loss:0.10057486600329145\n",
      "train loss:0.12673115109741476\n",
      "train loss:0.07144469652909376\n",
      "train loss:0.039535428767360936\n",
      "train loss:0.12945482329947836\n",
      "train loss:0.11574258865137722\n",
      "train loss:0.056736565825333256\n",
      "train loss:0.0663032440160992\n",
      "train loss:0.059753874142477875\n",
      "train loss:0.11264211849500104\n",
      "train loss:0.11102718008145146\n",
      "train loss:0.06007937800273921\n",
      "train loss:0.12108037461137937\n",
      "train loss:0.03876992821688026\n",
      "train loss:0.11653106719760369\n",
      "train loss:0.073194648502022\n",
      "train loss:0.06419413534364676\n",
      "train loss:0.07581223632252958\n",
      "train loss:0.08130370846231337\n",
      "train loss:0.05537658922511651\n",
      "train loss:0.037463632052642186\n",
      "train loss:0.053978964013933005\n",
      "train loss:0.06875787385684674\n",
      "train loss:0.08334389079575062\n",
      "train loss:0.09782712258907321\n",
      "train loss:0.07133043056820398\n",
      "train loss:0.10621663619991416\n",
      "train loss:0.09896045712866818\n",
      "train loss:0.040818687537772125\n",
      "train loss:0.059209143586402974\n",
      "train loss:0.06384142409740981\n",
      "train loss:0.08947703713923598\n",
      "train loss:0.07662614059825767\n",
      "train loss:0.107418913861319\n",
      "train loss:0.034152810814881\n",
      "train loss:0.039807583853716355\n",
      "train loss:0.20137126958721613\n",
      "train loss:0.03662431670788231\n",
      "train loss:0.11635591229761533\n",
      "train loss:0.1618152504968921\n",
      "train loss:0.04981669098402741\n",
      "train loss:0.0612998003159068\n",
      "train loss:0.13865101857930096\n",
      "train loss:0.1442778494444498\n",
      "train loss:0.14420557814393717\n",
      "train loss:0.09335345812013097\n",
      "train loss:0.0665024684264143\n",
      "train loss:0.0686287761688899\n",
      "train loss:0.06951412096745796\n",
      "train loss:0.06818505795625017\n",
      "train loss:0.06630737539694512\n",
      "train loss:0.06114224894964883\n",
      "train loss:0.12415085504970554\n",
      "train loss:0.028091227858826628\n",
      "train loss:0.08829088324468756\n",
      "train loss:0.05208070421102791\n",
      "train loss:0.1246031838270217\n",
      "train loss:0.11448823694282505\n",
      "train loss:0.10053404989426044\n",
      "train loss:0.08337737717136662\n",
      "train loss:0.055589189356715044\n",
      "train loss:0.1499001851147127\n",
      "train loss:0.10929378168797774\n",
      "train loss:0.05034563438613749\n",
      "train loss:0.0930399828102898\n",
      "train loss:0.14030749850992114\n",
      "train loss:0.10718285673621115\n",
      "train loss:0.06136784550018902\n",
      "train loss:0.05103721437281601\n",
      "train loss:0.07111250332067308\n",
      "train loss:0.08394251136895471\n",
      "train loss:0.06430904986324106\n",
      "train loss:0.0978918257635051\n",
      "train loss:0.08873558824410001\n",
      "train loss:0.0673741503912326\n",
      "train loss:0.048371469760595386\n",
      "train loss:0.06964288547326682\n",
      "train loss:0.045209077379931885\n",
      "train loss:0.06999659046240449\n",
      "train loss:0.10310367071705077\n",
      "train loss:0.023082706878837022\n",
      "train loss:0.07329506229650962\n",
      "train loss:0.06714492319247119\n",
      "train loss:0.20936640894843947\n",
      "train loss:0.17428774814516962\n",
      "train loss:0.1101783910052431\n",
      "train loss:0.15209940392758614\n",
      "train loss:0.06291923818554496\n",
      "train loss:0.08047460828864436\n",
      "train loss:0.0972340411697567\n",
      "train loss:0.06610246349243237\n",
      "train loss:0.057835343220022165\n",
      "train loss:0.04085770664279448\n",
      "train loss:0.12919454408400907\n",
      "train loss:0.11310340760594725\n",
      "train loss:0.10698555915996062\n",
      "train loss:0.1743807124483054\n",
      "train loss:0.12277975672049282\n",
      "train loss:0.07266015439227017\n",
      "train loss:0.09645814501279404\n",
      "train loss:0.07433548006965944\n",
      "train loss:0.08257747880538753\n",
      "train loss:0.05786466785739764\n",
      "train loss:0.04583829456192851\n",
      "train loss:0.09320152767585618\n",
      "train loss:0.05191299792568887\n",
      "train loss:0.10504962641038638\n",
      "train loss:0.1179893119609086\n",
      "train loss:0.0631231899792602\n",
      "train loss:0.05334090333207823\n",
      "train loss:0.055242949072804234\n",
      "train loss:0.12643187588819457\n",
      "train loss:0.17819706876588592\n",
      "train loss:0.027572453557103693\n",
      "train loss:0.08865541389222152\n",
      "train loss:0.033103092028889836\n",
      "train loss:0.045432388967263815\n",
      "train loss:0.05395806140535146\n",
      "train loss:0.036382836477525334\n",
      "train loss:0.06000109356929764\n",
      "train loss:0.11031987077526406\n",
      "train loss:0.03745723551766799\n",
      "train loss:0.11140462207679257\n",
      "train loss:0.020271853401969547\n",
      "train loss:0.06149296347726974\n",
      "train loss:0.04018443719102445\n",
      "train loss:0.02916467156182215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.04134855626189048\n",
      "train loss:0.16629183169458703\n",
      "train loss:0.03309531684654799\n",
      "train loss:0.05777047134212504\n",
      "train loss:0.04651088231830044\n",
      "train loss:0.1266596275162763\n",
      "train loss:0.11039242169938618\n",
      "train loss:0.019506042218035157\n",
      "train loss:0.06936708757077543\n",
      "train loss:0.04065536626613817\n",
      "train loss:0.02662052964142734\n",
      "train loss:0.09862677818449228\n",
      "train loss:0.035097436889929\n",
      "train loss:0.033100622771400454\n",
      "train loss:0.03325543293572294\n",
      "train loss:0.07623192580134804\n",
      "train loss:0.09062017738429219\n",
      "train loss:0.04985672400570249\n",
      "train loss:0.08166709660579025\n",
      "train loss:0.0487386705476342\n",
      "train loss:0.04808906164582866\n",
      "train loss:0.021858345109662825\n",
      "train loss:0.05095191005010914\n",
      "train loss:0.07507329497515873\n",
      "train loss:0.055651112423373304\n",
      "train loss:0.06739036392111351\n",
      "train loss:0.17983687784617916\n",
      "train loss:0.16480061491712056\n",
      "train loss:0.030602713728593828\n",
      "train loss:0.06724805846101091\n",
      "train loss:0.0885593114801399\n",
      "train loss:0.08737998802001058\n",
      "train loss:0.05826308137019238\n",
      "train loss:0.05330687397363485\n",
      "train loss:0.06828478686357765\n",
      "train loss:0.08944984144439838\n",
      "train loss:0.14029726946161725\n",
      "train loss:0.07167015546776014\n",
      "train loss:0.05523772764173744\n",
      "train loss:0.12569634532683616\n",
      "train loss:0.08184503692855191\n",
      "train loss:0.048088248308264504\n",
      "train loss:0.09932457432418666\n",
      "train loss:0.037894495034663515\n",
      "train loss:0.09925720173211275\n",
      "train loss:0.11271049911986147\n",
      "train loss:0.04999735338059171\n",
      "train loss:0.09037293578364698\n",
      "train loss:0.1105745006333483\n",
      "train loss:0.07965134079017633\n",
      "train loss:0.07203799769431775\n",
      "train loss:0.08628054787926048\n",
      "train loss:0.053676159461700956\n",
      "train loss:0.057011610144277206\n",
      "train loss:0.05824957939406812\n",
      "train loss:0.08613395467255908\n",
      "train loss:0.06836240630335982\n",
      "train loss:0.10835551750020653\n",
      "train loss:0.019742618441621583\n",
      "train loss:0.03205577118755834\n",
      "train loss:0.08026294715110906\n",
      "train loss:0.08980424778089169\n",
      "train loss:0.039806613792447425\n",
      "train loss:0.04698036303518637\n",
      "train loss:0.07349992066019788\n",
      "train loss:0.09727745364485686\n",
      "train loss:0.018099216284676024\n",
      "train loss:0.026560712257745082\n",
      "train loss:0.07681976908266407\n",
      "train loss:0.06809355703093535\n",
      "train loss:0.05002508397503314\n",
      "train loss:0.03897337209223527\n",
      "train loss:0.07326989742640484\n",
      "train loss:0.09110999928829455\n",
      "train loss:0.2569616274209561\n",
      "train loss:0.047092511961879205\n",
      "train loss:0.1026998685190315\n",
      "train loss:0.07760854340497264\n",
      "train loss:0.06791324242360129\n",
      "train loss:0.03753458267661661\n",
      "train loss:0.07398734530421347\n",
      "train loss:0.07408597705662176\n",
      "train loss:0.04127977131135895\n",
      "train loss:0.10155833920887854\n",
      "train loss:0.05084393475399826\n",
      "train loss:0.08970328500248774\n",
      "train loss:0.05055405801673125\n",
      "train loss:0.0409245018132009\n",
      "train loss:0.06008793329573859\n",
      "train loss:0.044186864585881835\n",
      "train loss:0.04944844541159841\n",
      "train loss:0.09567252825564136\n",
      "train loss:0.06362373278914836\n",
      "train loss:0.14599545583708903\n",
      "train loss:0.04350812424133454\n",
      "train loss:0.043773998730056725\n",
      "train loss:0.06710807033398494\n",
      "train loss:0.04159322861181635\n",
      "train loss:0.06654512031308776\n",
      "train loss:0.09957138536141873\n",
      "train loss:0.04319072615883143\n",
      "train loss:0.11185823383795483\n",
      "train loss:0.07646704845694333\n",
      "train loss:0.14913710037070962\n",
      "train loss:0.0769257288995999\n",
      "train loss:0.08321550171189922\n",
      "train loss:0.04550064850313354\n",
      "train loss:0.0488843423959255\n",
      "train loss:0.02174097404999252\n",
      "train loss:0.03935934108879949\n",
      "train loss:0.05380493313264219\n",
      "train loss:0.09369709326845116\n",
      "train loss:0.021171746664272156\n",
      "train loss:0.05014564555527513\n",
      "train loss:0.1593414607448801\n",
      "train loss:0.07235017053144689\n",
      "train loss:0.207865323530852\n",
      "train loss:0.020937254732845894\n",
      "train loss:0.05065113976457686\n",
      "train loss:0.04039036761724499\n",
      "train loss:0.03246701340636796\n",
      "train loss:0.2134987581315992\n",
      "train loss:0.10530736307314167\n",
      "train loss:0.14776108879213953\n",
      "train loss:0.07562276915797778\n",
      "train loss:0.10598499318822156\n",
      "train loss:0.03427708212192955\n",
      "train loss:0.0964517901294117\n",
      "train loss:0.11720586133215315\n",
      "train loss:0.0793368251161824\n",
      "train loss:0.03987023078334306\n",
      "train loss:0.14078801051991086\n",
      "train loss:0.06945870692016137\n",
      "train loss:0.05277261184641757\n",
      "train loss:0.12315612460130991\n",
      "train loss:0.08980263863674115\n",
      "train loss:0.07250631548856747\n",
      "train loss:0.08719132750043687\n",
      "train loss:0.04760555943516066\n",
      "train loss:0.12113666048117051\n",
      "train loss:0.022342250060047312\n",
      "train loss:0.08968561268568584\n",
      "train loss:0.05301260575285499\n",
      "train loss:0.04294672428979018\n",
      "train loss:0.04944252653385581\n",
      "train loss:0.052998841623583065\n",
      "train loss:0.05073324348734205\n",
      "train loss:0.07243952973425431\n",
      "train loss:0.036231924638037885\n",
      "train loss:0.05154589060899475\n",
      "train loss:0.07031880996580413\n",
      "train loss:0.02699866039450563\n",
      "train loss:0.07535316139895265\n",
      "train loss:0.05610345579806928\n",
      "train loss:0.024195904490455784\n",
      "train loss:0.07670654223505774\n",
      "train loss:0.0642863734223536\n",
      "train loss:0.0677503482507042\n",
      "train loss:0.023834529427990497\n",
      "train loss:0.03841399675283639\n",
      "train loss:0.06927721974131142\n",
      "train loss:0.02896263516063922\n",
      "train loss:0.0698915014913386\n",
      "train loss:0.0739616856885855\n",
      "train loss:0.07899785504146009\n",
      "train loss:0.07767791797731954\n",
      "train loss:0.04782387232858618\n",
      "train loss:0.12557467407001546\n",
      "train loss:0.05297583735688417\n",
      "train loss:0.05195012534555035\n",
      "train loss:0.06954732212926436\n",
      "train loss:0.05998831508502095\n",
      "train loss:0.009974123251374624\n",
      "train loss:0.04028760400578177\n",
      "train loss:0.055280386614087657\n",
      "train loss:0.05203976772065635\n",
      "train loss:0.09732972710350624\n",
      "train loss:0.14837394638284393\n",
      "train loss:0.052877298408598616\n",
      "train loss:0.08375885796953927\n",
      "train loss:0.12734162555655726\n",
      "train loss:0.09376183633008563\n",
      "train loss:0.03985786026135161\n",
      "train loss:0.07570992012689294\n",
      "train loss:0.01677500623645979\n",
      "train loss:0.08336843410675356\n",
      "train loss:0.08666227779103748\n",
      "train loss:0.16925649626016612\n",
      "train loss:0.05122532955033139\n",
      "train loss:0.114069124381886\n",
      "train loss:0.05522877639961035\n",
      "train loss:0.08895514059731773\n",
      "train loss:0.044571161310761935\n",
      "train loss:0.10498391603866375\n",
      "train loss:0.025252434343453457\n",
      "train loss:0.13651671610177052\n",
      "train loss:0.05162773781793727\n",
      "train loss:0.04079060063414496\n",
      "train loss:0.06809323302442921\n",
      "train loss:0.07655455931242656\n",
      "train loss:0.048215745157888755\n",
      "train loss:0.03253295171223402\n",
      "train loss:0.06777063561160292\n",
      "train loss:0.07697335061842302\n",
      "train loss:0.022866177533717065\n",
      "train loss:0.08593885318862102\n",
      "train loss:0.1264959527244396\n",
      "train loss:0.03331290118380262\n",
      "train loss:0.02574793093198828\n",
      "train loss:0.053454152691909645\n",
      "train loss:0.03563103890477284\n",
      "train loss:0.05143779920459315\n",
      "train loss:0.04785325674552197\n",
      "train loss:0.024162334954486834\n",
      "train loss:0.05554243730723535\n",
      "train loss:0.06829894933229515\n",
      "train loss:0.03740749035508749\n",
      "train loss:0.024110910820855147\n",
      "train loss:0.11017717012201837\n",
      "train loss:0.05619931265787163\n",
      "train loss:0.03215868142847699\n",
      "train loss:0.09925034494946035\n",
      "train loss:0.14960202079491972\n",
      "train loss:0.034295663192443954\n",
      "train loss:0.07368973721342428\n",
      "train loss:0.02797981087249918\n",
      "train loss:0.016349515054028155\n",
      "train loss:0.04674141202162889\n",
      "train loss:0.035911277879333514\n",
      "train loss:0.09357952184279802\n",
      "train loss:0.036136083207361176\n",
      "train loss:0.062332738401359646\n",
      "train loss:0.08595362883690186\n",
      "train loss:0.06447440479714994\n",
      "train loss:0.029532480904976538\n",
      "train loss:0.034323981911403775\n",
      "train loss:0.09262888989260683\n",
      "train loss:0.022732283441382804\n",
      "train loss:0.029070951518734792\n",
      "train loss:0.031097829890803404\n",
      "train loss:0.03524936708097674\n",
      "train loss:0.03603925932944875\n",
      "train loss:0.05877614166910274\n",
      "train loss:0.12637445378468853\n",
      "train loss:0.07736441077563279\n",
      "train loss:0.07790678330054115\n",
      "train loss:0.04395922946463351\n",
      "train loss:0.0442106382809214\n",
      "train loss:0.05045624767841453\n",
      "train loss:0.04143591144358344\n",
      "train loss:0.023027573029121517\n",
      "train loss:0.01909966678212942\n",
      "train loss:0.05920751688924346\n",
      "train loss:0.0301004781802851\n",
      "train loss:0.06287073034031296\n",
      "train loss:0.03607009191005668\n",
      "train loss:0.08012239838226927\n",
      "train loss:0.042297306003113204\n",
      "train loss:0.07829775727936367\n",
      "train loss:0.10798162914831014\n",
      "train loss:0.04356152944193827\n",
      "train loss:0.10067245236712218\n",
      "train loss:0.028968015275260908\n",
      "train loss:0.049577315910075546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.04132350143612132\n",
      "train loss:0.06568264013002763\n",
      "train loss:0.026394535959609437\n",
      "train loss:0.04147575319086069\n",
      "train loss:0.07778462354137489\n",
      "train loss:0.025070874526818377\n",
      "train loss:0.08964433227770144\n",
      "train loss:0.02396695120516933\n",
      "train loss:0.057147195712344806\n",
      "train loss:0.044602772806605566\n",
      "train loss:0.0735977887632563\n",
      "train loss:0.029407673496906782\n",
      "train loss:0.02499574604936721\n",
      "train loss:0.11905875158571183\n",
      "train loss:0.04626447272796252\n",
      "train loss:0.042813744859791635\n",
      "train loss:0.03139410313951718\n",
      "train loss:0.0342447130795787\n",
      "train loss:0.022251322197197915\n",
      "train loss:0.031223058725300724\n",
      "train loss:0.052550912618169125\n",
      "train loss:0.046137265473033935\n",
      "train loss:0.015045808568541099\n",
      "train loss:0.12147979070969331\n",
      "train loss:0.03948793982973165\n",
      "train loss:0.05166390636272875\n",
      "train loss:0.05219743946085091\n",
      "train loss:0.02779955577455846\n",
      "train loss:0.08479635990007478\n",
      "train loss:0.025114114422852604\n",
      "train loss:0.061724667784195386\n",
      "train loss:0.08287711537023668\n",
      "train loss:0.10135046882473152\n",
      "train loss:0.03983918437566245\n",
      "train loss:0.11753801029809735\n",
      "train loss:0.03127740228913822\n",
      "train loss:0.08024040474993559\n",
      "train loss:0.04257678014029812\n",
      "train loss:0.02971952747301483\n",
      "train loss:0.03592207870251952\n",
      "train loss:0.035922139562023524\n",
      "train loss:0.032740473835543765\n",
      "train loss:0.01867865161310408\n",
      "train loss:0.05629620211793273\n",
      "train loss:0.17398389509372925\n",
      "train loss:0.03196715437108309\n",
      "train loss:0.0417766554324159\n",
      "train loss:0.050124815765345075\n",
      "train loss:0.0598875886259276\n",
      "train loss:0.16135036968701313\n",
      "train loss:0.02308350566891311\n",
      "train loss:0.01583533253153533\n",
      "train loss:0.12493850918496813\n",
      "train loss:0.06454752277496478\n",
      "train loss:0.07260344685389399\n",
      "train loss:0.07769155786455088\n",
      "train loss:0.04637010830003018\n",
      "train loss:0.0958368346112308\n",
      "train loss:0.03503011417210326\n",
      "train loss:0.07943811623129443\n",
      "train loss:0.02579002713479566\n",
      "train loss:0.02473639520027954\n",
      "train loss:0.045311508696100074\n",
      "train loss:0.15109447586089778\n",
      "train loss:0.022564417170984806\n",
      "train loss:0.06482092344528463\n",
      "train loss:0.020182767233376676\n",
      "train loss:0.04047672558587267\n",
      "train loss:0.07691613633819781\n",
      "train loss:0.14735114227521628\n",
      "train loss:0.07174933474614749\n",
      "train loss:0.1262898016442365\n",
      "train loss:0.14360132450345164\n",
      "train loss:0.07861090545713081\n",
      "train loss:0.020212078802574352\n",
      "train loss:0.036091179227910664\n",
      "train loss:0.028565105943470573\n",
      "train loss:0.06827873122774344\n",
      "train loss:0.029909392886844098\n",
      "train loss:0.03772528310189027\n",
      "train loss:0.03947691881041155\n",
      "train loss:0.04567724092413172\n",
      "train loss:0.07899390788354298\n",
      "train loss:0.05712643672973293\n",
      "train loss:0.175905705452506\n",
      "train loss:0.16546312709127586\n",
      "train loss:0.022178299287918465\n",
      "train loss:0.10124765550732563\n",
      "train loss:0.09254749343717314\n",
      "train loss:0.036186302630659035\n",
      "train loss:0.045535917420206296\n",
      "train loss:0.09784043521713855\n",
      "train loss:0.07845888523784529\n",
      "train loss:0.027256864327899408\n",
      "train loss:0.03918564806663117\n",
      "train loss:0.022605393893109667\n",
      "train loss:0.06863569563050845\n",
      "train loss:0.10724100069864577\n",
      "train loss:0.024109080403137834\n",
      "train loss:0.10775029841538311\n",
      "train loss:0.10077355775808852\n",
      "train loss:0.08212467957018971\n",
      "train loss:0.09432594875116505\n",
      "train loss:0.08691558345084154\n",
      "train loss:0.040628220179585145\n",
      "train loss:0.05621516063237773\n",
      "train loss:0.05020943265396003\n",
      "train loss:0.04710860664147231\n",
      "train loss:0.043140829339891155\n",
      "train loss:0.017635256983463545\n",
      "train loss:0.09636479006174214\n",
      "train loss:0.042285971730189956\n",
      "train loss:0.05598983963842257\n",
      "train loss:0.10908227167524163\n",
      "train loss:0.09258159265406124\n",
      "train loss:0.061045185585105785\n",
      "train loss:0.08850941606507585\n",
      "train loss:0.08375754809064302\n",
      "train loss:0.08233498773221432\n",
      "train loss:0.0677536668612449\n",
      "train loss:0.06898618162739886\n",
      "train loss:0.0834496848577063\n",
      "train loss:0.07096893128446866\n",
      "train loss:0.06876622800436297\n",
      "train loss:0.06501794598396736\n",
      "train loss:0.04631482114654784\n",
      "train loss:0.04936139100044183\n",
      "train loss:0.09600586402120655\n",
      "train loss:0.08033285175317674\n",
      "train loss:0.04204237200551044\n",
      "train loss:0.10971131831538468\n",
      "train loss:0.08648663453084637\n",
      "train loss:0.03577450835486829\n",
      "train loss:0.08834887861924193\n",
      "train loss:0.01702260452852336\n",
      "train loss:0.033598375634673404\n",
      "train loss:0.037182507909667616\n",
      "=== epoch:3, train acc:0.974, test acc:0.978 ===\n",
      "train loss:0.018058829551642643\n",
      "train loss:0.0892880095540904\n",
      "train loss:0.06607845351729072\n",
      "train loss:0.036958630742298805\n",
      "train loss:0.03589251110949386\n",
      "train loss:0.08923670424816926\n",
      "train loss:0.10407580839525483\n",
      "train loss:0.09503331791651712\n",
      "train loss:0.026881462022098554\n",
      "train loss:0.04666714854658282\n",
      "train loss:0.04076529479694533\n",
      "train loss:0.01972912758121855\n",
      "train loss:0.039469001938399306\n",
      "train loss:0.1972832355954916\n",
      "train loss:0.04192969011175182\n",
      "train loss:0.10656053467938184\n",
      "train loss:0.048343709774428804\n",
      "train loss:0.14016643316118588\n",
      "train loss:0.0424378145121877\n",
      "train loss:0.023556594452127898\n",
      "train loss:0.0463855567264035\n",
      "train loss:0.16101376398914957\n",
      "train loss:0.10608668679421086\n",
      "train loss:0.03592368315272511\n",
      "train loss:0.11416212763006438\n",
      "train loss:0.05710639618712368\n",
      "train loss:0.04532042690780487\n",
      "train loss:0.04416243150704628\n",
      "train loss:0.028088089755407532\n",
      "train loss:0.027838827774649175\n",
      "train loss:0.09712312097017066\n",
      "train loss:0.037160154115353936\n",
      "train loss:0.037376291341870344\n",
      "train loss:0.05037204212229386\n",
      "train loss:0.07854368209321481\n",
      "train loss:0.06854551180693857\n",
      "train loss:0.042191101123621795\n",
      "train loss:0.0809122115434613\n",
      "train loss:0.059374260816341666\n",
      "train loss:0.1095859056568021\n",
      "train loss:0.0715063346111103\n",
      "train loss:0.0222968216597755\n",
      "train loss:0.018631170267145482\n",
      "train loss:0.08520422523732464\n",
      "train loss:0.017924424302694458\n",
      "train loss:0.024290862580348925\n",
      "train loss:0.018851177880985066\n",
      "train loss:0.046473996651234\n",
      "train loss:0.05471977801997545\n",
      "train loss:0.03014758385985766\n",
      "train loss:0.034324672578138656\n",
      "train loss:0.03007283201210327\n",
      "train loss:0.04162081666333266\n",
      "train loss:0.11252263329050854\n",
      "train loss:0.03056146514052422\n",
      "train loss:0.05985583311343368\n",
      "train loss:0.046280283769807175\n",
      "train loss:0.06818706523822918\n",
      "train loss:0.031670882576223705\n",
      "train loss:0.07143087805688449\n",
      "train loss:0.006974501994818841\n",
      "train loss:0.030972668502208225\n",
      "train loss:0.08020362409574679\n",
      "train loss:0.031998482343612564\n",
      "train loss:0.02712386308941149\n",
      "train loss:0.05451387338842429\n",
      "train loss:0.044904072762136246\n",
      "train loss:0.0985490520321546\n",
      "train loss:0.03568491615655044\n",
      "train loss:0.06345093319588763\n",
      "train loss:0.09303281450903399\n",
      "train loss:0.041553284291494075\n",
      "train loss:0.04417395897905583\n",
      "train loss:0.09474679752355392\n",
      "train loss:0.03137236943324896\n",
      "train loss:0.10575538653219697\n",
      "train loss:0.10105117082303038\n",
      "train loss:0.06845135104736802\n",
      "train loss:0.05170073690714898\n",
      "train loss:0.014196870562895359\n",
      "train loss:0.01411970960987957\n",
      "train loss:0.03999903184728501\n",
      "train loss:0.11627014631218749\n",
      "train loss:0.07025712964420017\n",
      "train loss:0.06441623913904246\n",
      "train loss:0.13757294813551327\n",
      "train loss:0.0692673898915344\n",
      "train loss:0.02455972972548813\n",
      "train loss:0.070422552039623\n",
      "train loss:0.024700759994415608\n",
      "train loss:0.0368435685589987\n",
      "train loss:0.02724138378180172\n",
      "train loss:0.030282032189397085\n",
      "train loss:0.06764284797184607\n",
      "train loss:0.048638375262190586\n",
      "train loss:0.022021045942509487\n",
      "train loss:0.06800404963580252\n",
      "train loss:0.17640476025057072\n",
      "train loss:0.08413578980327373\n",
      "train loss:0.07960787118513414\n",
      "train loss:0.04474985165729212\n",
      "train loss:0.05472263548429048\n",
      "train loss:0.04082506315459322\n",
      "train loss:0.009804774548681925\n",
      "train loss:0.05848244728547841\n",
      "train loss:0.031933693587843474\n",
      "train loss:0.05384724577242941\n",
      "train loss:0.038642440685398835\n",
      "train loss:0.022802454962358092\n",
      "train loss:0.10614766638071634\n",
      "train loss:0.06743558010092739\n",
      "train loss:0.03460554782855695\n",
      "train loss:0.07557560271406216\n",
      "train loss:0.043478484596030355\n",
      "train loss:0.04137732759815961\n",
      "train loss:0.03145193631105356\n",
      "train loss:0.020376380669926593\n",
      "train loss:0.03745786930397402\n",
      "train loss:0.0443991752379211\n",
      "train loss:0.018962785484738506\n",
      "train loss:0.04688623631790546\n",
      "train loss:0.0708389764910491\n",
      "train loss:0.024173412305554746\n",
      "train loss:0.046253377803244566\n",
      "train loss:0.03261367514966422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.06824563560997918\n",
      "train loss:0.04144348626539546\n",
      "train loss:0.012798545540284846\n",
      "train loss:0.0791735398617231\n",
      "train loss:0.028519147920481828\n",
      "train loss:0.03625424951468881\n",
      "train loss:0.032025046351289485\n",
      "train loss:0.054777268819815844\n",
      "train loss:0.06676562632372779\n",
      "train loss:0.04472209529524544\n",
      "train loss:0.07223587275708375\n",
      "train loss:0.016942404661409543\n",
      "train loss:0.12449036528733139\n",
      "train loss:0.013829307228928627\n",
      "train loss:0.027305945188933426\n",
      "train loss:0.05974807108793403\n",
      "train loss:0.07076909075333983\n",
      "train loss:0.039665566683837354\n",
      "train loss:0.01398027108446024\n",
      "train loss:0.09809109117307077\n",
      "train loss:0.03288077788449679\n",
      "train loss:0.04868610553177777\n",
      "train loss:0.1464775457296044\n",
      "train loss:0.05365116421632182\n",
      "train loss:0.03506402257998208\n",
      "train loss:0.06729532645072463\n",
      "train loss:0.01936257689753059\n",
      "train loss:0.0565042583805511\n",
      "train loss:0.016141626594688742\n",
      "train loss:0.10374343997854614\n",
      "train loss:0.04593667925206236\n",
      "train loss:0.13391399937489182\n",
      "train loss:0.020446279071825946\n",
      "train loss:0.045064198567214483\n",
      "train loss:0.039459302583001864\n",
      "train loss:0.03503809953426332\n",
      "train loss:0.022191490602167803\n",
      "train loss:0.06970213331336461\n",
      "train loss:0.053175603816231494\n",
      "train loss:0.05314894426310036\n",
      "train loss:0.12233603289597554\n",
      "train loss:0.013466137779447362\n",
      "train loss:0.020206645447164474\n",
      "train loss:0.10460627489695035\n",
      "train loss:0.11633264202970181\n",
      "train loss:0.02606544313985253\n",
      "train loss:0.026200577557275784\n",
      "train loss:0.013936859960305777\n",
      "train loss:0.03742612815329478\n",
      "train loss:0.0282644650398141\n",
      "train loss:0.08153759618552202\n",
      "train loss:0.09248697333909156\n",
      "train loss:0.028592777054389208\n",
      "train loss:0.014277294608551363\n",
      "train loss:0.0248815086584022\n",
      "train loss:0.06695342846640162\n",
      "train loss:0.03213617085846207\n",
      "train loss:0.06797869340677538\n",
      "train loss:0.04501418007014215\n",
      "train loss:0.07689906459567489\n",
      "train loss:0.09308067074259245\n",
      "train loss:0.09865916395525158\n",
      "train loss:0.012306628472356024\n",
      "train loss:0.03713442412547951\n",
      "train loss:0.05353487411915405\n",
      "train loss:0.12678729588324653\n",
      "train loss:0.07042851568932139\n",
      "train loss:0.04157177589049063\n",
      "train loss:0.03289537175348669\n",
      "train loss:0.057245568791334654\n",
      "train loss:0.053924824094222626\n",
      "train loss:0.03677499558290878\n",
      "train loss:0.08346919207299164\n",
      "train loss:0.0220142924759381\n",
      "train loss:0.08169960296892304\n",
      "train loss:0.032561525291178645\n",
      "train loss:0.05362717602643227\n",
      "train loss:0.014055602506015764\n",
      "train loss:0.04514804733996004\n",
      "train loss:0.05419828144919988\n",
      "train loss:0.039641120439065716\n",
      "train loss:0.05655876211148333\n",
      "train loss:0.027083000743964712\n",
      "train loss:0.043699299216847745\n",
      "train loss:0.026586443439024644\n",
      "train loss:0.027406830958391883\n",
      "train loss:0.02100274001395257\n",
      "train loss:0.06457380719391512\n",
      "train loss:0.07942776886285002\n",
      "train loss:0.13960366299740634\n",
      "train loss:0.03852014890598218\n",
      "train loss:0.033117363242706956\n",
      "train loss:0.03832687786338894\n",
      "train loss:0.041042034059103664\n",
      "train loss:0.03215796502072987\n",
      "train loss:0.015216872916985097\n",
      "train loss:0.10286894422978708\n",
      "train loss:0.0666756911442097\n",
      "train loss:0.00839791280431532\n",
      "train loss:0.0224222751797429\n",
      "train loss:0.023648949070613563\n",
      "train loss:0.044636626093254465\n",
      "train loss:0.019790650442684445\n",
      "train loss:0.0121794014512946\n",
      "train loss:0.013491032286572223\n",
      "train loss:0.027595582709190526\n",
      "train loss:0.028120122325917304\n",
      "train loss:0.03125867375610464\n",
      "train loss:0.060247207404674846\n",
      "train loss:0.04179094836821279\n",
      "train loss:0.008983305238522336\n",
      "train loss:0.021984754363231752\n",
      "train loss:0.00990205721032405\n",
      "train loss:0.08168439196200242\n",
      "train loss:0.020247248905944263\n",
      "train loss:0.06952313837953543\n",
      "train loss:0.018353177378428606\n",
      "train loss:0.018512029003073204\n",
      "train loss:0.030599963047440906\n",
      "train loss:0.04549399211533103\n",
      "train loss:0.03204685554737416\n",
      "train loss:0.05319484088017082\n",
      "train loss:0.022843032127781007\n",
      "train loss:0.045303383564804484\n",
      "train loss:0.024367991007678773\n",
      "train loss:0.04369046279038666\n",
      "train loss:0.034523054951497406\n",
      "train loss:0.08296779246872056\n",
      "train loss:0.01972522571515533\n",
      "train loss:0.0375393299687368\n",
      "train loss:0.05562417177808288\n",
      "train loss:0.04479045782339991\n",
      "train loss:0.051228946854929215\n",
      "train loss:0.01732534064128056\n",
      "train loss:0.07304319557758933\n",
      "train loss:0.05786896482650532\n",
      "train loss:0.04079566883374728\n",
      "train loss:0.055404084050576244\n",
      "train loss:0.024100793012554675\n",
      "train loss:0.08208671885538335\n",
      "train loss:0.02748496680960666\n",
      "train loss:0.007090760226859437\n",
      "train loss:0.005580662828487321\n",
      "train loss:0.023130970173101284\n",
      "train loss:0.037366126810322406\n",
      "train loss:0.05695246968209742\n",
      "train loss:0.05846829356863452\n",
      "train loss:0.0894185331343864\n",
      "train loss:0.08534940296753658\n",
      "train loss:0.008044371890101577\n",
      "train loss:0.04701056058886262\n",
      "train loss:0.04619540205621931\n",
      "train loss:0.025533156164042472\n",
      "train loss:0.024364062986690187\n",
      "train loss:0.06251216793440742\n",
      "train loss:0.030964435402066524\n",
      "train loss:0.059047857557764434\n",
      "train loss:0.05697466537981037\n",
      "train loss:0.012068019809874963\n",
      "train loss:0.015352776286590153\n",
      "train loss:0.07119057448879434\n",
      "train loss:0.016451687776480393\n",
      "train loss:0.05198727975756287\n",
      "train loss:0.020849244140983707\n",
      "train loss:0.015649971029459128\n",
      "train loss:0.01981676310620409\n",
      "train loss:0.006231576945473782\n",
      "train loss:0.038333006579334146\n",
      "train loss:0.060793850048275075\n",
      "train loss:0.036213492812974264\n",
      "train loss:0.007549717376758723\n",
      "train loss:0.052540271555147636\n",
      "train loss:0.098261217835852\n",
      "train loss:0.058718758207056326\n",
      "train loss:0.03131187054974498\n",
      "train loss:0.03182606697522319\n",
      "train loss:0.07397359926837846\n",
      "train loss:0.026589295800493188\n",
      "train loss:0.0826757956235247\n",
      "train loss:0.03408363080782551\n",
      "train loss:0.09037634631231542\n",
      "train loss:0.01782586781354222\n",
      "train loss:0.04636799978424671\n",
      "train loss:0.035243309634470706\n",
      "train loss:0.04374408933317032\n",
      "train loss:0.06607246505907775\n",
      "train loss:0.02975410723086648\n",
      "train loss:0.014176435736285574\n",
      "train loss:0.040165878932233195\n",
      "train loss:0.03244473538742969\n",
      "train loss:0.024215033634263958\n",
      "train loss:0.04677609821192233\n",
      "train loss:0.020086181773719278\n",
      "train loss:0.04118475320474783\n",
      "train loss:0.04362414020418298\n",
      "train loss:0.051189104996129275\n",
      "train loss:0.04451145308086543\n",
      "train loss:0.024944078722694815\n",
      "train loss:0.015703188718839873\n",
      "train loss:0.1079738137150739\n",
      "train loss:0.014786317005802557\n",
      "train loss:0.01820183832654045\n",
      "train loss:0.008397171868268376\n",
      "train loss:0.024814936622299267\n",
      "train loss:0.03603578709157991\n",
      "train loss:0.03554694263953467\n",
      "train loss:0.08495637636849175\n",
      "train loss:0.01769011273270547\n",
      "train loss:0.0632682657753929\n",
      "train loss:0.01669600236047227\n",
      "train loss:0.009796362845726565\n",
      "train loss:0.09416912455193932\n",
      "train loss:0.05105219421898959\n",
      "train loss:0.048483794068688794\n",
      "train loss:0.044437348303528294\n",
      "train loss:0.03217622168302865\n",
      "train loss:0.04518517678586973\n",
      "train loss:0.011637179128724941\n",
      "train loss:0.03220763304989392\n",
      "train loss:0.11007410930619078\n",
      "train loss:0.18379894380115858\n",
      "train loss:0.03978278254010642\n",
      "train loss:0.03207897826758784\n",
      "train loss:0.02581017299849905\n",
      "train loss:0.02527054145948539\n",
      "train loss:0.0538067920208789\n",
      "train loss:0.05064305785658294\n",
      "train loss:0.020931038571313097\n",
      "train loss:0.03886430609633205\n",
      "train loss:0.13690777347219782\n",
      "train loss:0.035048918991723466\n",
      "train loss:0.08724699017957464\n",
      "train loss:0.020761675782670103\n",
      "train loss:0.020068132880519923\n",
      "train loss:0.016777306521712762\n",
      "train loss:0.17220160815882984\n",
      "train loss:0.14078929851999109\n",
      "train loss:0.028358258894295486\n",
      "train loss:0.02158685190512295\n",
      "train loss:0.02954851804893801\n",
      "train loss:0.11379235889298445\n",
      "train loss:0.016272155344855474\n",
      "train loss:0.07531439197532996\n",
      "train loss:0.044806606595370495\n",
      "train loss:0.019752315859625957\n",
      "train loss:0.047344324196441676\n",
      "train loss:0.027373011976708838\n",
      "train loss:0.025860865191608594\n",
      "train loss:0.026381935749190767\n",
      "train loss:0.04677506182457002\n",
      "train loss:0.025325291641184952\n",
      "train loss:0.030439327743051116\n",
      "train loss:0.10153330311330241\n",
      "train loss:0.05647375316336554\n",
      "train loss:0.03692592407530695\n",
      "train loss:0.013976676813804902\n",
      "train loss:0.011262335425829034\n",
      "train loss:0.027648080432436127\n",
      "train loss:0.015443296012328805\n",
      "train loss:0.03215264456697919\n",
      "train loss:0.019034669331879136\n",
      "train loss:0.043352361404184546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.025024761683888938\n",
      "train loss:0.06581673200098775\n",
      "train loss:0.0827024784398688\n",
      "train loss:0.016798804920889074\n",
      "train loss:0.03637457292604875\n",
      "train loss:0.03460222906574509\n",
      "train loss:0.022020363793906216\n",
      "train loss:0.07678156362547899\n",
      "train loss:0.04184772020667753\n",
      "train loss:0.08890392627306967\n",
      "train loss:0.030485943651280833\n",
      "train loss:0.047407447586161104\n",
      "train loss:0.03753977002975189\n",
      "train loss:0.05080169929435722\n",
      "train loss:0.03724977779642045\n",
      "train loss:0.036580078022798924\n",
      "train loss:0.013947194620150523\n",
      "train loss:0.026618361071596482\n",
      "train loss:0.015152717216893107\n",
      "train loss:0.02310686702067531\n",
      "train loss:0.02667730556346971\n",
      "train loss:0.06890215926628257\n",
      "train loss:0.04124365354995058\n",
      "train loss:0.02059635741385977\n",
      "train loss:0.015417832736026354\n",
      "train loss:0.018282708517284866\n",
      "train loss:0.01615784468209035\n",
      "train loss:0.05903090556475135\n",
      "train loss:0.05191909262933152\n",
      "train loss:0.02555477680940514\n",
      "train loss:0.036060294372360906\n",
      "train loss:0.028341081601345287\n",
      "train loss:0.026138059901998436\n",
      "train loss:0.028789363651075397\n",
      "train loss:0.0866920784641885\n",
      "train loss:0.026002813683940227\n",
      "train loss:0.02932995101195982\n",
      "train loss:0.023213343610474647\n",
      "train loss:0.06757528664325171\n",
      "train loss:0.032793491390101376\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(\"..//\")\n",
    "sys.path.append(\"..//ch07\")#       \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from simple_convnet import SimpleConvNet\n",
    "from common.trainer import Trainer\n",
    "\n",
    "#  \n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "#      .\n",
    "#x_train, t_train = x_train[:5000], t_train[:5000]\n",
    "#x_test, t_test = x_test[:1000], t_test[:1000]\n",
    "\n",
    "max_epochs = 20\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "                        \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "#  \n",
    "network.save_params(\"params.pkl\")\n",
    "print(\"Saved Network Parameters!\")\n",
    "\n",
    "#  \n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yyc",
   "language": "python",
   "name": "yyc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
