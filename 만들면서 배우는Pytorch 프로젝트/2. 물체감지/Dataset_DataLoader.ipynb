{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パッケージのimport\n",
    "import os.path as osp\n",
    "import random\n",
    "# XMLをファイルやテキストから読み込んだり、加工したり、保存したりするためのライブラリ\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 乱数のシードを設定\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 학습 및 검증용 화상 데이터, 어노테이션 데이터의 파일 경로 리스트 작성\n",
    "\n",
    "def make_datapath_list(rootpath):\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    rootpath : str\n",
    "        데이터 폴더 경로\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ret : train_img_list, train_anno_list, val_img_list, val_anno_list\n",
    "        데이터 경로를 저장한 리스트\n",
    "    \"\"\"\n",
    "\n",
    "    # 화상 파일과 어노테이셔 파일의 경로 템플릿 작성\n",
    "    imgpath_template = osp.join(rootpath, 'JPEGImages', '%s.jpg')\n",
    "    annopath_template = osp.join(rootpath, 'Annotations', '%s.xml')\n",
    "\n",
    "    # 훈렴 및 검증 파일 아이디(파일이름) 취득\n",
    "    train_id_names = osp.join(rootpath + 'ImageSets/Main/train.txt')\n",
    "    val_id_names = osp.join(rootpath + 'ImageSets/Main/val.txt')\n",
    "\n",
    "    # 검증 데이터의 화상 파일과 어노테이션 파일의 경로 리스트 작성\n",
    "    train_img_list = list()\n",
    "    train_anno_list = list()\n",
    "\n",
    "    for line in open(train_id_names):\n",
    "        file_id = line.strip()  # 공백과 줄 바꿈 제거\n",
    "        img_path = (imgpath_template % file_id)  # 화상 경로\n",
    "        anno_path = (annopath_template % file_id)  # 어노테이션 경로\n",
    "        train_img_list.append(img_path)  # 리스트에 추가\n",
    "        train_anno_list.append(anno_path)  # 리스트에 추가\n",
    "\n",
    "    # 검증데이터 화상 파일과 어노테이션 파일의 경로 리스트 작성\n",
    "    val_img_list = list()\n",
    "    val_anno_list = list()\n",
    "\n",
    "    for line in open(val_id_names):\n",
    "        file_id = line.strip()  # 공백과 줄 바꿈 제거\n",
    "        img_path = (imgpath_template % file_id)  # 화상 경로\n",
    "        anno_path = (annopath_template % file_id)  # 어노테이션 경로\n",
    "        val_img_list.append(img_path)  # 리스트에 추가\n",
    "        val_anno_list.append(anno_path)  # 리스트에 추가\n",
    "\n",
    "    return train_img_list, train_anno_list, val_img_list, val_anno_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/VOCdevkit/VOC2012/JPEGImages/2008_000008.jpg\n"
     ]
    }
   ],
   "source": [
    "# 파일 경로 리스트 작성\n",
    "rootpath = \"./data/VOCdevkit/VOC2012/\"\n",
    "train_img_list, train_anno_list, val_img_list, val_anno_list = make_datapath_list(\n",
    "    rootpath)\n",
    "\n",
    "# 동작 확인\n",
    "print(train_img_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XML 형식의 어노테이션을 리스트 형식으로 변환하는 클래스\n",
    "class Anno_xml2list(object):\n",
    "    \"\"\"\n",
    "    한 화상의 XML 형식 어노테이션 데이터를 화상 크기로 규격화 하여 리스트 형식으로 변환\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    classes : 리스트\n",
    "        VOC의 클래스명을 저장한 리스트\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, classes):\n",
    "\n",
    "        self.classes = classes\n",
    "\n",
    "    def __call__(self, xml_path, width, height):\n",
    "        \"\"\"\n",
    "        한 화상의 xml 형식 어노테이션 데이터를 화상 크기로 규격화하여 리스트 형식으로 변환\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        xml_path : str\n",
    "            xml 파일경로\n",
    "        width : int\n",
    "            대상 화상 폭。\n",
    "        height : int\n",
    "            대상 。\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ret : [[xmin, ymin, xmax, ymax, label_ind], ... ]\n",
    "            물체의 어노테이션 데이터를 저장한 리스트. 화상에 존재하는 물체 수만큼의 요소를 가짐\n",
    "        \"\"\"\n",
    "\n",
    "        # 화상 내  모든 물체(object)의 어노테이션을 이 리스트에 저장\n",
    "        ret = []\n",
    "\n",
    "        # xml업로드\n",
    "        xml = ET.parse(xml_path).getroot()\n",
    "\n",
    "        # 화상 내 물체 수만큼 반복\n",
    "        for obj in xml.iter('object'):\n",
    "\n",
    "            # 어노테이션에서 검지가 difficult로 설정된 것은 제외\n",
    "            difficult = int(obj.find('difficult').text)\n",
    "            if difficult == 1:\n",
    "                continue\n",
    "\n",
    "            # 한 물체의 어노테이션을 저장하는 리스트\n",
    "            bndbox = []\n",
    "\n",
    "            name = obj.find('name').text.lower().strip()  # 물체 이름\n",
    "            bbox = obj.find('bndbox')  # 바운딩 박스 정보\n",
    "\n",
    "            # 어노테이션의 xmin, ymin, xmax, ymax를 취득하고 0~1으로 규격화\n",
    "            pts = ['xmin', 'ymin', 'xmax', 'ymax']\n",
    "\n",
    "            for pt in (pts):\n",
    "                # VOC는 원점이 (1,1)이므로 1을 빼서 (0,0)으로 한다.\n",
    "                cur_pixel = int(bbox.find(pt).text) - 1\n",
    "\n",
    "                # 폭 높이로 규격화\n",
    "                if pt == 'xmin' or pt == 'xmax':  # x방향의 경우 폭으로 나눈다\n",
    "                    cur_pixel /= width\n",
    "                else:  # y방향의 경우 높이로 나눈다.\n",
    "                    cur_pixel /= height\n",
    "\n",
    "                bndbox.append(cur_pixel)\n",
    "\n",
    "            # 어노테이션의 클래스명 index를 취득하여 추가\n",
    "            label_idx = self.classes.index(name)\n",
    "            bndbox.append(label_idx)\n",
    "\n",
    "            # res에 [xmin, ymin, xmax, ymax, label_ind] 를 더한다\n",
    "            ret += [bndbox]\n",
    "\n",
    "        return np.array(ret)  # [[xmin, ymin, xmax, ymax, label_ind], ... ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.09      ,  0.03003003,  0.998     ,  0.996997  , 18.        ],\n",
       "       [ 0.122     ,  0.56756757,  0.164     ,  0.72672673, 14.        ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 동작 확인\n",
    "voc_classes = ['aeroplane', 'bicycle', 'bird', 'boat',\n",
    "               'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "               'cow', 'diningtable', 'dog', 'horse',\n",
    "               'motorbike', 'person', 'pottedplant',\n",
    "               'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "\n",
    "transform_anno = Anno_xml2list(voc_classes)\n",
    "\n",
    "# 화상 로드용으로 openCV 사용\n",
    "ind = 1\n",
    "image_file_path = val_img_list[ind]\n",
    "img = cv2.imread(image_file_path)  # [높이][폭][색RGB]\n",
    "height, width, channels = img.shape  # 화상 크기 취득\n",
    "\n",
    "# 어노테이션을 리스트로 표시\n",
    "transform_anno(val_anno_list[ind], width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils 폴더에 있는 data_augumentation.py 에서 import\n",
    "# 입력 영상의 전처리 클래스\n",
    "from utils.data_augumentation import Compose, ConvertFromInts, ToAbsoluteCoords, PhotometricDistort, Expand, RandomSampleCrop, RandomMirror, ToPercentCoords, Resize, SubtractMeans\n",
    "\n",
    "\n",
    "class DataTransform():\n",
    "    \"\"\"\n",
    "    화상과 어노테이션의 전처리 클래스. 훈련과 추론에서 다르게 작동한다.\n",
    "    화상 크기를 300x300 으로 한다.\n",
    "    학습 시 데이터 확장을 수행한다.\n",
    "\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    input_size : int\n",
    "        리사이즈 대상 화상의 크기\n",
    "    color_mean : (B, G, R)\n",
    "        각 색상 채널의 평균값\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, color_mean):\n",
    "        self.data_transform = {\n",
    "            'train': Compose([\n",
    "                ConvertFromInts(),   #  int를 float32로 변환\n",
    "                ToAbsoluteCoords(),  # 어노테이션 데이터의 규격화 반환\n",
    "                PhotometricDistort(),  # 화상의 색조 등 임의로 변화\n",
    "                Expand(color_mean),  # 화상의 캔버스 확대\n",
    "                RandomSampleCrop(),  # 화상 내의 특정 부분 무작위 추출\n",
    "                RandomMirror(),  # 화상 반전\n",
    "                ToPercentCoords(),  # 어노테이션 데이터를 0~1로 규격화\n",
    "                Resize(input_size),  # 화상 크기를 input_size x input_size로 변형\n",
    "                SubtractMeans(color_mean)  # BGR 색상의 평균값 빼기\n",
    "            ]),\n",
    "            'val': Compose([\n",
    "                ConvertFromInts(),  # int를 float로 변환\n",
    "                Resize(input_size),  # 화상크기를 input_size x input_size 로 변형\n",
    "                SubtractMeans(color_mean)  # BGR색상의 평균값 빼기\n",
    "            ])\n",
    "        }\n",
    "\n",
    "    def __call__(self, img, phase, boxes, labels):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        phase : 'train' or 'val'\n",
    "            전처리 모드 지정\n",
    "        \"\"\"\n",
    "        return self.data_transform[phase](img, boxes, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOC2012의 데이터셋 작성\n",
    "\n",
    "\n",
    "class VOCDataset(data.Dataset):\n",
    "    \"\"\"\n",
    "    VOC2012의 Dataset을 만드는 클래스. 파이토치의 Dataset 클래스를 상속한다.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    img_list : 리스트\n",
    "        화상 경로를 저장한 리스트\n",
    "    anno_list : 리스트\n",
    "        어노테이션 경로를 저장한 리스트ㅜ\n",
    "    phase : 'train' or 'test'\n",
    "        학습 또는 훈련 설정\n",
    "    transform : object\n",
    "        전처리 클래스의 인스턴스\n",
    "    transform_anno : object\n",
    "        xml 어노테이션을 리스트로 변환하는 인스턴스\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, img_list, anno_list, phase, transform, transform_anno):\n",
    "        self.img_list = img_list\n",
    "        self.anno_list = anno_list\n",
    "        self.phase = phase  # train or test 지정 \n",
    "        self.transform = transform  # 화상변형\n",
    "        self.transform_anno = transform_anno  # 어노테이션 데이터를 xml에서 리스트로 변경\n",
    "\n",
    "    def __len__(self):\n",
    "        '''화상의 매수 반환'''\n",
    "        return len(self.img_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        '''\n",
    "        전처리한 화상의 텐서 형식 데이터와 어노테이션 취득\n",
    "        '''\n",
    "        im, gt, h, w = self.pull_item(index)\n",
    "        return im, gt\n",
    "\n",
    "    def pull_item(self, index):\n",
    "        '''전처리한 화상의 텐서 형식 데이터, 어노테이션, 화상의 높이, 폭 취득'''\n",
    "\n",
    "        # 1. 화상읽기\n",
    "        image_file_path = self.img_list[index]\n",
    "        img = cv2.imread(image_file_path)  # [높이][폭][色BGR]\n",
    "        height, width, channels = img.shape  # 화상 크기 취즉\n",
    "\n",
    "        # 2. xml 형식의 어노테이션 정보를 리스트에 저장\n",
    "        anno_file_path = self.anno_list[index]\n",
    "        anno_list = self.transform_anno(anno_file_path, width, height)\n",
    "\n",
    "        # 3. 전처리 실시\n",
    "        img, boxes, labels = self.transform(\n",
    "            img, self.phase, anno_list[:, :4], anno_list[:, 4])\n",
    "\n",
    "        # 색상 채널의 순서가 BGR이므로 RGB로 순서 변경\n",
    "        # (높이, 폭 색상 체널)의 순서를 (색상채널, 높이, 폭) 으로 변경\n",
    "        img = torch.from_numpy(img[:, :, (2, 1, 0)]).permute(2, 0, 1)\n",
    "\n",
    "        # BBox와 라벨을 세트로 한 np.array를 작성. 변수 이름 gt는 ground truth의 약칭\n",
    "        gt = np.hstack((boxes, np.expand_dims(labels, axis=1)))\n",
    "\n",
    "        return img, gt, height, width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[   0.9417,    6.1650,   11.1283,  ...,  -22.9083,  -13.2200,\n",
       "             -9.4033],\n",
       "          [   6.4367,    9.6600,   13.8283,  ...,  -21.4433,  -18.6500,\n",
       "            -18.2033],\n",
       "          [  10.8833,   13.5500,   16.7000,  ...,  -20.9917,  -24.5250,\n",
       "            -25.1917],\n",
       "          ...,\n",
       "          [ -23.9500,  -14.9000,   -1.7583,  ..., -108.6083, -111.0000,\n",
       "           -117.8083],\n",
       "          [ -28.2817,  -20.1750,   -5.5633,  ..., -104.9933, -111.8350,\n",
       "           -119.0000],\n",
       "          [ -20.4767,  -21.0000,  -12.6333,  ..., -107.1683, -115.7800,\n",
       "           -117.1100]],\n",
       " \n",
       "         [[  25.9417,   30.1650,   35.1283,  ...,  -18.0767,  -14.7250,\n",
       "            -11.8533],\n",
       "          [  31.4367,   33.6600,   37.8283,  ...,  -13.5017,  -10.8250,\n",
       "            -10.3783],\n",
       "          [  35.7917,   37.5500,   40.7000,  ...,  -11.8417,  -13.0750,\n",
       "            -14.0167],\n",
       "          ...,\n",
       "          [  -1.9500,    7.1000,   20.2417,  ..., -101.9083, -102.0000,\n",
       "           -109.7167],\n",
       "          [  -6.2817,    1.8250,   16.4367,  ..., -100.0517, -103.6700,\n",
       "           -111.0000],\n",
       "          [   1.5233,    1.0000,    9.3667,  ..., -102.5017, -107.7800,\n",
       "           -109.1100]],\n",
       " \n",
       "         [[  45.2750,   55.1650,   62.1283,  ...,   12.8500,   22.0550,\n",
       "             27.8167],\n",
       "          [  50.8800,   58.3300,   64.4983,  ...,   15.8350,   21.5150,\n",
       "             22.7967],\n",
       "          [  56.0667,   60.5500,   65.1500,  ...,   15.6417,   14.8250,\n",
       "             14.7083],\n",
       "          ...,\n",
       "          [  36.7167,   43.1000,   56.2417,  ...,  -94.7583,  -96.0000,\n",
       "           -101.9000],\n",
       "          [  32.3850,   37.8250,   52.4367,  ...,  -92.1617,  -96.0000,\n",
       "           -101.8867],\n",
       "          [  40.1900,   37.0000,   45.3667,  ...,  -94.5017,  -99.7800,\n",
       "            -99.1467]]]),\n",
       " array([[ 0.09      ,  0.03003003,  0.998     ,  0.996997  , 18.        ],\n",
       "        [ 0.122     ,  0.56756757,  0.164     ,  0.72672673, 14.        ]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 동작 확인\n",
    "color_mean = (104, 117, 123)  # (BGR)의 색의 평균값\n",
    "input_size = 300  # 화상의 input 사이즈를 300x300 으로 변경\n",
    "\n",
    "train_dataset = VOCDataset(train_img_list, train_anno_list, phase=\"train\", transform=DataTransform(\n",
    "    input_size, color_mean), transform_anno=Anno_xml2list(voc_classes))\n",
    "\n",
    "val_dataset = VOCDataset(val_img_list, val_anno_list, phase=\"val\", transform=DataTransform(\n",
    "    input_size, color_mean), transform_anno=Anno_xml2list(voc_classes))\n",
    "\n",
    "\n",
    "# 데이터 출력 예\n",
    "val_dataset.__getitem__(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def od_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Dataset에서 꺼내는 어노테이션 데이터의 크기는 화상마다 다르다.\n",
    "    화상 내의 물체 수가 두 개이면 (2,5) 사이즈지만 세 개이면 (3,5)등으로 바뀐다.\n",
    "    변화에 대응하느 DataLoader를 만드는 collate_fn 작성\n",
    "    collate_fn은 파이토치 리스트로 mini-batch를 작성하는 함수이다.\n",
    "    미니 배치 분량의 화싱이 나열된 리스트 변수 batch에 미니 배치 번호를 지정하는 \n",
    "    차원을 가장 앞에 하나 추가하여 리스트 형태를 변형한다.\n",
    "    \"\"\"\n",
    "\n",
    "    targets = []\n",
    "    imgs = []\n",
    "    for sample in batch:\n",
    "        imgs.append(sample[0])  # sample[0]은 화상 img\n",
    "        targets.append(torch.FloatTensor(sample[1]))  # sample[1]은 어노테이션 gt\n",
    "\n",
    "    # imgs는 미니 배치 크기의 리스트\n",
    "    # 리스트 요소는 torch.Size([3, 300, 300])\n",
    "    # 이 리스트를 torch.Size([batch_num, 3, 300, 300])의 텐서로 변환\n",
    "    imgs = torch.stack(imgs, dim=0)\n",
    "\n",
    "    # targets은 어노테이션의 정답인 gt의 리스트\n",
    "    # 리스트 크기 = 미니 배치 크기\n",
    "    # targets 리스트의 요소는 [n,5]\n",
    "    # n은 화상마다 다르며 화상 속 물체의 수\n",
    "    # 5는 [xmin, ymin, xmax, ymax, class_index] \n",
    "\n",
    "    return imgs, targets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
