{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パッケージのimport\n",
    "import os.path as osp\n",
    "import random\n",
    "# XMLをファイルやテキストから読み込んだり、加工したり、保存したりするためのライブラリ\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 乱数のシードを設定\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 학습 및 검증용 화상 데이터, 어노테이션 데이터의 파일 경로 리스트 작성\n",
    "\n",
    "def make_datapath_list(rootpath):\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    rootpath : str\n",
    "        데이터 폴더 경로\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ret : train_img_list, train_anno_list, val_img_list, val_anno_list\n",
    "        데이터 경로를 저장한 리스트\n",
    "    \"\"\"\n",
    "\n",
    "    # 화상 파일과 어노테이셔 파일의 경로 템플릿 작성\n",
    "    imgpath_template = osp.join(rootpath, 'JPEGImages', '%s.jpg')\n",
    "    annopath_template = osp.join(rootpath, 'Annotations', '%s.xml')\n",
    "\n",
    "    # 훈렴 및 검증 파일 아이디(파일이름) 취득\n",
    "    train_id_names = osp.join(rootpath + 'ImageSets/Main/train.txt')\n",
    "    val_id_names = osp.join(rootpath + 'ImageSets/Main/val.txt')\n",
    "\n",
    "    # 검증 데이터의 화상 파일과 어노테이션 파일의 경로 리스트 작성\n",
    "    train_img_list = list()\n",
    "    train_anno_list = list()\n",
    "\n",
    "    for line in open(train_id_names):\n",
    "        file_id = line.strip()  # 공백과 줄 바꿈 제거\n",
    "        img_path = (imgpath_template % file_id)  # 화상 경로\n",
    "        anno_path = (annopath_template % file_id)  # 어노테이션 경로\n",
    "        train_img_list.append(img_path)  # 리스트에 추가\n",
    "        train_anno_list.append(anno_path)  # 리스트에 추가\n",
    "\n",
    "    # 검증데이터 화상 파일과 어노테이션 파일의 경로 리스트 작성\n",
    "    val_img_list = list()\n",
    "    val_anno_list = list()\n",
    "\n",
    "    for line in open(val_id_names):\n",
    "        file_id = line.strip()  # 공백과 줄 바꿈 제거\n",
    "        img_path = (imgpath_template % file_id)  # 화상 경로\n",
    "        anno_path = (annopath_template % file_id)  # 어노테이션 경로\n",
    "        val_img_list.append(img_path)  # 리스트에 추가\n",
    "        val_anno_list.append(anno_path)  # 리스트에 추가\n",
    "\n",
    "    return train_img_list, train_anno_list, val_img_list, val_anno_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/VOCdevkit/VOC2012/JPEGImages/2008_000008.jpg\n"
     ]
    }
   ],
   "source": [
    "# 파일 경로 리스트 작성\n",
    "rootpath = \"./data/VOCdevkit/VOC2012/\"\n",
    "train_img_list, train_anno_list, val_img_list, val_anno_list = make_datapath_list(\n",
    "    rootpath)\n",
    "\n",
    "# 동작 확인\n",
    "print(train_img_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XML 형식의 어노테이션을 리스트 형식으로 변환하는 클래스\n",
    "class Anno_xml2list(object):\n",
    "    \"\"\"\n",
    "    한 화상의 XML 형식 어노테이션 데이터를 화상 크기로 규격화 하여 리스트 형식으로 변환\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    classes : 리스트\n",
    "        VOC의 클래스명을 저장한 리스트\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, classes):\n",
    "\n",
    "        self.classes = classes\n",
    "\n",
    "    def __call__(self, xml_path, width, height):\n",
    "        \"\"\"\n",
    "        한 화상의 xml 형식 어노테이션 데이터를 화상 크기로 규격화하여 리스트 형식으로 변환\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        xml_path : str\n",
    "            xml 파일경로\n",
    "        width : int\n",
    "            대상 화상 폭。\n",
    "        height : int\n",
    "            대상 。\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ret : [[xmin, ymin, xmax, ymax, label_ind], ... ]\n",
    "            물체의 어노테이션 데이터를 저장한 리스트. 화상에 존재하는 물체 수만큼의 요소를 가짐\n",
    "        \"\"\"\n",
    "\n",
    "        # 화상 내  모든 물체(object)의 어노테이션을 이 리스트에 저장\n",
    "        ret = []\n",
    "\n",
    "        # xml업로드\n",
    "        xml = ET.parse(xml_path).getroot()\n",
    "\n",
    "        # 화상 내 물체 수만큼 반복\n",
    "        for obj in xml.iter('object'):\n",
    "\n",
    "            # 어노테이션에서 검지가 difficult로 설정된 것은 제외\n",
    "            difficult = int(obj.find('difficult').text)\n",
    "            if difficult == 1:\n",
    "                continue\n",
    "\n",
    "            # 한 물체의 어노테이션을 저장하는 리스트\n",
    "            bndbox = []\n",
    "\n",
    "            name = obj.find('name').text.lower().strip()  # 물체 이름\n",
    "            bbox = obj.find('bndbox')  # 바운딩 박스 정보\n",
    "\n",
    "            # 어노테이션의 xmin, ymin, xmax, ymax를 취득하고 0~1으로 규격화\n",
    "            pts = ['xmin', 'ymin', 'xmax', 'ymax']\n",
    "\n",
    "            for pt in (pts):\n",
    "                # VOC는 원점이 (1,1)이므로 1을 빼서 (0,0)으로 한다.\n",
    "                cur_pixel = int(bbox.find(pt).text) - 1\n",
    "\n",
    "                # 폭 높이로 규격화\n",
    "                if pt == 'xmin' or pt == 'xmax':  # x방향의 경우 폭으로 나눈다\n",
    "                    cur_pixel /= width\n",
    "                else:  # y방향의 경우 높이로 나눈다.\n",
    "                    cur_pixel /= height\n",
    "\n",
    "                bndbox.append(cur_pixel)\n",
    "\n",
    "            # 어노테이션의 클래스명 index를 취득하여 추가\n",
    "            label_idx = self.classes.index(name)\n",
    "            bndbox.append(label_idx)\n",
    "\n",
    "            # res에 [xmin, ymin, xmax, ymax, label_ind] 를 더한다\n",
    "            ret += [bndbox]\n",
    "\n",
    "        return np.array(ret)  # [[xmin, ymin, xmax, ymax, label_ind], ... ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.09      ,  0.03003003,  0.998     ,  0.996997  , 18.        ],\n",
       "       [ 0.122     ,  0.56756757,  0.164     ,  0.72672673, 14.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 동작 확인\n",
    "voc_classes = ['aeroplane', 'bicycle', 'bird', 'boat',\n",
    "               'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "               'cow', 'diningtable', 'dog', 'horse',\n",
    "               'motorbike', 'person', 'pottedplant',\n",
    "               'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "\n",
    "transform_anno = Anno_xml2list(voc_classes)\n",
    "\n",
    "# 화상 로드용으로 openCV 사용\n",
    "ind = 1\n",
    "image_file_path = val_img_list[ind]\n",
    "img = cv2.imread(image_file_path)  # [높이][폭][색RGB]\n",
    "height, width, channels = img.shape  # 화상 크기 취득\n",
    "\n",
    "# 어노테이션을 리스트로 표시\n",
    "transform_anno(val_anno_list[ind], width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils 폴더에 있는 data_augumentation.py 에서 import\n",
    "# 입력 영상의 전처리 클래스\n",
    "from utils.data_augumentation import Compose, ConvertFromInts, ToAbsoluteCoords, PhotometricDistort, Expand, RandomSampleCrop, RandomMirror, ToPercentCoords, Resize, SubtractMeans\n",
    "\n",
    "\n",
    "class DataTransform():\n",
    "    \"\"\"\n",
    "    화상과 어노테이션의 전처리 클래스. 훈련과 추론에서 다르게 작동한다.\n",
    "    화상 크기를 300x300 으로 한다.\n",
    "    학습 시 데이터 확장을 수행한다.\n",
    "\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    input_size : int\n",
    "        리사이즈 대상 화상의 크기\n",
    "    color_mean : (B, G, R)\n",
    "        각 색상 채널의 평균값\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, color_mean):\n",
    "        self.data_transform = {\n",
    "            'train': Compose([\n",
    "                ConvertFromInts(),   #  int를 float32로 변환\n",
    "                ToAbsoluteCoords(),  # 어노테이션 데이터의 규격화 반환\n",
    "                PhotometricDistort(),  # 화상의 색조 등 임의로 변화\n",
    "                Expand(color_mean),  # 화상의 캔버스 확대\n",
    "                RandomSampleCrop(),  # 화상 내의 특정 부분 무작위 추출\n",
    "                RandomMirror(),  # 화상 반전\n",
    "                ToPercentCoords(),  # 어노테이션 데이터를 0~1로 규격화\n",
    "                Resize(input_size),  # 화상 크기를 input_size x input_size로 변형\n",
    "                SubtractMeans(color_mean)  # BGR 색상의 평균값 빼기\n",
    "            ]),\n",
    "            'val': Compose([\n",
    "                ConvertFromInts(),  # int를 float로 변환\n",
    "                Resize(input_size),  # 화상크기를 input_size x input_size 로 변형\n",
    "                SubtractMeans(color_mean)  # BGR색상의 평균값 빼기\n",
    "            ])\n",
    "        }\n",
    "\n",
    "    def __call__(self, img, phase, boxes, labels):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        phase : 'train' or 'val'\n",
    "            전처리 모드 지정\n",
    "        \"\"\"\n",
    "        return self.data_transform[phase](img, boxes, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOC2012의 데이터셋 작성\n",
    "\n",
    "\n",
    "class VOCDataset(data.Dataset):\n",
    "    \"\"\"\n",
    "    VOC2012のDatasetを作成するクラス。PyTorchのDatasetクラスを継承。\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    img_list : リスト\n",
    "        画像のパスを格納したリスト\n",
    "    anno_list : リスト\n",
    "        アノテーションへのパスを格納したリスト\n",
    "    phase : 'train' or 'test'\n",
    "        学習か訓練かを設定する。\n",
    "    transform : object\n",
    "        前処理クラスのインスタンス\n",
    "    transform_anno : object\n",
    "        xmlのアノテーションをリストに変換するインスタンス\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, img_list, anno_list, phase, transform, transform_anno):\n",
    "        self.img_list = img_list\n",
    "        self.anno_list = anno_list\n",
    "        self.phase = phase  # train もしくは valを指定\n",
    "        self.transform = transform  # 画像の変形\n",
    "        self.transform_anno = transform_anno  # アノテーションデータをxmlからリストへ\n",
    "\n",
    "    def __len__(self):\n",
    "        '''画像の枚数を返す'''\n",
    "        return len(self.img_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        '''\n",
    "        前処理をした画像のテンソル形式のデータとアノテーションを取得\n",
    "        '''\n",
    "        im, gt, h, w = self.pull_item(index)\n",
    "        return im, gt\n",
    "\n",
    "    def pull_item(self, index):\n",
    "        '''前処理をした画像のテンソル形式のデータ、アノテーション、画像の高さ、幅を取得する'''\n",
    "\n",
    "        # 1. 画像読み込み\n",
    "        image_file_path = self.img_list[index]\n",
    "        img = cv2.imread(image_file_path)  # [高さ][幅][色BGR]\n",
    "        height, width, channels = img.shape  # 画像のサイズを取得\n",
    "\n",
    "        # 2. xml形式のアノテーション情報をリストに\n",
    "        anno_file_path = self.anno_list[index]\n",
    "        anno_list = self.transform_anno(anno_file_path, width, height)\n",
    "\n",
    "        # 3. 前処理を実施\n",
    "        img, boxes, labels = self.transform(\n",
    "            img, self.phase, anno_list[:, :4], anno_list[:, 4])\n",
    "\n",
    "        # 色チャネルの順番がBGRになっているので、RGBに順番変更\n",
    "        # さらに（高さ、幅、色チャネル）の順を（色チャネル、高さ、幅）に変換\n",
    "        img = torch.from_numpy(img[:, :, (2, 1, 0)]).permute(2, 0, 1)\n",
    "\n",
    "        # BBoxとラベルをセットにしたnp.arrayを作成、変数名「gt」はground truth（答え）の略称\n",
    "        gt = np.hstack((boxes, np.expand_dims(labels, axis=1)))\n",
    "\n",
    "        return img, gt, height, width"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
